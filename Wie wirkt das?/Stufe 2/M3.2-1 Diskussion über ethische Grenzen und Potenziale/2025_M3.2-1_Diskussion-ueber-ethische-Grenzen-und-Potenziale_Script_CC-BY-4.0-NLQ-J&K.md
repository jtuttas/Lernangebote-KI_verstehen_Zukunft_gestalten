## Start: Worum geht es?

Dieses Lernangebot vermittelt in kompakter und praxisnaher Form, wie Künstliche Intelligenz im Bildungsbereich verantwortungsvoll eingesetzt werden kann. Im Mittelpunkt steht die ethische Betrachtung von Chancen und Grenzen. Sie lernen, welche Rollen Gerechtigkeit, Transparenz, Verantwortung, Individualisierung und Datenschutz spielen und wie Schulen sowie Schulverwaltungen diese Aspekte in ihre Arbeit integrieren können.

Anhand realistischer Beispiele aus Unterricht und Verwaltung erfahren Sie, wie Künstliche Intelligenz Routinetätigkeiten erleichtert, individuelle Lernwege unterstützt und zugleich Risiken wie Verzerrungen oder mangelnde Nachvollziehbarkeit erzeugen kann. Das Lernangebot zeigt praxisorientierte Strategien, um diese Spannungsfelder bewusst zu gestalten und einen ethischen Rahmen zu entwickeln.

Nach Abschluss können Sie zentrale ethische Herausforderungen benennen, typische Risikoquellen erkennen, grundlegende Leitlinien formulieren und konkrete Entscheidungen im Schulalltag kritisch reflektieren. Sie vertiefen damit bereits vorhandenes Wissen und stärken Ihre Fähigkeit, künstliche Intelligenz verantwortungsbewusst zu nutzen.

Dieses Lernangebot richtet sich an **Lehrkräfte aller Schulformen, pädagogische Fachkräfte und Mitarbeitende in der Schulverwaltung.** Grundlegende Kenntnisse zur Funktionsweise von Künstlicher Intelligenz sind empfehlenswert, weiteres technisches Detailwissen ist nicht erforderlich. Offenheit für Reflexion und für partizipative Lösungswege ist die wichtigste Voraussetzung. Zur Vorbereitung empfiehlt sich ein Blick in weitere Lernangebote dieser Reihe:
* M1.1 Einführung: Künstliche Intelligenz in Schule und Unterricht – Funktionsweise, Chancen und Herausforderungen
* M1.1 Grundsätzliches Verständnis der Funktionsweise von KI
* M1.1 Einführung zu KI und Datenschutz in Schule und Verwaltung
* M3.1 KI und Ethik: Chancen und Risiken der KI-Nutzung
* M3.1 Ethik und Verantwortung: Das Wechselverhältnis von Technologie und Gesellschaft

Das Lernangebot besteht aus vier Videosequenzen, ergänzt durch Praxistipps, Checklisten und Aufgaben zur Selbstreflexion. Die Gesamtdauer einschließlich Vor- und Nachbereitung beträgt rund dreißig Minuten.

---

## Testen Sie Ihr Vorwissen

### Fragen

1.  Welche ethischen Grundpfeiler stellen sicher, dass Lernende nachvollziehen können, wie eine KI zu einer Bewertung kommt?
    * **Transparenz und Nachvollziehbarkeit**
    * Gerechtigkeit und Chancengleichheit
    * Verantwortung und Haftung
    * Datenschutz und Urheberrecht

2.  Was beschreibt den Begriff „Digital Divide“ im Zusammenhang mit KI in der Bildung am treffendsten?
    * **Unterschiedliche Zugänge zu digitalen Geräten und Internet**
    * Das Recht auf Löschung personenbezogener Daten
    * Die technische Erklärung eines Algorithmus
    * Eine Methode zur Fehlerkorrektur bei KI-Systemen

3.  Welche Aussage entspricht den Vorgaben der Datenschutz-Grundverordnung für Schulen?
    * **Personenbezogene Daten dürfen nur für klar definierte Zwecke verarbeitet werden**
    * Schulen dürfen alle Lerndaten dauerhaft speichern
    * Eltern haben kein Recht auf Auskunft über die Datennutzung
    * Anbieter können Daten ohne Zustimmung für Werbung nutzen

4.  Wer trägt letztlich die Verantwortung für Entscheidungen, die ein KI-System im Unterricht vorschlägt?
    * **Die Lehrkraft oder das Verwaltungspersonal**
    * Das KI-System selbst
    * Der technische Supportdienst
    * Die Lernenden

5.  Welcher Begriff beschreibt das Risiko, dass ein KI-System Lernende dauerhaft auf ein Leistungsniveau festlegt?
    * **Schubladisierung**
    * Explainable AI
    * Open-Source-Lizenz
    * Gamification

6.  Welche Maßnahme hilft besonders, Verzerrungen (Bias) in einem KI-System zu reduzieren?
    * **Vielfältige und repräsentative Trainingsdaten verwenden**
    * Nur Testergebnisse der leistungsstärksten Lernenden einsetzen
    * Entscheidungen ausschließlich automatisiert übernehmen
    * Den Algorithmus nicht regelmäßig aktualisieren

7.  Was ist ein zentrales Ziel von erklärbarer KI (Explainable AI) im schulischen Kontext?
    * **Die Entscheidungswege des Systems verständlich darzustellen**
    * Die Rechenleistung des Systems zu erhöhen
    * Alle Bewertungen automatisiert zu übernehmen
    * Datenschutzbestimmungen außer Kraft zu setzen

8.  Wie kann KI Mitarbeitende in der Schulverwaltung sinnvoll unterstützen?
    * **Erstellung von Vorschlägen für den Vertretungsplan**
    * Ersetzen sämtlicher persönlicher Beratungsgespräche
    * Festlegen verbindlicher Personalentscheidungen
    * Ignorieren gesetzlicher Datenschutzvorgaben

9.  Welche Kombination gewährleistet ausgewogenes und lernförderliches Feedback?
    * **Automatisiertes KI-Feedback ergänzt durch persönliches Lehrkraft-Feedback**
    * Ausschließlich automatische Rückmeldungen der KI
    * Nur mündliche Rückmeldungen ohne KI-Unterstützung
    * Verzicht auf jede Form von Feedback

10. Welches Prinzip gehört zu einem ethischen Rahmen für den KI-Einsatz in Schulen?
    * **Entscheidung durch einen Menschen über alle bedeutsamen Entscheidungen**
    * Ausschließliche Nutzung proprietärer Black-Box-Systeme
    * Unbegrenzte Speicherung aller Lerndaten
    * Verpflichtende Bewertung aller Leistungen durch KI

### Auswertung der Fragen

**Einstieg (0–3 richtige Antworten):**
Klasse, dass Sie sich an den Fragen versucht haben! Jetzt können Sie tiefer in die Materie eintauchen.

**Fortgeschritten (4–7 richtige Antworten):**
Sie haben schon ein solides Grundwissen. Der Kurs wird Ihnen helfen, Themen weiter zu vertiefen.

**Profi (8–10 richtige Antworten):**
Beeindruckend! Ihr Wissen ist bereits fundiert. Der Kurs kann Ihnen eine Auffrischung und neue Impulse bieten.

---

## Grundlagen

### Bevor es los geht …

Dieses Lernangebot richtet sich an **Lehrkräfte aller Schulformen, pädagogische Fachkräfte und Mitarbeitende in der Schulverwaltung**, die praxisnah verstehen möchten, wie Künstliche Intelligenz in Schule und Verwaltung verantwortungsvoll eingesetzt werden kann. Ziel ist es, zentrale ethische Dimensionen wie **Gerechtigkeit, Transparenz, Verantwortung, Individualisierung und Datenschutz** kennenzulernen, ihre praktische Relevanz realistisch einzuschätzen und konkrete Handlungsoptionen für den eigenen Arbeitsbereich zu entwickeln.

Das Lernangebot unterstützt Sie dabei, typische Anwendungsfelder von Künstlicher Intelligenz in Unterricht und Verwaltung zu erkennen, deren Funktionsweise nachzuvollziehen und ihre Auswirkungen kritisch zu bewerten. Dabei werden sowohl Chancen als auch Risiken thematisiert, damit ein reflektierter und verantwortungsbewusster Einsatz möglich ist.

**Behandelte Aspekte im Überblick:**
* **Ethische Leitplanken verstehen:** Gerechtigkeit, Transparenz, Verantwortung, Individualisierung, Datenschutz
* **Rolle von Lehrkräften und Verwaltungspersonal klären:** menschliche Entscheidungshoheit bewahren, Entscheidungen nachvollziehbar gestalten
* **Risiken erkennen und minimieren:** Verzerrungen, Digital Divide, Schubladisierung, Datenmissbrauch
* **Praxistransfer sichern:** Checklisten und Leitfragen, um eigene Prozesse anzupassen und einen ethischen Rahmen zu entwickeln

Mit diesem Lernangebot legen Sie die Grundlage, um KI-gestützte Werkzeuge pädagogisch und organisatorisch fundiert einzusetzen und dabei ethische Anforderungen konsequent zu berücksichtigen.

### Einführung – Ethische Fragen an KI in der Bildung

Dieses Video ist eine Einführung zu folgender Frage: Welche ethischen Überlegungen spielen eine Rolle, wenn Künstliche Intelligenz in der Bildung, sowohl im Unterricht als auch in der Verwaltung, eingesetzt wird?

Wir starten mit einem Gedankenexperiment: Stellen Sie sich vor, eine Schule setzt eine Anwendung auf Basis künstlicher Intelligenz ein, die den Lernenden täglich individuelle Übungsaufgaben zusammenstellt. Nach einigen Monaten bemerkt das Kollegium, dass Lernende mit nicht-deutscher Muttersprache fast ausschließlich einfache Lückentexte erhalten, während ihre Mitschülerinnen und Mitschüler eine breite Auswahl an anspruchsvolleren Aufgaben bekommen. Was als hilfreiche Unterstützung gedacht war, wirft plötzlich grundlegende Fragen auf: Wer trägt die Verantwortung für diese Entscheidung? War sie gerecht? Und wie transparent war der Empfehlungsprozess eigentlich?

Eine solche Situation zeigt, dass Künstliche Intelligenz nicht nur eine Frage der Technik ist. Sie betrifft zentrale Werte: **Fairness, Verantwortung, Chancengleichheit und Transparenz.**

In diesem Video erhalten Sie einen Überblick über die wichtigsten ethischen Aspekte beim Einsatz von KI in Schule und Verwaltung. Dabei geht es nicht um technische Details, sondern um grundlegende Überlegungen, die für einen verantwortungsvollen Umgang mit KI notwendig sind.

**Erstlich: Gerechtigkeit und Chancengleichheit.** Künstliche Intelligenz kann Lernprozesse personalisieren, riskiert aber Benachteiligungen, wenn Daten oder digitale Ausstattung unausgewogen sind. Schulen sollen Systeme regelmäßig auf Verzerrungen prüfen und fehlende Ressourcen durch gezielte Förderprogramme ausgleichen.

**Zweitens: Transparenz und Nachvollziehbarkeit.** Die Entscheidungswege vieler Modelle bleiben verborgen. Erklärbare Künstliche Intelligenz und menschliche Kontrolle schaffen Vertrauen, weil sie Gründe offenlegen und Korrekturen ermöglichen.

**Drittens: Verantwortung und Kontrolle.** Künstliche Intelligenz darf nur Empfehlungen geben, die Entscheidung treffen Menschen. Lehrkräfte und Verwaltung prüfen Ergebnisse, dokumentieren den Prozess und greifen bei Fehlern ein.

**Viertens: Individualisierung versus Standardisierung.** Adaptive Systeme fördern individuelles Lernen, dürfen Schülerinnen und Schüler aber nicht festlegen. Pädagogische Begleitung und regelmäßige Überprüfung verhindern Schubladisierung und bewahren gemeinsame Lernphasen.

**Fünftens: Datenschutz und ethische Leitlinien.** Daten von Lernenden sind sensibel. Sie dürfen nur sparsam und gemäß der Datenschutz-Grundverordnung verarbeitet werden, mit klaren Zugriffsrechten und konsequenter Anonymisierung.

Der reflektierte Einsatz von KI im Bildungskontext erfordert die konsequente Beachtung von **Gerechtigkeit, Transparenz, Verantwortlichkeit, gewissenhafter Individualisierung und striktem Datenschutz.** Diese Leitprinzipien müssen von Anbeginn in Entwicklung, Auswahl, Einführung und laufende Nutzung von KI-Systemen eingebettet werden, damit der technologische Fortschritt auch ethisch verantwortbar bleibt.

---

### Gerechtigkeit, Transparenz und Verantwortung – drei ethische Grundpfeiler

In diesem Video geht es um die ethischen Grenzen beim Einsatz von Künstlicher Intelligenz in Schule und Verwaltung. Im Zentrum stehen die Fragen nach **Gerechtigkeit, Transparenz und Verantwortung**. Ziel ist es, anhand konkreter Beispiele und mit Blick auf beide Bereiche Herausforderungen, Risiken und Gestaltungsspielräume verständlich darzustellen.

**Beginnen wir mit dem Thema Gerechtigkeit und Chancengleichheit.** Ein KI-gestütztes System kann etwa Lernende automatisch in Leistungsgruppen einteilen oder Verwaltungsentscheidungen vorschlagen. Im ersten Moment wirkt das effizient und unvoreingenommen. Kritisch wird es jedoch, wenn die Datenbasis, Stichwort **Bias**, nicht ausgewogen ist. Zum Beispiel können Lernende mit Deutsch als Zweitsprache benachteiligt werden, wenn die KI auf Mustern basiert, die überwiegend an Muttersprachlerinnen und Muttersprachlern erlernt wurden. Ein anderer wichtiger Punkt ist der sogenannte **Digital Divide**: Nicht alle Schülerinnen und Schüler, aber auch nicht alle Kollegien und Verwaltungsmitarbeitende verfügen über gleich guten Zugang zu Endgeräten, stabilem Internet und IT-Unterstützung. Wer deutlich schlechter ausgestattet ist, kann von den Möglichkeiten der KI nicht im gleichen Maße profitieren. Deshalb ist es essenziell, **Ausgleichsmaßnahmen** wie Leihgeräte, Hotspots oder gezielte Beratung anzubieten und diese tatsächlich konsequent in die Einführung von KI-Systemen zu integrieren. Daneben sollten Lehrkräfte und Verwaltungsmitarbeitende regelmäßig überprüfen, ob Gruppen systematisch benachteiligt werden. So kann verhindert werden, dass Technik bestehende Ungleichheiten nicht nur abbildet, sondern verstärkt.

**Zur Transparenz.** Viele KI-Systeme funktionieren nach dem sogenannten **Blackbox-Prinzip**: Man gibt Daten ein und erhält eine Empfehlung oder Entscheidung, aber der Entscheidungsweg bleibt für Nutzerinnen und Nutzer oft im Dunkeln. Das ist zum Beispiel dann problematisch, wenn ein automatisiertes System in der Verwaltung Anfragen von Eltern sortiert und niemand erklären kann, warum ein bestimmter Antrag als dringlich eingestuft wurde. Ähnliche Situationen gibt es auch im Unterricht: Ein Schüler oder eine Schülerin erhält das Feedback, die Antwort sei falsch, aber es gibt keine nachvollziehbare Begründung. Das kann zu Unsicherheiten und Vertrauensverlust führen, sowohl bei den Betroffenen als auch beim Kollegium. Eine Lösung besteht im Einsatz **erklärbarer, sogenannter Explainable-AI-Systeme.** Diese liefern zu ihren Entscheidungen nachvollziehbare Begründungen oder machen die wichtigsten Einflussfaktoren sichtbar. Wo dies nicht möglich ist, empfiehlt sich ein **Monitoring**: Ergebnisse, die plausibel sind, werden übernommen, bei unklaren Empfehlungen greift eine **menschliche Überprüfung**. Transparenz bedeutet nicht, dass jeder Algorithmus im Detail verstanden werden muss. Aber die wichtigsten Kriterien und Entscheidungswege müssen so erklärt werden, dass die Betroffenen sie in Alltagssprache nachvollziehen und kritische Nachfragen stellen können.

**Verantwortung.** Auch wenn Algorithmen heute Vorschläge und sogar Entscheidungen treffen, bleibt die Verantwortung letztlich bei den **Menschen**. Lehrkräfte dürfen die von KI vergebenen Empfehlungen oder Noten nicht ungeprüft übernehmen, sondern sie auf Plausibilität und Förderpotenzial prüfen und korrigieren. In der Schulverwaltung gilt dies gleichermaßen: Eine Software kann etwa Stellenbesetzungen oder Raumbelegungen vorschlagen, doch die Kontrolle über diese Entscheidungen bleibt bei den Menschen, die mit den lokalen Rahmenbedingungen vertraut sind. Dazu gehört auch, dass Prozesse **dokumentiert** werden: Welche Daten wurden wann genutzt, wie kam eine Entscheidung zustande, und wer hat sie letztlich bestätigt oder geändert? Eine solche **Rückverfolgbarkeit**, oft als **Audit-Trail** bezeichnet, macht Fehler aufspürbar und sichert Transparenz für spätere Nachfragen.

Zusammenfassend heißt das: Erstens: **Gerechtigkeit** bedeutet, dass KI niemanden aufgrund von Sprache, Herkunft oder schlechter IT-Ausstattung benachteiligt. Zweitens, **Transparenz** ist Voraussetzung für Vertrauen, weil sie nachvollziehbar macht, wie Entscheidungen entstehen. Drittens: **Verantwortung** heißt, dass am Ende immer Menschen für die Kontrolle und Korrektur von KI-Prozessen zuständig sind und nicht das System selbst. Wenn diese drei Prinzipien konsequent berücksichtigt werden, kann KI ein wertvolles Werkzeug für Schulen und Verwaltungen sein, mit dem Potenziale ausgeschöpft werden, ohne zentrale Werte aufs Spiel zu setzen.

---

### Praxis-Tipps für Gerechtigkeit, Transparenz und Verantwortung

* **Bias-Check im Team:** Erstellen Sie halbjährlich eine einfache Checkliste, mit der Lehrkräfte und Verwaltungsmitarbeitende prüfen, ob ein genutztes KI-System bestimmte Gruppen systematisch benachteiligt. Sammeln Sie Hinweise auf Sprach-, Herkunfts- oder Geschlechterverzerrungen und halten Sie konkrete Korrekturmaßnahmen fest.
* **Geräte- und Hotspot-Pool:** Richten Sie einen schul- oder verwaltungsweiten Pool aus Leihgeräten und mobilen Hotspots ein. Dokumentieren Sie die Ausleihe transparent und priorisieren Sie Lernende oder Kollegien, die sonst keinen stabilen Zugang haben. So mindern Sie den Digital Divide von Beginn an.
* **Transparenz-Protokoll für KI-Entscheidungen:** Verpflichten Sie Anbietende, zu jeder automatisierten Empfehlung eine Kurzbegründung in Alltagssprache bereitzustellen. Ergänzen Sie diese Informationen in einem frei zugänglichen Protokoll, damit Lernende, Eltern und Mitarbeitende jederzeit nachlesen können, wie das System arbeitet.
* **Vier-Augen-Prinzip bei sensiblen Vorschlägen:** Legen Sie fest, dass jede automatisierte Empfehlung mit erheblicher Tragweite, etwa bei der Erstellung eines Vertretungsplans, von einer zweiten Person geprüft wird. So bleibt die letzte Verantwortung eindeutig beim Menschen.
* **Lernende einbinden:** Lassen Sie Schülerinnen und Schüler regelmäßig reflektieren, ob sie die KI-Rückmeldungen nachvollziehen können. Nutzen Sie kurze Umfragen oder Gesprächsrunden und passen Sie die Systeme bei wiederkehrenden Unklarheiten an. Das stärkt Transparenz und Akzeptanz.
* **Glossar verständlicher Kriterien:** Erstellen Sie ein schulinternes Glossar, das zentrale Fachbegriffe erklärt, zum Beispiel „Bias“, „Explainable AI“ oder „Audit Trail“. Hängen Sie das Glossar im Lehrerzimmer und im Verwaltungsbereich aus, damit alle Beteiligten dieselbe Sprache nutzen und Unsicherheiten leichter ansprechen können.
* **Monatliches Dashboard-Monitoring:** Richten Sie ein einfaches Dashboard ein, das anonymisierte Kennzahlen wie Nutzungsraten, Fehlerrückmeldungen und Korrekturen durch Lehrkräfte zeigt. Besprechen Sie die Ergebnisse monatlich im Kollegium, um Probleme früh zu erkennen und gemeinsam Lösungen zu entwickeln.

---

### Potenziale von KI zur Verbesserung des Zugangs zur Bildung und zur Individualisierung des Lernens

In diesem Video widmen wir uns dem **Potenzial** der Künstlichen Intelligenz, den Zugang zur Bildung zu verbessern und Lernen **individuell** zu gestalten und fragen zugleich nach den **Grenzen** dieser Möglichkeiten. Sie erfahren, wie KI Lernprozesse anpassen kann, warum Individualisierung nicht immer automatisch besser ist und welche Rolle die Lehrkraft weiterhin spielt.

Künstliche Intelligenz eröffnet die Chance, Lerninhalte und -methoden auf **einzelne Lernende zuzuschneiden**. Moderne KI-gestützte Plattformen analysieren Stärken und Schwächen in Echtzeit und schlagen passende Aufgaben vor. Wer zum Beispiel beim Üben eines Grammatikthemas Schwierigkeiten zeigt, erhält gezielt zusätzliche Übungen oder Erklärungen. Ebenso profitieren schnelle Lernende, weil sie anspruchsvollere Aufgaben erhalten und so gefordert bleiben. Lehrkräften bietet das die Möglichkeit, **differenzierte Bildungsangebote effizienter** umzusetzen und auch in Klassen mit sehr unterschiedlichen Lernständen stärker auf Einzelne einzugehen.

Das gilt nicht nur für den Unterricht: In der **Verwaltung** kann KI ebenfalls gezielt unterstützen. Beispielsweise können Assistenten Anfragen automatisch vorsortieren oder Problemlagen von Eltern früher erkennen, indem sie eingehende Nachrichten analysieren. So können Verwaltungsmitarbeitende schneller passgenaue Lösungen finden und **entlastet** werden. Auch hier gilt: Die Technik hilft dabei, individuell auf Anliegen einzugehen, und ermöglicht mehr Zeit für das, was wirklich zählt, wie das persönliche Gespräch oder die Beratung.

Allerdings hat jede Innovation auch ihre Grenzen. Individualisierte Lernwege klingen vielversprechend, doch in der Praxis gibt es mehrere Herausforderungen:

**Erstens** besteht die Gefahr, dass Lernende durch KI-Systeme übermäßig in feste Kategorien eingeordnet werden. Das kann dazu führen, dass jemand, der anfangs Schwierigkeiten zeigt, dauerhaft nur leichtere Aufgaben erhält, selbst dann, wenn eigentlich mehr Potenzial vorhanden wäre. Das wird als **„Schubladisierung“** bezeichnet und birgt die Gefahr sich selbst erfüllender Prophezeiungen. Es braucht daher regelmäßig eine Überprüfung durch Lehrkräfte: Entspricht der Lernfortschritt tatsächlich dem vorgeschlagenen Weg? Wie kann ich gezielt Anreize setzen, damit ein Lernender auch anspruchsvollere Aufgaben ausprobiert?

**Zweitens** führt die Personalisierung dazu, dass Lernende in ihrem eigenen Tempo und Stil arbeiten. Das ist grundsätzlich positiv, doch der **soziale Austausch und das gemeinsame Lernen** dürfen dabei nicht verloren gehen. Studien zeigen, dass die Förderung von Kooperation, Diskussion und kreativen Lösungen nach wie vor zentrale Bausteine erfolgreichen Lernens sind. Auch das **Feedback der Lehrkraft** bleibt unersetzbar, denn sie kann motivierend reagieren, Kontext erklären und individuelle Förderung über das hinaus, was Algorithmen leisten können.

Ein **dritter Punkt** sind die technischen und ethischen Rahmenbedingungen: Personalisierung ist nur dann sinnvoll, wenn sie nicht Diskriminierungsrisiken vergrößert. Systeme müssen regelmäßig dahingehend überprüft werden, ob bestimmte Gruppen, zum Beispiel Lernende mit Behinderung oder nicht Muttersprachler, benachteiligt werden. Und auch der **Datenschutz** muss strikt eingehalten werden, da individuelle Lernprofile eine besonders sensible Form von Daten darstellen.

Nicht zuletzt ist eine **kritische Begleitung durch das Kollegium** nötig. KI kann Routineaufgaben erleichtern und als Werkzeug zur Förderung von Lernenden dienen, aber sie ist **kein Ersatz für pädagogisches Gespür, Reflexion und die lebendige Interaktion** im Unterricht oder in der Verwaltung. Schulen und Verwaltungsstellen sollten daher klare Leitlinien zur Nutzung von KI entwickeln: Welche Aufgaben können gut automatisiert werden, wo bleibt der Mensch die entscheidende Instanz? Und wie stellen wir sicher, dass die Förderung tatsächlich individuell, gerecht und unterstützend bleibt?

Zusammengefasst: Die Möglichkeiten der KI zur Individualisierung des Lernens und zur Verbesserung des Zugangs zur Bildung sind groß. Sie können Unterschiede ausgleichen, selbstständiges Lernen fördern und Lehrende entlasten. Gleichzeitig gilt es, die Gefahr einer zu starken **Standardisierung, Diskriminierung oder der Vernachlässigung von sozialem Lernen** im Blick zu behalten.

---

### Praxis-Tipps für die verantwortungsvolle Individualisierung mit KI

* **Kontrollliste „Schubladisierung vermeiden“:** Erstellen Sie eine einfache Tabelle mit den Spalten: Name, empfohlene Aufgabenstufe, händisch überprüft ja/nein, neue Einstufung. Prüfen Sie einmal pro Woche stichprobenartig, ob Lernende dauerhaft auf einer zu niedrigen Stufe festhängen, und passen Sie das Niveau bei Bedarf an.
* **Soziale Lernphasen einplanen:** Legen Sie in jeder Unterrichtseinheit eine feste Zeit fest, in der alle Lernenden ihre individuellen Aufgaben unterbrechen und in Zweier- oder Dreiergruppen über Lösungswege sprechen. So bleibt kooperatives Lernen erhalten.
* **Feedback-Doppelpack:** Kombinieren Sie automatisches KI-Feedback mit einem kurzen Audio-Kommentar der Lehrkraft. Sprechen Sie dabei gezielt Stärken und einen nächsten Lernschritt an. Das erhöht Motivation und verhindert, dass Lernende sich nur auf die Maschinenrückmeldung verlassen.
* **Bias-Monitoring auf Klassen-Ebene:** Exportieren Sie monatlich die anonymisierten Leistungsdaten aus der Lernplattform. Vergleichen Sie Durchschnittswerte nach Merkmalen wie Erst- oder Zweitsprache. Weichen die Ergebnisse stark ab, hinterfragen Sie die Aufgabenauswahl oder passen Sie Förderangebote an.
* **Datenschutz-Reminder:** Hängen Sie im Lehrerzimmer einen A4-Zettel mit drei Prüffragen aus: Werden nur unbedingt nötige Daten erhoben? Sind die Daten verschlüsselt gespeichert? Wissen Lernende, wofür ihre Daten genutzt werden? Stellen Sie sich die Fragen für jede neue Plattform.
* **Klarer Aufgabenfahrplan:** Definieren Sie vor Kursbeginn, welche Arbeitsschritte die KI übernehmen darf (zum Beispiel Übungszuteilung) und welche in menschlicher Hand bleiben (zum Beispiel Notengebung). Halten Sie den Plan schriftlich fest und besprechen Sie ihn im Kollegium.
* **Verwaltungs-Quick-Check:** Für Verwaltungsmitarbeitende: Lassen Sie den KI-Assistenten eingehende Anfragen vorsortieren, aber prüfen Sie täglich die Kategorie „hohe Dringlichkeit“ persönlich nach. Dokumentieren Sie jede Änderung, um den Algorithmus langfristig zu verbessern.
* **Lernprotokolle der Lernenden:** Fordern Sie Lernende auf, einmal pro Woche in zwei Sätzen zu notieren, ob die vorgeschlagenen KI-Aufgaben für sie zu schwer, genau richtig oder zu leicht waren. Nutzen Sie diese Rückmeldungen, um die Systemeinstellungen feinzuzusteuern.

---

### Entwicklung eines ethischen Rahmens für KI im Bildungssystem

In diesem Video geht es darum, wie ein **ethischer Rahmen** für den Einsatz von Künstlicher Intelligenz in Schulen und Bildungseinrichtungen entwickelt werden kann. Dabei richten wir den Blick sowohl auf die Chancen als auch auf die Risiken von KI und fragen, wie sich Prinzipien wie Transparenz, Fairness und Datenschutz in der Praxis umsetzen lassen.

Zunächst zur grundlegenden Frage: **Warum braucht es überhaupt einen ethischen Rahmen für KI?** Die Antwort liegt auf der Hand: Künstliche Intelligenz hat das Potenzial, Bildungsprozesse tiefgreifend zu beeinflussen. Damit sie gerecht, verantwortungsvoll und im Sinne aller Beteiligten eingesetzt werden kann, sind klare **Leitlinien** notwendig. Diese Leitlinien helfen, Orientierung zu schaffen, Unsicherheiten zu reduzieren und das Vertrauen in neue Technologien zu stärken, egal ob im Unterricht oder in der Schulverwaltung.

**Erstlich: Transparenz als Dreh- und Angelpunkt.** Schulen sollten ausschließlich KI-Systeme verwenden, deren Entscheidungsverfahren **nachvollziehbar** sind. Es muss für Lehrkräfte, Verwaltungsmitarbeitende, Eltern und Lernende verständlich sein, auf welcher Grundlage die KI zu einem Ergebnis kommt. Das betrifft sowohl die verwendeten Daten als auch die Bewertungsmaßstäbe und die Art, wie Empfehlungen oder Entscheidungen zustande kommen. Ein praktischer Ansatz ist zum Beispiel, dass jede automatisierte Bewertung eine kurze Begründung liefert oder bei Zweifeln menschlich überprüft wird.

**Zweitens: Fairness und Inklusion müssen gewährleistet sein.** KI darf keinen Lernenden, keine Lehrkraft und keinen Verwaltungsmitarbeitenden systematisch benachteiligen. Dazu ist es notwendig, regelmäßige Tests durchzuführen, ob bestimmte Gruppen bei der Nutzung **diskriminiert** werden, beispielsweise durch sprachliche, soziale oder kulturelle Barrieren. Wo Auffälligkeiten entdeckt werden, müssen Korrekturen erfolgen, beispielsweise durch Anpassung der Trainingsdaten oder durch besondere Fördermaßnahmen für einzelne Gruppen.

**Drittens: Datenschutz und Datensicherheit** gehören zu den wichtigsten Grundpfeilern eines ethischen Rahmens. KI-Systeme im Bildungsbereich arbeiten häufig mit sensiblen personenbezogenen Daten wie Noten, Förderbedarfen oder familiärem Hintergrund. Hier gilt: Alle Daten dürfen ausschließlich im Rahmen der **Datenschutz-Grundverordnung (DSGVO)** verarbeitet werden. Die Nutzerinnen und Nutzer müssen informiert werden, wie ihre Daten verwendet werden, und ihnen muss das Recht eingeräumt werden, diese einzusehen, zu berichtigen oder löschen zu lassen. Schulen und Verwaltungen sind verpflichtet, Anbieter sorgfältig auszuwählen und die Datenverarbeitung transparent und sicher zu gestalten.

**Viertens: Menschliche Aufsicht ist unabdingbar.** Entscheidend ist, dass KI immer ein Werkzeug bleibt und nie allein über Bildungsbiografien oder wichtige Verwaltungsvorgänge entscheidet. Lehrkräfte und Verwaltungsmitarbeitende benötigen Handlungsspielräume, um Entscheidungen der KI zu prüfen, zu bestätigen oder zu korrigieren. Für jede bedeutsame Entscheidung muss klar sein, wer letztlich verantwortlich ist: **Immer der Mensch, nicht die Maschine.**

**Fünftens: Reflexion im Kollegium und in Teams sollte fest etabliert sein.** Einen ethischen Rahmen lebt man nicht, indem man ihn einmal festschreibt, sondern indem regelmäßig geprüft und reflektiert wird, ob die vereinbarten Prinzipien in der Praxis tatsächlich wirken. Dies kann etwa über Fortbildungen, Teamgespräche oder Feedbackrunden geschehen. Ziel ist es, voneinander zu lernen, Unsicherheiten offen zu benennen und gemeinsam Lösungen zu entwickeln.

Abschließend ein Blick in die Zukunft: Die Gestaltung eines ethischen Rahmens für KI in Schulen ist keine einmalige Aufgabe. Sie muss sich mit der Technologie weiterentwickeln und im Schulalltag verankert werden. Wichtig dabei ist Mut zur gemeinsamen Diskussion, Offenheit für Neuerungen und das Bewusstsein, dass **menschliche Werte das Fundament** jeder digitalen Innovation bleiben. Ein klar strukturierter, gemeinsam entwickelter und von allen getragener Kodex schafft die Voraussetzungen dafür, dass KI tatsächlich zum Gewinn für alle wird.


* **Ethik-Workshop starten:** Planen Sie zu Beginn des Schuljahres einen eintägigen Workshop mit Lehrkräften, Verwaltungsmitarbeitenden, Lernenden und Eltern. Ziel ist ein gemeinsam entwickelter Kodex mit klaren Verantwortlichkeiten, der alle Beteiligten einbindet und von Anfang an Akzeptanz schafft.
* **Transparenz-Steckbrief für jedes KI-Tool:** Erstellen Sie pro eingesetztem System ein einseitiges Dokument mit den Punkten Datenquellen, Entscheidungslogik in Alltagssprache, Anwendungszweck, menschliche Kontrollinstanz. Hängen Sie diese Steckbriefe gut sichtbar im Lehrerzimmer und im Verwaltungsbereich aus.
* **Monatlicher Fairness-Test:** Führen Sie einmal im Monat eine Zufallsstichprobe durch: Vergleichen Sie Ergebnisse oder Empfehlungen des KI-Systems für unterschiedliche Lerngruppen. Dokumentieren Sie Auffälligkeiten und leiten Sie bei Bedarf sofortige Anpassungen oder Zusatzförderungen ein.
* **Vier-Augen-Prinzip für kritische Entscheidungen:** Legen Sie verbindlich fest, dass automatisierte Empfehlungen mit hoher Tragweite stets von mindestens einer zweiten Person gegengezeichnet werden. Das sichert Menschliche Aufsicht und schafft Vertrauen.
* **Ethik-Beauftragte bestimmen:** Benennen Sie eine Lehrkraft oder eine Verwaltungsfachkraft, die als zentrale Ansprechperson für Fragen rund um KI, Fairness und Transparenz fungiert. Diese Person sammelt Rückmeldungen, koordiniert Verbesserungen und berichtet zweimal jährlich im Kollegium.
* **Feedback-Runden im Kollegium institutionalisieren:** Reservieren Sie alle acht Wochen zehn Minuten in der Dienstbesprechung für Erfahrungen mit KI-Einsatz: Was lief gut, wo gab es Probleme, welche Anpassungen werden nötig. So bleibt der Rahmen lebendig und passt sich an neue Herausforderungen an.
* **Lernende aktiv einbeziehen:** Richten Sie eine digitale Pinnwand ein, auf der Lernende anonym Rückmeldungen zu KI-Tools geben können. Analysieren Sie diese Rückmeldungen einmal pro Quartal im Schulentwicklungsteam und verwenden Sie sie, um den Kodex weiterzuentwickeln.

---

## Vertiefung

### Vertiefende Informationen zum Thema

* KMK-Handlungsempfehlungen zum Umgang mit KI an Schulen.
* Der Beitrag „Schulische Nutzung von KI-Schreibtools aus Sicht des Datenschutzes“ auf kits.blog.
* Der „Handlungsleitfaden zum Umgang mit textgenerierenden KI-Anwendungen“ des Ministeriums für Schule und Bildung des Landes Nordrhein-Westfalen.
* Der Beitrag „Ambivalenzen generativer KI in Schule und Unterricht“ des Leibniz-Institus für Bildungsmedien | Georg-Eckert-Institut
* Die Folge SMM 054 KI in Bildungsprozessen mit Thomas Iser (MK) und Jörg Steinemann (NLQ) aus dem Podcast „Schule macht Medien“.
* Die deutsche Fassung des EU AI Acts.
* Die UNESCO-Empfehlungen zur Ethik der Künstlichen Intelligenz
* Das „AI Competency Framework for Teachers“ der UNESCO.
* Die Handreichung zum Stand in Wissenschaft und Praxis „Künstliche Intelligenz in der Schule“ des BMBF als Teile des Begleitprozesses „Künstliche Intelligenz im Bildungsbereich“
* Der Beitrag von Axel Krommer „Paradigmen und palliative Didaktik. Oder: Wie Medien Wissen und Lernen prägen.“
* Die „Zukunftsstudie: Leben, Arbeit, Bildung 2035+“ der Bertelsmannstiftung ist mit Herausgabe in 2020 schon vergleichsweise alt, gibt aber interessante Einblicke, welche Fragen damals gestellt und eingeordnet wurden und wie die Entwicklungen bis heute tatsächlich vorangeschritten sind.

---

## Transferaufgaben

### Selbstreflexion [SR]

Verfassen Sie ein kurzes Protokoll (maximal eine Seite), in dem Sie drei konkrete Situationen aus Ihrem Unterrichts- oder Verwaltungsalltag beschreiben, in denen derzeit bereits Künstliche Intelligenz eingesetzt wird oder künftig eingesetzt werden könnte.

Analysieren Sie für jede Situation, ob die folgenden drei ethischen Prinzipien ausreichend erfüllt sind:

* **Gerechtigkeit und Chancengleichheit** – werden Lernende, Lehrkräfte oder Mitarbeitende benachteiligt oder bevorzugt?
* **Transparenz und Nachvollziehbarkeit** – ist für alle Betroffenen verständlich, wie die Entscheidung der Künstlichen Intelligenz zustande kommt?
* **Verantwortung und Kontrolle** – wer trägt letztlich die Entscheidung und überprüft die Ergebnisse?

Schließen Sie Ihr Protokoll mit zwei bis drei Sätzen ab, in denen Sie zusammenfassen, welche Prinzipien in Ihrem Arbeitskontext am stärksten gestärkt oder verbessert werden müssen.

### Transferaufgabe [TA]

**Beachten Sie:** Die Nutzung von KI-Tools in Ihrem Arbeitsalltag ist im Vorfeld vom Datenschutzbeauftragten zu prüfen. Grundsätzlich dürfen keine personenbezogenen oder personenbeziehbaren Daten in KI eingegeben werden.

Planen Sie ein kleines Pilotprojekt für Ihre Schule oder Verwaltung, in dem Sie eine Anwendung auf Basis von Künstlicher Intelligenz gezielt erproben.

Wählen Sie ein konkretes Werkzeug aus und beschreiben Sie in höchstens zehn Stichpunkten:

* den geplanten Einsatz (Unterrichtseinheit oder Verwaltungsprozess),
* die pädagogischen oder organisatorischen Ziele,
* die notwendigen Rahmenbedingungen (zum Beispiel Endgeräte, Schulung, Datenschutz),
* die Kriterien, mit denen Sie den Erfolg des Pilotprojekts evaluieren (zum Beispiel Lernfortschritt, Zeitersparnis, Zufriedenheit der Beteiligten),
* die Maßnahmen, mit denen Sie Gerechtigkeit, Transparenz und Verantwortung während der Pilotphase sichern.

Bereiten Sie Ihre Ergebnisse so auf, dass sie im Kollegium vorgestellt und gemeinsam weiterentwickelt werden können.

---

## Zusammenfassung & Glossar

### Zusammenfassung

In diesem Modul werden praxisnahe Strategien vorgestellt, wie Schulen und Schulverwaltungen Künstliche Intelligenz **verantwortungsvoll** einsetzen können. Die vier Videos bieten einen verständlichen und klar strukturierten Überblick über die **ethischen Dimensionen** von KI und richten sich an Lehrkräfte, pädagogische Fachkräfte sowie Mitarbeitende in der Schulverwaltung.

1.  Das erste Video führt in das Thema ein und erläutert, warum ein ethischer Blick auf KI notwendig ist. Es stellt die fünf zentralen Prinzipien, **Gerechtigkeit, Transparenz, Verantwortung, Individualisierung und Datenschutz**, vor und zeigt auf, welche Fragen sich daraus für den schulischen Alltag ergeben.
2.  Im zweiten Video liegt der Fokus auf **Grenzen und Risiken**. Anhand konkreter Beispiele wird erklärt, wie **Bias, Digital Divide** und fehlende Nachvollziehbarkeit entstehen können und welche Maßnahmen helfen, diese Probleme zu vermeiden.
3.  Das dritte Video beleuchtet die **Potenziale** der KI für personalisierte Lernwege und effiziente Verwaltungsprozesse. Es zeigt, wie adaptive Plattformen Lernfortschritte analysieren, warum **menschliches Feedback** unverzichtbar bleibt und welche Rolle kooperative Lernformen weiterhin spielen.
4.  Im vierten Video geht es um die Entwicklung eines **ethischen Rahmens**. Es wird dargestellt, wie Schulen Transparenz-Steckbriefe, Fairness-Checks und Datenschutzrichtlinien etablieren, **menschliche Aufsicht** sichern und Reflexionsprozesse im Kollegium verankern können.

Dieses Modul macht deutlich: Künstliche Intelligenz kann Bildungsprozesse bereichern und Abläufe erleichtern, wenn sie entlang klarer ethischer Leitlinien eingeführt, regelmäßig überprüft und von allen Beteiligten kritisch reflektiert wird.

### Glossar

Hier finden Sie unser Glossar zum Thema: Glossar KI

---

## Anschlüsse

## Testen Sie Ihr Vorwissen

---

## Abspann

### KI-Transparenzhinweis

Wir praktizieren, was wir lehren! Dieses Lernangebot wurde bewusst mit KI-Technologien entwickelt – als lebendiges Beispiel für die Möglichkeiten moderner künstlicher Intelligenz. Unsere KI-Assistenten waren unsere Co-Kreativen:
* Perplexity AI gestaltete Struktur und Inhalte
* Gemini und NotebookLM recherchierte unterstützende Quellen
* ChatGPT schrieb Textentwürfe
* DeepL verfeinerte die Sprache

So zeigen wir: KI ist mehr als eine Technologie – sie ist ein mächtiges Werkzeug für Kreativität und Wissensarbeit. Eines bleibt dabei unverrückbar: Die menschliche Expertise und Verantwortung bilden die Grundlage.

### Letzte Aktualisierung

Dieses Lernangebot wurde im September 2025 fertiggestellt und ist danach nicht mehr aktualisiert worden. Es liegt in der Natur des Internets, dass Webangebote und Links sich verändern oder nicht mehr verfügbar sind. Insofern bitten wir um Nachsicht, falls ein genanntes und/oder verlinktes Angebot nicht mehr erreichbar ist oder sich verändert hat.

### Kontakt

Wenn Sie eine Frage oder eine Rückmeldung zu diesem Lernangebot haben, freuen wir uns, wenn Sie uns im Forum oder Christian Haake über christian.haake@nlq.niedersachsen.de, Tel. +49 5121 1695151‬ kontaktieren.

### Team

Verantwortlich seitens des NLQ: Christian Haake und Jörg Steinemann
Fachliche Beratung: Stephanie Aboueme Aboueme
Konzeption, Redaktion: Jöran Muuß-Merholz, Blanche Fabri, Nicole Hagen, Frank Homp, Tessa Moje der Agentur J&K – Jöran und Konsorten
Gesamtleitung: Blanche Fabri, Agentur J&K – Jöran und Konsorten
Mitarbeit: Jula Henke, Pascal Fieseler, Ben Paetzold der Agentur J&K – Jöran und Konsorten

### Downloads

Die Materialien dieses Kurses finden Sie zum Download in GitHub.

### Lizenzhinweise

Dieses Angebot ist frei lizenziert und im Sinne von Open Educational Resources (OER) offen zur weiteren Verwendung, Veränderung, Weitergabe etc. Als Gesamtwerk steht er unter der Lizenz CC BY 4.0. Details zu dieser Lizenz finden Sie hier in Kurzform und hier ausführlich. Als Namensnennung im Sinne der Lizenz ist vorgesehen: „Agentur J&K – Jöran und Konsorten im Auftrag des Niedersächsischen Landesinstituts für schulische Qualitätsentwicklung (NLQ Hildesheim)“.

Einzelne Elemente des Angebots, zum Beispiel Abbildungen, Videos, Texte, können eigenständig unter anderen Lizenzbedingungen freigegeben sein, auch durch Dritte. In diesen Fällen ist dies im oder am jeweiligen Element angegeben.

Screenshots und Screencasts werden im Sinne von Bildzitaten und/oder in der Annahme genutzt, dass die abgebildeten Inhalte keinen urheberrechtlichen Schutz beanspruchen können. Die darin abgebildeten Inhalte / Programme stehen i.d.R. nicht unter freier Lizenz und können nur weiterverwendet werden, solange sie im Sinne von Bildzitaten genutzt werden. Abgebildete Logos, Marken etc. stehen nicht unter freier Lizenz und sind unter Umständen zudem markenrechtlich geschützt.

---

## Fließtext

### Video 1: Einführung – Ethische Fragen an KI in der Bildung

Dieses Video ist eine Einführung zu folgender Frage: Welche ethischen Überlegungen spielen eine Rolle, wenn Künstliche Intelligenz in der Bildung, sowohl im Unterricht als auch in der Verwaltung, eingesetzt wird?

Wir starten mit einem Gedankenexperiment: Stellen Sie sich vor, eine Schule setzt eine Anwendung auf Basis künstlicher Intelligenz ein, die den Lernenden täglich individuelle Übungsaufgaben zusammenstellt. Nach einigen Monaten bemerkt das Kollegium, dass Lernende mit nicht-deutscher Muttersprache fast ausschließlich einfache Lückentexte erhalten, während ihre Mitschülerinnen und Mitschüler eine breite Auswahl an anspruchsvolleren Aufgaben bekommen. Was als hilfreiche Unterstützung gedacht war, wirft plötzlich grundlegende Fragen auf: Wer trägt die Verantwortung für diese Entscheidung? War sie gerecht? Und wie transparent war der Empfehlungsprozess eigentlich?

Eine solche Situation zeigt, dass Künstliche Intelligenz nicht nur eine Frage der Technik ist. Sie betrifft zentrale Werte: **Fairness, Verantwortung, Chancengleichheit und Transparenz.**

In diesem Video erhalten Sie einen Überblick über die wichtigsten ethischen Aspekte beim Einsatz von KI in Schule und Verwaltung. Dabei geht es nicht um technische Details, sondern um grundlegende Überlegungen, die für einen verantwortungsvollen Umgang mit KI notwendig sind.

**Erstlich: Gerechtigkeit und Chancengleichheit.** Künstliche Intelligenz kann Lernprozesse personalisieren, riskiert aber Benachteiligungen, wenn Daten oder digitale Ausstattung unausgewogen sind. Schulen sollen Systeme regelmäßig auf Verzerrungen prüfen und fehlende Ressourcen durch gezielte Förderprogramme ausgleichen.

**Zweitens: Transparenz und Nachvollziehbarkeit.** Die Entscheidungswege vieler Modelle bleiben verborgen. Erklärbare Künstliche Intelligenz und menschliche Kontrolle schaffen Vertrauen, weil sie Gründe offenlegen und Korrekturen ermöglichen.

**Drittens: Verantwortung und Kontrolle.** Künstliche Intelligenz darf nur Empfehlungen geben, die Entscheidung treffen Menschen. Lehrkräfte und Verwaltung prüfen Ergebnisse, dokumentieren den Prozess und greifen bei Fehlern ein.

**Viertens: Individualisierung versus Standardisierung.** Adaptive Systeme fördern individuelles Lernen, dürfen Schülerinnen und Schüler aber nicht festlegen. Pädagogische Begleitung und regelmäßige Überprüfung verhindern Schubladisierung und bewahren gemeinsame Lernphasen.

**Fünftens: Datenschutz und ethische Leitlinien.** Daten von Lernenden sind sensibel. Sie dürfen nur sparsam und gemäß der Datenschutz-Grundverordnung verarbeitet werden, mit klaren Zugriffsrechten und konsequenter Anonymisierung.

Der reflektierte Einsatz von KI im Bildungskontext erfordert die konsequente Beachtung von **Gerechtigkeit, Transparenz, Verantwortlichkeit, gewissenhafter Individualisierung und striktem Datenschutz.** Diese Leitprinzipien müssen von Anbeginn in Entwicklung, Auswahl, Einführung und laufende Nutzung von KI-Systemen eingebettet werden, damit der technologische Fortschritt auch ethisch verantwortbar bleibt.

### Video 2: Gerechtigkeit, Transparenz und Verantwortung – drei ethische Grundpfeiler

Im zweiten Video geht es um die ethischen Grenzen beim Einsatz von Künstlicher Intelligenz in Schule und Verwaltung. Im Zentrum stehen die Fragen nach **Gerechtigkeit, Transparenz und Verantwortung.** Ziel ist es, anhand konkreter Beispiele und mit Blick auf beide Bereiche Herausforderungen, Risiken und Gestaltungsspielräume verständlich darzustellen.

Beginnen wir mit dem Thema **Gerechtigkeit und Chancengleichheit.** Ein KI-gestütztes System kann etwa Lernende automatisch in Leistungsgruppen einteilen oder Verwaltungsentscheidungen vorschlagen. Im ersten Moment wirkt das effizient und unvoreingenommen. Kritisch wird es jedoch, wenn die Datenbasis, Stichwort **Bias**, nicht ausgewogen ist. Zum Beispiel können Lernende mit Deutsch als Zweitsprache benachteiligt werden, wenn die KI auf Mustern basiert, die überwiegend an Muttersprachlerinnen und Muttersprachlern erlernt wurden. Ein anderer wichtiger Punkt ist der sogenannte **Digital Divide**: Nicht alle Schülerinnen und Schüler, aber auch nicht alle Kollegien und Verwaltungsmitarbeitende verfügen über gleich guten Zugang zu Endgeräten, stabilem Internet und IT-Unterstützung. Wer deutlich schlechter ausgestattet ist, kann von den Möglichkeiten der KI nicht im gleichen Maße profitieren. Deshalb ist es essenziell, Ausgleichsmaßnahmen wie Leihgeräte, Hotspots oder gezielte Beratung anzubieten und diese tatsächlich konsequent in die Einführung von KI-Systemen zu integrieren. Daneben sollten Lehrkräfte und Verwaltungsmitarbeitende regelmäßig überprüfen, ob Gruppen systematisch benachteiligt werden. So kann verhindert werden, dass Technik bestehende Ungleichheiten nicht nur abbildet, sondern verstärkt.

Zur **Transparenz.** Viele KI-Systeme funktionieren nach dem sogenannten **Blackbox-Prinzip**: Man gibt Daten ein und erhält eine Empfehlung oder Entscheidung, aber der Entscheidungsweg bleibt für Nutzerinnen und Nutzer oft im Dunkeln. Das ist zum Beispiel dann problematisch, wenn ein automatisiertes System in der Verwaltung Anfragen von Eltern sortiert und niemand erklären kann, warum ein bestimmter Antrag als dringlich eingestuft wurde. Ähnliche Situationen gibt es auch im Unterricht: Ein Schüler oder eine Schülerin erhält das Feedback, die Antwort sei falsch, aber es gibt keine nachvollziehbare Begründung. Das kann zu Unsicherheiten und Vertrauensverlust führen, sowohl bei den Betroffenen als auch beim Kollegium. Eine Lösung besteht im Einsatz **erklärbarer, sogenannter Explainable-AI-Systeme.** Diese liefern zu ihren Entscheidungen nachvollziehbare Begründungen oder machen die wichtigsten Einflussfaktoren sichtbar. Wo dies nicht möglich ist, empfiehlt sich ein **Monitoring**: Ergebnisse, die plausibel sind, werden übernommen, bei unklaren Empfehlungen greift eine **menschliche Überprüfung.** Transparenz bedeutet nicht, dass jeder Algorithmus im Detail verstanden werden muss. Aber die wichtigsten Kriterien und Entscheidungswege müssen so erklärt werden, dass die Betroffenen sie in Alltagssprache nachvollziehen und kritische Nachfragen stellen können.

**Verantwortung.** Auch wenn Algorithmen heute Vorschläge und sogar Entscheidungen treffen, bleibt die Verantwortung letztlich bei den **Menschen.** Lehrkräfte dürfen die von KI vergebenen Empfehlungen oder Noten nicht ungeprüft übernehmen, sondern sie auf Plausibilität und Förderpotenzial prüfen und korrigieren. In der Schulverwaltung gilt dies gleichermaßen: Eine Software kann etwa Stellenbesetzungen oder Raumbelegungen vorschlagen, doch die Kontrolle über diese Entscheidungen bleibt bei den Menschen, die mit den lokalen Rahmenbedingungen vertraut sind. Dazu gehört auch, dass Prozesse **dokumentiert** werden: Welche Daten wurden wann genutzt, wie kam eine Entscheidung zustande, und wer hat sie letztlich bestätigt oder geändert? Eine solche **Rückverfolgbarkeit**, oft als **Audit-Trail** bezeichnet, macht Fehler aufspürbar und sichert Transparenz für spätere Nachfragen.

Zusammenfassend heißt das: Erstens: **Gerechtigkeit** bedeutet, dass KI niemanden aufgrund von Sprache, Herkunft oder schlechter IT-Ausstattung benachteiligt. Zweitens, **Transparenz** ist Voraussetzung für Vertrauen, weil sie nachvollziehbar macht, wie Entscheidungen entstehen. Drittens: **Verantwortung** heißt, dass am Ende immer Menschen für die Kontrolle und Korrektur von KI-Prozessen zuständig sind und nicht das System selbst. Wenn diese drei Prinzipien konsequent berücksichtigt werden, kann KI ein wertvolles Werkzeug für Schulen und Verwaltungen sein, mit dem Potenziale ausgeschöpft werden, ohne zentrale Werte aufs Spiel zu setzen.

### Video 3: Exploration des Potenzials von KI zur Verbesserung des Zugangs zur Bildung, zur Individualisierung des Lernens

Im dritten Video widmen wir uns dem **Potenzial** der Künstlichen Intelligenz, den Zugang zur Bildung zu verbessern und Lernen **individuell** zu gestalten und fragen zugleich nach den **Grenzen** dieser Möglichkeiten. Sie erfahren, wie KI Lernprozesse anpassen kann, warum Individualisierung nicht immer automatisch besser ist und welche Rolle die Lehrkraft weiterhin spielt.

Künstliche Intelligenz eröffnet die Chance, Lerninhalte und -methoden auf **einzelne Lernende zuzuschneiden.** Moderne KI-gestützte Plattformen analysieren Stärken und Schwächen in Echtzeit und schlagen passende Aufgaben vor. Wer zum Beispiel beim Üben eines Grammatikthemas Schwierigkeiten zeigt, erhält gezielt zusätzliche Übungen oder Erklärungen. Ebenso profitieren schnelle Lernende, weil sie anspruchsvollere Aufgaben erhalten und so gefordert bleiben. Lehrkräften bietet das die Möglichkeit, **differenzierte Bildungsangebote effizienter** umzusetzen und auch in Klassen mit sehr unterschiedlichen Lernständen stärker auf Einzelne einzugehen.

Das gilt nicht nur für den Unterricht: In der **Verwaltung** kann KI ebenfalls gezielt unterstützen. Beispielsweise können Assistenten Anfragen automatisch vorsortieren oder Problemlagen von Eltern früher erkennen, indem sie eingehende Nachrichten analysieren. So können Verwaltungsmitarbeitende schneller passgenaue Lösungen finden und **entlastet** werden. Auch hier gilt: Die Technik hilft dabei, individuell auf Anliegen einzugehen, und ermöglicht mehr Zeit für das, was wirklich zählt, wie das persönliche Gespräch oder die Beratung.

Allerdings hat jede Innovation auch ihre Grenzen. Individualisierte Lernwege klingen vielversprechend, doch in der Praxis gibt es mehrere Herausforderungen:

**Erstlich** besteht die Gefahr, dass Lernende durch KI-Systeme übermäßig in feste Kategorien eingeordnet werden. Das kann dazu führen, dass jemand, der anfangs Schwierigkeiten zeigt, dauerhaft nur leichtere Aufgaben erhält, selbst dann, wenn eigentlich mehr Potenzial vorhanden wäre. Das wird als **„Schubladisierung“** bezeichnet und birgt die Gefahr sich selbst erfüllender Prophezeiungen. Es braucht daher regelmäßig eine Überprüfung durch Lehrkräfte: Entspricht der Lernfortschritt tatsächlich dem vorgeschlagenen Weg? Wie kann ich gezielt Anreize setzen, damit ein Lernender auch anspruchsvollere Aufgaben ausprobiert?

**Zweitens** führt die Personalisierung dazu, dass Lernende in ihrem eigenen Tempo und Stil arbeiten. Das ist grundsätzlich positiv, doch der **soziale Austausch und das gemeinsame Lernen** dürfen dabei nicht verloren gehen. Studien zeigen, dass die Förderung von Kooperation, Diskussion und kreativen Lösungen nach wie vor zentrale Bausteine erfolgreichen Lernens sind. Auch das **Feedback der Lehrkraft** bleibt unersetzbar, denn sie kann motivierend reagieren, Kontext erklären und individuelle Förderung über das hinaus, was Algorithmen leisten können.

Ein **dritter Punkt** sind die technischen und ethischen Rahmenbedingungen: Personalisierung ist nur dann sinnvoll, wenn sie nicht Diskriminierungsrisiken vergrößert. Systeme müssen regelmäßig dahingehend überprüft werden, ob bestimmte Gruppen, zum Beispiel Lernende mit Behinderung oder nicht Muttersprachler, benachteiligt werden. Und auch der **Datenschutz** muss strikt eingehalten werden, da individuelle Lernprofile eine besonders sensible Form von Daten darstellen.

Nicht zuletzt ist eine **kritische Begleitung durch das Kollegium** nötig. KI kann Routineaufgaben erleichtern und als Werkzeug zur Förderung von Lernenden dienen, aber sie ist **kein Ersatz für pädagogisches Gespür, Reflexion und die lebendige Interaktion** im Unterricht oder in der Verwaltung. Schulen und Verwaltungsstellen sollten daher klare Leitlinien zur Nutzung von KI entwickeln: Welche Aufgaben können gut automatisiert werden, wo bleibt der Mensch die entscheidende Instanz? Und wie stellen wir sicher, dass die Förderung tatsächlich individuell, gerecht und unterstützend bleibt?

Zusammengefasst: Die Möglichkeiten der KI zur Individualisierung des Lernens und zur Verbesserung des Zugangs zur Bildung sind groß. Sie können Unterschiede ausgleichen, selbstständiges Lernen fördern und Lehrende entlasten. Gleichzeitig gilt es, die Gefahr einer zu starken **Standardisierung, Diskriminierung oder der Vernachlässigung von sozialem Lernen** im Blick zu behalten.

### Video 4: Entwicklung eines ethischen Rahmens für den Einsatz von KI in Bildungseinrichtungen, der sowohl die Möglichkeiten als auch die Risiken berücksichtigt.

In diesem Video geht es darum, wie ein **ethischer Rahmen** für den Einsatz von Künstlicher Intelligenz in Schulen und Bildungseinrichtungen entwickelt werden kann. Dabei richten wir den Blick sowohl auf die Chancen als auch auf die Risiken von KI und fragen, wie sich Prinzipien wie Transparenz, Fairness und Datenschutz in der Praxis umsetzen lassen.

Zunächst zur grundlegenden Frage: **Warum braucht es überhaupt einen ethischen Rahmen für KI?** Die Antwort liegt auf der Hand: Künstliche Intelligenz hat das Potenzial, Bildungsprozesse tiefgreifend zu beeinflussen. Damit sie gerecht, verantwortungsvoll und im Sinne aller Beteiligten eingesetzt werden kann, sind klare **Leitlinien** notwendig. Diese Leitlinien helfen, Orientierung zu schaffen, Unsicherheiten zu reduzieren und das Vertrauen in neue Technologien zu stärken, egal ob im Unterricht oder in der Schulverwaltung.

**Erstlich: Transparenz als Dreh- und Angelpunkt.** Schulen sollten ausschließlich KI-Systeme verwenden, deren Entscheidungsverfahren **nachvollziehbar** sind. Es muss für Lehrkräfte, Verwaltungsmitarbeitende, Eltern und Lernende verständlich sein, auf welcher Grundlage die KI zu einem Ergebnis kommt. Das betrifft sowohl die verwendeten Daten als auch die Bewertungsmaßstäbe und die Art, wie Empfehlungen oder Entscheidungen zustande kommen. Ein praktischer Ansatz ist zum Beispiel, dass jede automatisierte Bewertung eine kurze Begründung liefert oder bei Zweifeln menschlich überprüft wird.

**Zweitens: Fairness und Inklusion müssen gewährleistet sein.** KI darf keinen Lernenden, keine Lehrkraft und keinen Verwaltungsmitarbeitenden systematisch benachteiligen. Dazu ist es notwendig, regelmäßige Tests durchzuführen, ob bestimmte Gruppen bei der Nutzung **diskriminiert** werden, beispielsweise durch sprachliche, soziale oder kulturelle Barrieren. Wo Auffälligkeiten entdeckt werden, müssen Korrekturen erfolgen, beispielsweise durch Anpassung der Trainingsdaten oder durch besondere Fördermaßnahmen für einzelne Gruppen.

**Drittens: Datenschutz und Datensicherheit** gehören zu den wichtigsten Grundpfeilern eines ethischen Rahmens. KI-Systeme im Bildungsbereich arbeiten häufig mit sensiblen personenbezogenen Daten wie Noten, Förderbedarfen oder familiärem Hintergrund. Hier gilt: Alle Daten dürfen ausschließlich im Rahmen der **Datenschutz-Grundverordnung (DSGVO)** verarbeitet werden. Die Nutzerinnen und Nutzer müssen informiert werden, wie ihre Daten verwendet werden, und ihnen muss das Recht eingeräumt werden, diese einzusehen, zu berichtigen oder löschen zu lassen. Schulen und Verwaltungen sind verpflichtet, Anbieter sorgfältig auszuwählen und die Datenverarbeitung transparent und sicher zu gestalten.

**Viertens: Menschliche Aufsicht ist unabdingbar.** Entscheidend ist, dass KI immer ein Werkzeug bleibt und nie allein über Bildungsbiografien oder wichtige Verwaltungsvorgänge entscheidet. Lehrkräfte und Verwaltungsmitarbeitende benötigen Handlungsspielräume, um Entscheidungen der KI zu prüfen, zu bestätigen oder zu korrigieren. Für jede bedeutsame Entscheidung muss klar sein, wer letztlich verantwortlich ist: **Immer der Mensch, nicht die Maschine.**

**Fünftens: Reflexion im Kollegium und in Teams sollte fest etabliert sein.** Einen ethischen Rahmen lebt man nicht, indem man ihn einmal festschreibt, sondern indem regelmäßig geprüft und reflektiert wird, ob die vereinbarten Prinzipien in der Praxis tatsächlich wirken. Dies kann etwa über Fortbildungen, Teamgespräche oder Feedbackrunden geschehen. Ziel ist es, voneinander zu lernen, Unsicherheiten offen zu benennen und gemeinsam Lösungen zu entwickeln.

Abschließend ein Blick in die Zukunft: Die Gestaltung eines ethischen Rahmens für KI in Schulen ist keine einmalige Aufgabe. Sie muss sich mit der Technologie weiterentwickeln und im Schulalltag verankert werden. Wichtig dabei ist Mut zur gemeinsamen Diskussion, Offenheit für Neuerungen und das Bewusstsein, dass **menschliche Werte das Fundament** jeder digitalen Innovation bleiben. Ein klar strukturierter, gemeinsam entwickelter und von allen getragener Kodex schafft die Voraussetzungen dafür, dass KI tatsächlich zum Gewinn für alle wird.

---