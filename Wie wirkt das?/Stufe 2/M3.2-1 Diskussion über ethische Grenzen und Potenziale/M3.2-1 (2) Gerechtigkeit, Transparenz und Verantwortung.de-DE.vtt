WEBVTT

1
00:00:06.480 --> 00:00:08.680
In diesem Video geht es um die ethischen

2
00:00:08.680 --> 00:00:10.920
Grenzen beim Einsatz von Künstlicher

3
00:00:10.920 --> 00:00:13.200
Intelligenz in Schule und Verwaltung.

4
00:00:13.760 --> 00:00:15.760
Im Zentrum stehen die Fragen

5
00:00:15.760 --> 00:00:17.200
nach Gerechtigkeit,

6
00:00:17.200 --> 00:00:19.200
Transparenz und Verantwortung.

7
00:00:22.400 --> 00:00:23.920
Beginnen wir mit dem Thema

8
00:00:23.920 --> 00:00:26.160
Gerechtigkeit und Chancengleichheit.

9
00:00:26.930 --> 00:00:29.410
Ein KI gestütztes System kann etwa

10
00:00:29.410 --> 00:00:31.170
Lernende automatisch in

11
00:00:31.170 --> 00:00:33.290
Leistungsgruppen einteilen oder

12
00:00:33.290 --> 00:00:35.730
Verwaltungsentscheidungen vorschlagen.

13
00:00:35.730 --> 00:00:37.570
Im ersten Moment wirkt das

14
00:00:37.570 --> 00:00:40.050
effizient und unvoreingenommen.

15
00:00:40.050 --> 00:00:41.890
Kritisch wird es jedoch, wenn

16
00:00:41.890 --> 00:00:44.610
die Datenbasis Stichwort Bias

17
00:00:44.610 --> 00:00:45.970
nicht ausgewogen ist.

18
00:00:46.610 --> 00:00:48.810
Zum Beispiel können Lernende mit Deutsch

19
00:00:48.810 --> 00:00:51.330
als Zweitsprache benachteiligt werden,

20
00:00:51.330 --> 00:00:53.900
wenn die KI auf Mustern basiert,

21
00:00:53.900 --> 00:00:56.380
die überwiegend an Muttersprachlerinnen

22
00:00:56.380 --> 00:00:59.340
und Muttersprachlern erlernt wurden.

23
00:00:59.340 --> 00:01:01.220
Ein anderer wichtiger Punkt ist

24
00:01:01.220 --> 00:01:03.900
der sogenannte Digital Divide.

25
00:01:03.900 --> 00:01:06.140
Nicht alle Schülerinnen und Schüler,

26
00:01:06.140 --> 00:01:08.180
aber auch nicht alle Kollegien und

27
00:01:08.180 --> 00:01:10.500
Verwaltungsmitarbeitende verfügen über

28
00:01:10.500 --> 00:01:13.220
gleich guten Zugang zu Endgeräten,

29
00:01:13.220 --> 00:01:16.060
stabilem Internet und IT Unterstützung.

30
00:01:16.620 --> 00:01:18.860
Wer deutlich schlechter ausgestattet ist,

31
00:01:19.510 --> 00:01:21.270
kann von den Möglichkeiten der KI

32
00:01:21.270 --> 00:01:23.110
nicht im gleichen Maße profitieren.

33
00:01:23.830 --> 00:01:25.750
Deshalb ist es essentiell,

34
00:01:25.750 --> 00:01:28.270
Ausgleichsmaßnahmen wie Leihgeräte,

35
00:01:28.270 --> 00:01:30.550
Hotspots oder gezielte Beratung

36
00:01:30.550 --> 00:01:32.670
anzubieten und diese tatsächlich

37
00:01:32.670 --> 00:01:34.390
konsequent in die Einführung von

38
00:01:34.390 --> 00:01:36.230
KI Systemen zu integrieren.

39
00:01:37.030 --> 00:01:38.910
Daneben sollten Lehrkräfte und

40
00:01:38.910 --> 00:01:41.110
Verwaltungsmitarbeitende regelmäßig

41
00:01:41.110 --> 00:01:42.830
überprüfen, ob Gruppen

42
00:01:42.830 --> 00:01:44.470
systematisch benachteiligt werden.

43
00:01:45.200 --> 00:01:47.280
So kann verhindert werden, dass Technik

44
00:01:47.280 --> 00:01:48.880
bestehende Ungleichheiten nicht

45
00:01:48.880 --> 00:01:51.299
nur abbildet, sondern verstärkt.

46
00:01:53.933 --> 00:01:54.960
Zur Transparenz:

47
00:01:54.960 --> 00:01:57.000
Viele KI-Systeme funktionieren nach

48
00:01:57.000 --> 00:01:59.360
dem sogenannten Blackbox-Prinzip.

49
00:01:59.360 --> 00:02:01.720
Man gibt Daten ein und erhält eine

50
00:02:01.720 --> 00:02:03.520
Empfehlung oder Entscheidung,

51
00:02:03.520 --> 00:02:05.400
aber der Entscheidungsweg bleibt für

52
00:02:05.400 --> 00:02:08.320
Nutzerinnen und Nutzer oft im Dunkeln.

53
00:02:08.320 --> 00:02:09.680
Das ist zum Beispiel dann

54
00:02:09.680 --> 00:02:11.240
problematisch, wenn ein

55
00:02:11.240 --> 00:02:13.160
automatisiertes System in der

56
00:02:13.160 --> 00:02:14.760
Verwaltung Anfragen von Eltern

57
00:02:14.760 --> 00:02:17.040
sortiert und niemand erklären kann,

58
00:02:17.040 --> 00:02:18.960
warum ein bestimmter Antrag als

59
00:02:18.960 --> 00:02:20.560
dringlich eingestuft wurde.

60
00:02:21.120 --> 00:02:23.520
Ähnliche Situationen gibt es auch im Unterricht.

61
00:02:24.480 --> 00:02:26.560
Ein Schüler oder eine Schülerin

62
00:02:26.560 --> 00:02:28.440
erhält das Feedback, die Antwort

63
00:02:28.440 --> 00:02:30.280
sei falsch, aber es gibt keine

64
00:02:30.280 --> 00:02:32.480
nachvollziehbare Begründung.

65
00:02:32.480 --> 00:02:34.280
Das kann zu Unsicherheiten und

66
00:02:34.280 --> 00:02:36.800
Vertrauensverlust führen, sowohl bei den

67
00:02:36.800 --> 00:02:39.630
Betroffenen als als auch beim Kollegium.

68
00:02:39.630 --> 00:02:40.990
Eine Lösung besteht im

69
00:02:40.990 --> 00:02:43.710
Einsatz erklärbarer sogenannter

70
00:02:43.710 --> 00:02:46.590
Explainable AI Systeme.

71
00:02:46.590 --> 00:02:48.390
Diese liefern zu ihren Entscheidungen

72
00:02:48.390 --> 00:02:50.350
nachvollziehbare Begründungen

73
00:02:50.350 --> 00:02:51.870
oder machen die wichtigsten

74
00:02:51.870 --> 00:02:54.030
Einflussfaktoren sichtbar.

75
00:02:54.030 --> 00:02:55.710
Wo dies nicht möglich ist,

76
00:02:55.710 --> 00:02:57.950
empfiehlt sich ein Monitoring.

77
00:02:57.950 --> 00:03:00.270
Bei den KI gestützten Empfehlungen

78
00:03:00.270 --> 00:03:01.910
muss eine Überprüfung durch

79
00:03:01.910 --> 00:03:03.070
einen Menschen stattfinden.

80
00:03:03.740 --> 00:03:05.180
Nur so können Ergebnisse

81
00:03:05.180 --> 00:03:07.420
verantwortungsvoll übernommen werden.

82
00:03:07.420 --> 00:03:09.820
Transparenz bedeutet nicht, dass jeder

83
00:03:09.820 --> 00:03:11.740
Algorithmus im Detail verstanden

84
00:03:11.740 --> 00:03:13.660
werden muss, aber die wichtigsten

85
00:03:13.660 --> 00:03:15.860
Kriterien und Entscheidungswege

86
00:03:15.860 --> 00:03:17.900
müssen so erklärt werden, dass die

87
00:03:17.900 --> 00:03:20.300
Betroffenen sie in Alltagssprache

88
00:03:20.300 --> 00:03:22.100
nachvollziehen und kritische

89
00:03:22.100 --> 00:03:23.500
Nachfragen stellen können.

90
00:03:26.620 --> 00:03:28.540
Zum Thema Verantwortung.

91
00:03:29.510 --> 00:03:31.070
Auch wenn Algorithmen heute

92
00:03:31.070 --> 00:03:32.910
Vorschläge und sogar Entscheidungen

93
00:03:32.910 --> 00:03:34.830
treffen, bleibt die Verantwortung

94
00:03:34.830 --> 00:03:36.230
letztlich bei den Menschen.

95
00:03:36.790 --> 00:03:39.430
Lehrkräfte dürfen die von KI vergebenen

96
00:03:39.430 --> 00:03:41.910
Empfehlungen nicht ungeprüft übernehmen,

97
00:03:41.910 --> 00:03:43.270
sondern müssen sie auf

98
00:03:43.270 --> 00:03:45.870
Plausibilität und Förderpotenzial prüfen

99
00:03:45.870 --> 00:03:47.990
und gegebenenfalls korrigieren.

100
00:03:48.550 --> 00:03:49.750
In der Schulverwaltung

101
00:03:49.750 --> 00:03:51.590
gilt dies gleichermaßen.

102
00:03:51.590 --> 00:03:53.830
Eine Software kann etwa den Einsatz

103
00:03:53.830 --> 00:03:55.910
von Vertretungskräften oder die

104
00:03:55.910 --> 00:03:57.660
Raumbelegung vorschlagen,

105
00:03:57.660 --> 00:04:00.370
die indem sie Ausfälle, Stundenpläne und

106
00:04:00.370 --> 00:04:02.930
Raumkapazitäten berücksichtigt.

107
00:04:02.930 --> 00:04:04.370
Doch die Kontrolle über diese

108
00:04:04.370 --> 00:04:06.530
Entscheidungen bleibt bei den Menschen,

109
00:04:06.530 --> 00:04:07.730
die mit den lokalen

110
00:04:07.730 --> 00:04:09.890
Rahmenbedingungen vertraut sind.

111
00:04:09.890 --> 00:04:12.130
Dazu gehört auch, dass Prozesse

112
00:04:12.130 --> 00:04:14.770
dokumentiert werden, welche Daten wurden

113
00:04:14.770 --> 00:04:16.850
wann genutzt, wie kam eine Entscheidung

114
00:04:16.850 --> 00:04:18.810
zustande und wer hat sie

115
00:04:18.810 --> 00:04:21.010
letztlich bestätigt oder geändert.

116
00:04:21.730 --> 00:04:23.890
Eine solche Rückverfolgbarkeit,

117
00:04:23.890 --> 00:04:26.290
oft als Audit Trail bezeichnet, macht

118
00:04:26.290 --> 00:04:28.210
Fehler aufspürbar und sichert

119
00:04:28.210 --> 00:04:30.690
Transparenz für spätere Nachfragen.

120
00:04:33.730 --> 00:04:37.090
Zusammenfassend heißt das, Erstens: Gerechtigkeit

121
00:04:37.090 --> 00:04:39.570
bedeutet, dass KI niemanden aufgrund

122
00:04:39.570 --> 00:04:42.010
von Sprache, Herkunft oder schlechter

123
00:04:42.010 --> 00:04:43.810
IT Ausstattung benachteiligt.

124
00:04:44.500 --> 00:04:45.330
Zweitens:

125
00:04:45.330 --> 00:04:47.290
Transparenz ist Voraussetzung für

126
00:04:47.290 --> 00:04:49.410
Vertrauen, weil sie nachvollziehbar

127
00:04:49.410 --> 00:04:50.930
macht, wie Entscheidungen entstehen.

128
00:04:52.066 --> 00:04:52.930
Drittens:

129
00:04:52.930 --> 00:04:55.250
Verantwortung heißt, dass am Ende

130
00:04:55.250 --> 00:04:57.170
immer Menschen für die Kontrolle und

131
00:04:57.170 --> 00:05:00.130
Korrektur von KI Prozessen zuständig

132
00:05:00.130 --> 00:05:02.690
sind und nicht das System selbst.

133
00:05:02.690 --> 00:05:04.890
Wenn diese drei Prinzipien konsequent

134
00:05:04.890 --> 00:05:06.850
berücksichtigt werden, kann KI

135
00:05:06.850 --> 00:05:08.850
ein wertvolles Werkzeug für Schulen

136
00:05:08.850 --> 00:05:10.410
und Verwaltungen sein, mit dem

137
00:05:10.410 --> 00:05:12.930
Potenziale ausgeschöpft werden, ohne

138
00:05:12.930 --> 00:05:15.170
zentrale Werte aufs Spiel zu setzen.
