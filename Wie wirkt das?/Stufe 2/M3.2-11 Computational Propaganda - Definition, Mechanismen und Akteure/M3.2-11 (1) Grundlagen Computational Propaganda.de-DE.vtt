WEBVTT

1
00:00:06.720 --> 00:00:09.600
Grundlagen Computational Propaganda.

2
00:00:13.440 --> 00:00:15.600
Willkommen zum Lernangebot

3
00:00:15.600 --> 00:00:19.440
Computational Propaganda. Definition,

4
00:00:19.440 --> 00:00:21.680
Mechanismen und Akteure.

5
00:00:22.560 --> 00:00:24.920
Im Folgenden geht es um ein Thema, das

6
00:00:24.920 --> 00:00:26.800
uns alle im Netz ständig betrifft.

7
00:00:27.570 --> 00:00:29.330
Computational Propaganda.

8
00:00:29.970 --> 00:00:32.210
Vielleicht haben Sie schon selbst erlebt,

9
00:00:32.210 --> 00:00:34.450
wie online versucht wird, Ihre Meinung

10
00:00:34.450 --> 00:00:36.450
gezielt zu beeinflussen.

11
00:00:36.450 --> 00:00:37.890
Manchmal subtil,

12
00:00:37.890 --> 00:00:40.370
manchmal sehr offensichtlich.

13
00:00:40.370 --> 00:00:41.850
Genau darum geht es in

14
00:00:41.850 --> 00:00:43.410
diesem Lernangebot.

15
00:00:43.410 --> 00:00:46.050
Wir stützen uns auf fundierte Quellen,

16
00:00:46.050 --> 00:00:48.530
darunter Berichte des Oxford Internet

17
00:00:48.530 --> 00:00:51.450
Institute, Analysen der Bundeszentrale

18
00:00:51.450 --> 00:00:53.770
für politische Bildung und aktuelle

19
00:00:53.770 --> 00:00:56.180
Studien zu KI und Desinformation.

20
00:00:56.900 --> 00:00:58.180
Warum das wichtig ist?

21
00:00:58.900 --> 00:01:01.140
Weil diese Techniken demokratische

22
00:01:01.140 --> 00:01:03.220
Prozesse beeinflussen können,

23
00:01:03.220 --> 00:01:05.340
zum Beispiel Wahlen und direkt

24
00:01:05.340 --> 00:01:07.940
im Social Media Feed eines jeden

25
00:01:07.940 --> 00:01:10.100
und einer jeden auftauchen, oft

26
00:01:10.100 --> 00:01:11.620
ohne dass dies bemerkt wird.

27
00:01:14.580 --> 00:01:17.460
Im Kern bedeutet Computational Propaganda

28
00:01:17.460 --> 00:01:19.700
den gezielten Einsatz digitaler

29
00:01:19.700 --> 00:01:22.590
Technologien, also Algorithmen,

30
00:01:22.590 --> 00:01:25.590
automatisierte Programme, Bots und immer

31
00:01:25.590 --> 00:01:27.550
mehr auch künstliche Intelligenz (KI),

32
00:01:28.790 --> 00:01:31.230
um online Meinungen zu beeinflussen.

33
00:01:31.230 --> 00:01:33.710
Das geschieht häufig mit irreführenden

34
00:01:33.710 --> 00:01:35.230
oder sogar falschen Informationen

35
00:01:35.870 --> 00:01:38.310
und vor allem dort, wo die Reichweite am

36
00:01:38.310 --> 00:01:41.070
größten ist, in sozialen Netzwerken.

37
00:01:41.630 --> 00:01:43.310
Das Entscheidende ist nicht nur

38
00:01:43.310 --> 00:01:45.390
die einzelne Lüge, sondern die

39
00:01:45.390 --> 00:01:48.220
systematische, oft automatisierte

40
00:01:48.220 --> 00:01:50.620
und skalierbare Beeinflussung.

41
00:01:50.620 --> 00:01:53.300
Es geht um koordinierte Aktionen, bei

42
00:01:53.300 --> 00:01:55.140
denen viele Bots oder Accounts

43
00:01:55.140 --> 00:01:57.980
gemeinsam Diskurse lenken oder stören.

44
00:01:57.980 --> 00:02:00.380
Propaganda im Industriemaßstab.

45
00:02:03.180 --> 00:02:05.660
KI hebt Computational Propaganda

46
00:02:05.660 --> 00:02:06.780
auf ein neues Level.

47
00:02:08.220 --> 00:02:10.860
Die massenhafte Inhaltserstellung mit KI

48
00:02:10.860 --> 00:02:12.860
kann Texte, Bilder und Videos

49
00:02:12.860 --> 00:02:15.260
generieren, die täuschend echt wirken.

50
00:02:16.130 --> 00:02:18.130
Inhalte werden mit Hilfe von KI

51
00:02:18.130 --> 00:02:19.730
personalisiert, auf dich und

52
00:02:19.730 --> 00:02:21.810
deine Interessen zugeschnitten,

53
00:02:21.810 --> 00:02:23.650
um maximale Wirkung zu erzielen.

54
00:02:24.770 --> 00:02:27.730
KI erkennt, was dich emotional anspricht

55
00:02:27.730 --> 00:02:30.690
und nutzt das durch gezielte Ansprache.

56
00:02:30.690 --> 00:02:33.370
Hochentwickelte Bots imitieren echte

57
00:02:33.370 --> 00:02:36.250
Nutzende, verbreiten Inhalte, verstärken

58
00:02:36.250 --> 00:02:39.170
Hashtags und simulieren Unterstützung.

59
00:02:39.170 --> 00:02:41.650
Das nennt man Astroturfing.

60
00:02:45.470 --> 00:02:47.190
Hinter der Technologie stehen immer

61
00:02:47.190 --> 00:02:49.310
Menschen oder Organisationen,

62
00:02:49.310 --> 00:02:52.190
Regierungen, Parteien, Interessengruppen

63
00:02:52.190 --> 00:02:54.830
oder finanzstarke Einzelpersonen.

64
00:02:54.830 --> 00:02:56.830
Sie nutzen diese Werkzeuge,

65
00:02:56.830 --> 00:02:59.190
um Wahlen zu beeinflussen, Gegner zu

66
00:02:59.190 --> 00:03:02.510
diskreditieren oder Misstrauen zu säen.

67
00:03:02.510 --> 00:03:04.310
Letztlich geht es Macht und

68
00:03:04.310 --> 00:03:05.630
Deutungshoheit im Netz.

69
00:03:08.840 --> 00:03:10.200
Konkrete Beispiele aus der

70
00:03:10.200 --> 00:03:12.840
Praxis für Computational Propaganda

71
00:03:12.840 --> 00:03:14.040
sind zum Beispiel die

72
00:03:14.040 --> 00:03:17.640
US-Präsidentschaftswahl 2016.

73
00:03:17.640 --> 00:03:19.040
Fast ein Fünftel aller

74
00:03:19.040 --> 00:03:20.600
Tweets kam von Bots.

75
00:03:21.320 --> 00:03:23.880
Russische Akteure streuten gezielt

76
00:03:23.880 --> 00:03:26.160
Desinformation, die öffentliche

77
00:03:26.160 --> 00:03:27.640
Meinung zu beeinflussen.

78
00:03:28.520 --> 00:03:30.760
Auch während der Wahlen in Brasilien

79
00:03:30.760 --> 00:03:33.320
und im Ukraine Konflikt wurden Bot-

80
00:03:33.320 --> 00:03:35.480
Netzwerke und Fake Accounts eingesetzt,

81
00:03:36.090 --> 00:03:38.570
um politische Narrative zu verstärken.

82
00:03:38.570 --> 00:03:40.010
Auch der Gesundheitsbereich

83
00:03:40.010 --> 00:03:41.770
bleibt nicht verschont.

84
00:03:41.770 --> 00:03:43.530
Anti-Impf-Kampagnen und

85
00:03:43.530 --> 00:03:46.490
Falschinformationen zu Covid-19

86
00:03:46.490 --> 00:03:48.490
wurden mit KI gestützten Methoden

87
00:03:48.490 --> 00:03:53.810
verbreitet und ebenso tauchen 2023-24

88
00:03:53.810 --> 00:03:56.650
KI generierte emotionalisierende

89
00:03:56.650 --> 00:03:58.810
Bilder in sozialen Netzwerken

90
00:03:58.810 --> 00:04:01.290
bezüglich des Gaza Konflikts auf.

91
00:04:04.400 --> 00:04:06.400
Die gesellschaftlichen Folgen von

92
00:04:06.400 --> 00:04:09.280
Computational Propaganda: Kampagnen

93
00:04:09.280 --> 00:04:12.000
fördern Echokammern und Filterblasen.

94
00:04:12.000 --> 00:04:13.440
Einem werden fast nur noch

95
00:04:13.440 --> 00:04:15.000
Inhalte gezeigt, die die

96
00:04:15.000 --> 00:04:16.560
eigene Meinung bestätigen.

97
00:04:16.560 --> 00:04:18.480
Das führt zu mehr Polarisierung

98
00:04:18.480 --> 00:04:19.959
und schwindendem Vertrauen

99
00:04:19.959 --> 00:04:22.480
in Medien und Institutionen.

100
00:04:22.480 --> 00:04:24.160
In einer sogenannten Post-

101
00:04:24.160 --> 00:04:26.880
Truth-Gesellschaft zählen Fakten weniger

102
00:04:26.880 --> 00:04:29.830
als Emotionen oder gefühlte Wahrheiten.

103
00:04:32.710 --> 00:04:34.390
Herausfordernd im Umgang mit

104
00:04:34.390 --> 00:04:36.910
Computational Propaganda ist, dass sich

105
00:04:36.910 --> 00:04:39.430
die Technologie rasant weiterentwickelt,

106
00:04:39.430 --> 00:04:41.590
oft schneller als die Regeln.

107
00:04:41.590 --> 00:04:43.750
Täter bleiben anonym, agieren

108
00:04:43.750 --> 00:04:46.110
grenzüberschreitend und es fehlen

109
00:04:46.110 --> 00:04:48.630
klare rechtliche Rahmenbedingungen.

110
00:04:48.630 --> 00:04:50.430
Es ist ein Wettrüsten zwischen

111
00:04:50.430 --> 00:04:52.150
Angreifern und Verteidigern.

112
00:04:55.120 --> 00:04:57.280
Es gibt kein Patentrezept dafür,

113
00:04:57.280 --> 00:04:59.120
was man dagegen tun kann,

114
00:04:59.120 --> 00:05:01.520
aber einen Mix aus Strategien.

115
00:05:02.480 --> 00:05:04.280
Auf der technologischen Seite kann

116
00:05:04.280 --> 00:05:06.080
KI auch genutzt werden,

117
00:05:06.080 --> 00:05:09.000
Bots und Fakes zu erkennen, Faktencheck-

118
00:05:09.000 --> 00:05:11.600
Tools zu verbessern und Desinformation

119
00:05:11.600 --> 00:05:13.440
schneller aufzudecken.

120
00:05:13.440 --> 00:05:15.240
Auf der gesellschaftlichen Seite

121
00:05:15.240 --> 00:05:17.520
muss die Medienkompetenz gestärkt,

122
00:05:17.520 --> 00:05:19.630
kritisches Denken gefördert

123
00:05:19.630 --> 00:05:22.150
und Bildung ausgebaut werden, damit wir

124
00:05:22.150 --> 00:05:24.430
alle lernen, Quellen zu prüfen und

125
00:05:24.430 --> 00:05:26.270
nicht alles sofort zu glauben.

126
00:05:26.910 --> 00:05:28.910
Politisch und rechtlich braucht

127
00:05:28.910 --> 00:05:30.510
es stärkere Forderungen

128
00:05:30.510 --> 00:05:32.030
nach mehr Transparenz der

129
00:05:32.030 --> 00:05:34.270
Plattformen, klare Regeln für

130
00:05:34.270 --> 00:05:36.110
politische Online-Werbung und

131
00:05:36.110 --> 00:05:37.710
den Einsatz von Bots

132
00:05:37.710 --> 00:05:39.270
und eine Verstärkung der

133
00:05:39.270 --> 00:05:40.990
internationalen Zusammenarbeit.

134
00:05:42.110 --> 00:05:44.350
Selbst wenn Sie glauben, nicht direkt

135
00:05:44.350 --> 00:05:45.870
Ziel einer Kampagne zu sein.

136
00:05:46.790 --> 00:05:47.910
Schon das Wissen diese

137
00:05:47.910 --> 00:05:50.630
Manipulationsmöglichkeiten verändert Ihr

138
00:05:50.630 --> 00:05:53.230
Online Verhalten und Ihr Vertrauen in

139
00:05:53.230 --> 00:05:56.150
das, was Sie sehen und lesen oder eben

140
00:05:56.150 --> 00:05:58.550
auch nicht sehen und nicht lesen.

141
00:05:58.550 --> 00:06:01.510
Macht Sie das kritischer, misstrauischer

142
00:06:01.510 --> 00:06:03.990
oder vielleicht sogar zynischer?

143
00:06:03.990 --> 00:06:05.190
Das ist eine wichtige

144
00:06:05.190 --> 00:06:06.550
Frage für jeden von uns.
