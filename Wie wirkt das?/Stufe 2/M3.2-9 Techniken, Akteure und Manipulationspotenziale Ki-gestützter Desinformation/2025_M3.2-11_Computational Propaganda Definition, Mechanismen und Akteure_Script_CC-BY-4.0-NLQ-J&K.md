# Techniken, Akteure und Manipulationspotenzial KI-gestützter Desinformation

## Start: Worum geht es?

Künstliche Intelligenz verändert, wie Informationen entstehen, verbreitet werden – und wie wir sie wahrnehmen. Im digitalen Zeitalter wächst das Risiko gezielter Desinformation: KI kann heute täuschend echte Falschmeldungen, manipulierte Bilder und Deepfakes erzeugen, die gezielt an verschiedene Gruppen ausgespielt werden. So werden gesellschaftliche Diskussionen, Meinungsbildung und sogar demokratische Prozesse beeinflusst.

In diesem Lernangebot erfahren Sie, wie KI-gestützte Desinformation funktioniert, wer hinter diesen Prozessen steht und warum demokratische Gesellschaften besonders gefordert sind. Sie lernen, typische Techniken und Akteure zu erkennen, psychologische Wirkmechanismen zu verstehen und gesellschaftliche Risiken differenziert zu bewerten.

Das Lernangebot richtet sich an alle, die sich auf Grundlage von vertieftem Basiswissen praxisorientiert mit den Potenzialen und Gefahren von KI im Kontext von Medien, Gesellschaft und Politik auseinandersetzen möchten. Sie benötigen keine spezialisierten Vorkenntnisse in Informatik oder KI – Offenheit für digitale Medien, gesellschaftliche Fragestellungen und die Bereitschaft, Informationen kritisch zu hinterfragen, reichen aus.

Schritt für Schritt erschließen Sie sich das Thema praxisnah und reflektiert: von zentralen Funktionsweisen und Einsatzfeldern von KI über aktuelle Beispiele bis hin zu Übungen, mit denen Sie Fakes und Desinformation selbst erkennen, bewerten und in den eigenen Alltag transferieren können. Reflexions- und Transferaufgaben unterstützen Sie dabei, Medien- und KI-Kompetenz gezielt weiterzuentwickeln.

Nach Abschluss des Lernangebots können Sie KI-basierte Desinformation erklären, typische Akteure und Techniken erkennen, Manipulationsmechanismen analysieren und Risiken für Demokratie, Medien und Gesellschaft reflektiert einschätzen. Sie erhalten Impulse und Methoden, um digitale Inhalte bewusst und kritisch zu prüfen, einfache KI-Tools zur Erkennung von Fakes zu nutzen und eigenständig Handlungsstrategien für den eigenen (Arbeits-)Alltag zu entwickeln.

---

### Testen Sie Ihr Vorwissen

**Welche der folgenden Aussagen über Deepfakes ist FALSCH?**
* Sie werden in der Regel mit Methoden der künstlichen Intelligenz erzeugt.
* **Sie sind heutzutage immer leicht als Fälschung zu erkennen.** (Richtig)
* Sie können Audio, Bild oder Video täuschend echt manipulieren.

**Was ist eine Hauptfunktion von Social Bots im Kontext von Desinformation?**
* Die Sicherstellung einer ausgewogenen und neutralen Berichterstattung.
* Die Erstellung von handschriftlichen Briefen zur analogen Beeinflussung.
* **Die automatisierte Verbreitung von Inhalten, um bestimmte Narrative zu verstärken.** (Richtig)

**Was beschreibt das Konzept der „Liar’s Dividend“ (Lügnerdividende) am besten?**
* Eine Methode zur Verbesserung der Bildauflösung in gefälschten Videos.
* **Die Möglichkeit, echte Beweise als Fälschung abzutun, weil die Existenz von Deepfakes bekannt ist.** (Richtig)
* Ein Bonusprogramm für Entwickler von Software zur Erkennung von Fälschungen.

**Was ist ein wesentliches neues Merkmal von KI-gestützter Desinformation im Vergleich zu früheren Formen?**
* Dass sie ausschließlich von staatlichen Akteuren genutzt wird.
* Dass sie immer leicht als plumpe Propaganda zu erkennen ist.
* **Die Möglichkeit, Inhalte massenhaft, personalisiert und in Echtzeit zu verbreiten.** (Richtig)

**Warum ist Medien- und KI-Kompetenz im Umgang mit Desinformation besonders wichtig?**
* Sie garantiert, dass man niemals auf Falschinformationen hereinfällt.
* **Sie fördert einen kritischen Umgang mit digitalen Informationen und hilft, Fakes besser zu erkennen.** (Richtig)
* Sie ist nur für Journalistinnen, Journalisten und Lehrkräfte relevant.

**Welche Gruppe gehört laut Text NICHT zu den typischen Akteuren von KI-Desinformation?**
* Politische Gruppen, die Wahlen beeinflussen wollen.
* Einzelpersonen, die frei verfügbare KI-Tools nutzen.
* Staatliche Akteure, die geopolitische Ziele verfolgen.
* **Forschungsgruppen, die an Methoden zur Erkennung von Fakes arbeiten.** (Richtig)

**Welches der folgenden ist ein typisches Ziel von KI-gestützter Desinformation?**
* Die Förderung des gesellschaftlichen Zusammenhalts und Vertrauens.
* Die Stärkung der Wissenschaftskommunikation und des Faktenwissens.
* **Die gesellschaftliche Polarisierung und die Diskreditierung von Personen.** (Richtig)

**Welcher psychologische Mechanismus trägt laut Text zur Wirkung von KI-Desinformation bei?**
* Die angeborene Fähigkeit des menschlichen Gehirns, Fälschungen immer sofort zu erkennen.
* **Der 'Truth Effect', bei dem häufige Wiederholung die Glaubwürdigkeit einer Aussage erhöht.** (Richtig)
* Der generelle Wunsch von Menschen nach ausschließlich objektiver und neutraler Berichterstattung.

**Woran kann man laut Text KI-generierte Fakes aktuell unter anderem erkennen?**
* **Durch die Analyse von Bildfehlern und die Nutzung von Faktencheck-Tools oder Rückwärtssuche.** (Richtig)
* An der grundsätzlich immer schlechteren Bildauflösung im Vergleich zu echten Aufnahmen.
* Gar nicht, da sie mittlerweile technisch perfekt und unmöglich zu entlarven sind.

**Welches Phänomen wird durch Filterblasen und Echokammern im Kontext der Desinformation verstärkt?**
* Eine Abnahme der emotionalen Reaktion auf Nachrichten.
* Die Konfrontation mit einer Vielzahl unterschiedlicher Meinungen und Perspektiven.
* **Die eigenen Überzeugungen werden ständig bestätigt, während andere Sichtweisen ausgeblendet werden.** (Richtig)

**Auswertung:**
* *Einstieg (0-3 richtige Antworten):* Klasse, dass Sie sich an den Fragen versucht haben! Jetzt können Sie tiefer in die Materie eintauchen.
* *Fortgeschritten (4-7 richtige Antworten):* Sie haben schon ein solides Grundwissen. Der Kurs wird Ihnen helfen, Themen weiter zu vertiefen.
* *Profi (8-10 richtige Antworten):* Beeindruckend! Ihr Wissen ist bereits fundiert. Der Kurs kann Ihnen eine Auffrischung und neue Impulse bieten.

---

## Grundlagen

### Bevor es los geht …
Das Lernangebot richtet sich an alle, die sich ein fundiertes, praxisnahes Verständnis darüber aneignen möchten, wie Künstliche Intelligenz (KI) heute zur gezielten Verbreitung von Desinformation eingesetzt wird – und welche Herausforderungen und Chancen daraus für Bildung, Gesellschaft und Demokratie erwachsen. Gerade weil KI-gestützte Falschinformationen unser Informationsumfeld immer stärker prägen, ist es wichtiger denn je, Mechanismen, Akteure und Risiken zu erkennen, einzuordnen und gemeinsam Gegenstrategien zu entwickeln.

Dieser Kurs hilft dabei, Unsicherheiten im Umgang mit digitalen Informationen abzubauen, eigene Fähigkeiten zur Analyse und Bewertung von Inhalten zu stärken und das Bewusstsein für gesellschaftliche sowie ethische Fragestellungen zu schärfen. Im Mittelpunkt stehen aktuelle technologische Entwicklungen (Stand August 2025), die Rolle verschiedener Akteursgruppen sowie die psychologischen und gesellschaftlichen Wirkungen von Desinformation.

Ziel ist es, kompetent auf neue Formen der digitalen Manipulation zu reagieren, reflektiert Stellung zu beziehen und andere im sicheren Umgang mit KI-gestützter Desinformation zu unterstützen.

**Folgende Aspekte werden behandelt:**
* **Techniken der KI-gestützten Desinformation:** Einführung in zentrale Technologien wie generative KI, Deepfakes, Social Bots und automatisierte Falschmeldungen – mit praxisnahen Beispielen.
* **Akteure und Motive:** Analyse von Akteursgruppen – von Staaten über politische Gruppen bis zu Einzelpersonen und „Disinformation-for-hire“-Dienstleistern – sowie deren Beweggründe und Methoden.
* **Manipulationspotenziale und Wirkmechanismen:** Verstehen, wie und warum KI-basierte Desinformation so überzeugend wirkt, welche psychologischen Effekte sie nutzt und wie sie öffentliche Meinung und gesellschaftlichen Zusammenhalt beeinflusst.
* **Kompetenzentwicklung und Gegenstrategien:** Anregungen, wie digitale Medienkompetenz gefördert, Fakten geprüft und Desinformation erkannt werden kann – inklusive Tipps für den Alltag, Schule und Verwaltung.
* **Reflexion und Transfer:** Aufgaben und Impulse zur Selbstreflexion: Welche Erfahrungen habe ich selbst mit (Des-)Information gemacht? Wie kann ich meine Erkenntnisse in Praxis, Unterricht oder Beruf weitergeben?

Das Lernangebot bietet damit eine praxisorientierte Grundlage, um die Herausforderungen KI-gestützter Desinformation kritisch, sicher und gestaltungsfreudig anzugehen – und um als Multiplikator*in zur Stärkung von Demokratie und Medienkompetenz in einer digitalen Gesellschaft beizutragen.

---

### Video 1: Einführung ins Thema
*(Sprechertext)*

**Die neue Dimension der Desinformation im Zeitalter der KI**

Die digitale Transformation hat die Art und Weise, wie Informationen erzeugt, verbreitet und konsumiert werden, grundlegend verändert. Im Zentrum dieser Entwicklung steht die Künstliche Intelligenz (KI), die nicht nur enorme Potenziale für Fortschritt und Effizienz birgt, sondern auch neue Herausforderungen mit sich bringt. Natürlich gibt es Herausforderungen, denen man sich gerne stellt – zum Beispiel, wie KI unser Lernen, Arbeiten oder Forschen verändert. Aber wie bei jeder neuen Technologie gibt es leider auch Schattenseiten.

Eine der gravierendsten ist die KI-gestützte Desinformation, die das Phänomen der Falschinformation auf eine neue Ebene hebt und weitreichende Implikationen für die Gesellschaft und demokratische Prozesse hat. Dieses Angebot zielt darauf ab, ein Verständnis dafür zu entwickeln, wie KI-Desinformation funktioniert, wer ein Interesse daran haben könnte und welche Beeinflussungsmöglichkeiten diese Akteure durch KI haben. Wir hoffen dadurch dazu beizutragen, dass Sie KI-Tools effektiver nutzen aber auch ihren gesellschaftlichen Einfluss kritisch hinterfragen können.

**Was ist Desinformation? – Begriffe und Abgrenzung**

Lassen Sie uns zu Beginn ein paar Begriffe klären. Unter Desinformation versteht man absichtlich verbreitete Falschinformationen, die täuschen und schaden sollen. Sie unterscheidet sich von Misinformation (Irrtumsinformation), bei der falsche Inhalte ohne Täuschungsabsicht weitergegeben werden, und von Malinformation, bei der echte Informationen in schädigender Weise aus dem Kontext gerissen oder geleakt werden. Kurz gesagt: Misinformation entsteht aus Versehen, Desinformation mit Absicht zur Irreführung, und Malinformation nutzt wahre Inhalte böswillig. Alle drei Phänomene – oft als “Fake News” bezeichnet – können das Vertrauen in Informationen untergraben.

**Generative KI verändert Desinformation**

Desinformation ist kein neues Phänomen. Doch mithilfe generativer Künstlicher Intelligenz (KI) lässt sie sich heute in bislang unerreichter Menge, Geschwindigkeit und Qualität herstellen und verbreiten. Fortschritte im Bereich Deep Learning erlauben es, täuschend echte Inhalte in Text, Bild, Audio und Video zu erzeugen. So reihen sich etwa Deepfakes – KI-manipulierte Videos oder Audios, die Aussehen oder Stimme realer Personen imitieren – in die lange Geschichte der Medienmanipulation ein, machen diese aber schneller, einfacher zugänglich und überzeugender. Wo früher erheblicher Aufwand nötig war, genügen heute wenige Klicks, um z.B. ein Video mit dem Gesicht und der Stimme einer Person zu fälschen.

Diese Entwicklung führt zu einer neuen Quantität und Qualität der Täuschung. Bürgerinnen und Bürger schenken visuellen Medien traditionell hohes Vertrauen, und über soziale Netzwerke erreichen Fakes in kürzester Zeit ein Massenpublikum. KI-Modelle wie große Sprachmodelle können zudem automatisiert unzählige falsche Texte generieren – etwa erfundene Nachrichtenartikel oder Social-Media-Posts – und so eine Flut an Desinformation erzeugen. Die Geschwindigkeit, Skalierbarkeit und authentische Wirkung KI-generierter Inhalte verleihen der Desinformation im digitalen Zeitalter eine ganz neue Dynamik.

**Desinformation bedroht Meinungsbildung & gesellschaftlichen Zusammenhalt**

Diese neue Dimension ist nicht bloß technischer Natur, sondern stellt eine ernsthafte Bedrohung für die Meinungsbildung, das Vertrauen und den gesellschaftlichen Zusammenhalt dar. Laut einer Studie der Bertelsmann Stiftung aus dem Jahr 2024 sind 81 % der Deutschen der Ansicht, dass Desinformation eine Gefahr für Demokratie und gesellschaftlichen Zusammenhalt bedeutet. 87 % befürchten, dass gezielte Fake News die Gesellschaft spalten, und 83 % warnen vor daraus resultierender Radikalisierung. Zudem glauben 88 % der Internetnutzer, dass der Fortschritt bei KI die Desinformationsgefahr weiter steigen lässt.

Tatsächlich zeigen Fälle von manipulierten Videos bei Wahlkämpfen oder Falschbehauptungen in Krisenzeiten, wie Desinformation Vertrauen in Medien, Institutionen und zwischen Bürgern erschüttert. Deepfakes etwa können das Vertrauen in gemeinsame Fakten erschüttern. Wenn Augen und Ohren trügen und wir nicht mehr wissen, was echt ist, fehlt die Grundlage für eine sachliche Diskussion. Dies gefährdet den demokratischen Diskurs, denn wenn öffentliche Debatten sich mehr um die Echtheit von Bildern oder Aussagen drehen gerät der Diskurs um gesellschaftliche Probleme und Lösungen aus dem Blickfeld. Insgesamt droht eine Erosion von Faktenbasis und Vertrauen, manche Beobachter warnen sogar vor einer “Infokalypse”, in der Wahrheit und Lüge ununterscheidbar werden. Andere Experten schätzen die Lage zwar etwas nüchterner ein, sehen aber ebenfalls eine schleichende “Verschmutzung” unseres Informationsökosystems.

**Der Dual-Use-Charakter der KI: Täuschung und Aufklärung**

Wichtig ist auch der sogenannte Dual-Use-Charakter der KI: Dieselben Technologien, die zur Täuschung eingesetzt werden, können auch zur Aufklärung beitragen. So gibt es KI-Tools, die Deepfakes oder Bot-Netzwerke erkennen und enttarnen – doch hier findet ein stetiges technologisches Wettrüsten zwischen Täuschung und Erkennung statt. Während KI-gestützte Fälschungen immer raffinierter werden, entwickeln sich parallel die Detektionsmethoden weiter. Dieser Wettlauf fordert nicht nur Technikerinnen und Techniker, sondern uns alle: Wir müssen lernen, kritischer mit digitalen Inhalten umzugehen und Desinformation zu durchschauen.

---

### Video 2: Techniken und Akteure der KI-gestützten Desinformation
*(Sprechertext)*

**Technologische Grundlagen: Wie KI Desinformation möglich macht**

Moderne Desinformationskampagnen nutzen eine Vielzahl fortschrittlicher KI-Technologien, um falsche oder irreführende Inhalte zu erzeugen und zu verbreiten. Im Zentrum stehen generative KI-Modelle – also Algorithmen, die eigenständig neue Inhalte produzieren können. Dazu zählen große Sprachmodelle (LLMs) wie Claude, Gemini oder ChatGPT, die in Sekundenschnelle täuschend echt klingende Texte erstellen, beispielsweise Fake-News-Artikel, erfundene Social-Media-Beiträge oder Kommentare.

Für visuelle Medien kommen unter anderem Generative Adversarial Networks (GANs) und Diffusionsmodelle wie Stable Diffusion, Midjourney oder DALL·E zum Einsatz. Mit diesen Verfahren lassen sich realistisch wirkende Bilder und Videos synthetisch herstellen. Ein Beispiel hierfür ist das viel diskutierte KI-Bild vom Papst im Designer-Mantel, das viral ging, obwohl es komplett künstlich erstellt war.

Besonders brisant sind sogenannte Deepfakes – also per KI manipulierte Videos oder Audios, die existierende Personen in Worten oder Handlungen zeigen, die nie stattgefunden haben. Dabei werden zum Beispiel Gesichter per Face-Swapping in Videos montiert oder Stimmen per Voice Cloning nachgeahmt.

Generative KI ist heute multimodal nutzbar: Es gibt Systeme für die automatisierte Texterstellung, Bilderzeugung, Sprachausgabe und sogar Musik – oft auch kombiniert, wie etwa in einem gefälschten Video mit erfundener Tonspur und passender Bildunterschrift. Im Unterschied zu früher ist die Produktion solcher Fakes heute oft schnell, kostengünstig und für viele Akteure zugänglich. Dadurch können in kürzester Zeit riesige Mengen an täuschend echten Inhalten erstellt werden – ein völlig neues Ausmaß an Desinformation.

**Automatisierte Verbreitung: Social Bots, Fake-Accounts und Content-Farmen**

Nicht nur die Erstellung, sondern auch die Verbreitung von Desinformation wird durch KI massiv erleichtert. Social Bots – automatisierte Accounts in sozialen Netzwerken – können mithilfe von KI rund um die Uhr Beiträge und Kommentare posten, Hashtags verbreiten oder Diskussionen beeinflussen. KI-gestützte Bot-Profile wirken dabei zunehmend authentisch, inklusive generierter Profilbilder und erfundener Biografien.

Praxisbeispiel: Im Jahr 2023 berichteten moldawische Behörden von Hunderten gefälschten Facebook-Profilen mit KI-generierten Porträtbildern und absichtlich eingebauten kleinen Fehlern, die pro-russische Desinformation verbreiteten. Diese Bot-Netzwerke posten koordiniert falsche Behauptungen, manipulieren Likes und Shares und suggerieren so künstlich breite Unterstützung für bestimmte Narrative.

Neben Social Bots werden auch Fake-Websites und Content-Farmen eingesetzt: Mit KI lassen sich in kurzer Zeit ganze Nachrichtenseiten klonen oder pseudo-journalistische Artikel generieren. Ein bekanntes Beispiel ist eine gefälschte Nachrichtenseite im französischen Wahlkampf 2017, die Emmanuel Macron fälschlich Finanzhilfe aus dem Ausland unterstellte.

**Manipulation von KI-Systemen: Adversarial Attacks und Data Poisoning**

Ein oft übersehener Aspekt ist, dass KI selbst Ziel von Manipulation sein kann. So nutzen Akteure sogenannte Adversarial Attacks, um beispielsweise Erkennungssysteme für Deepfakes auszutricksen. Bilder oder Videos werden dabei minimal verändert, sodass KI-basierte Detektoren sie nicht mehr als Fälschung erkennen. Ebenso problematisch ist das sogenannte Data Poisoning – also die bewusste „Vergiftung“ von Trainingsdaten. Wenn KI-Systeme mit tendenziösen oder falschen Informationen trainiert werden, kann das ihre Ausgaben und Entscheidungen langfristig verzerren. Dadurch könnten Sprachassistenten oder Suchmaschinen unwissentlich Desinformation weiterverbreiten, weil ihr Wissensfundus manipuliert wurde.

**Motive und Methoden von KI-gestützter Desinformation**

Die Motive hinter KI-gestützter Desinformation sind vielfältig: Sie reichen von Machtgewinn und Einfluss, gesellschaftlicher Destabilisierung, ideologischen Zielen, wirtschaftlichem Vorteil bis hin zu persönlicher Rache oder Rufschädigung. Die Methoden variieren – von massenhaft gestreuten Fake-Posts bis zu aufwendig produzierten Deepfakes oder gezielter Verbreitung von Gerüchten und Verschwörungsmythen.

Die Umsetzung dieser Motive und Methoden erfolgt durch verschiedenste Gruppen, die eigene Interessen verfolgen:

* **Staatliche Akteure:** Staatliche Akteure setzen Desinformation gezielt als Werkzeug hybrider Kriegsführung ein. Autokratische Regime wie Russland investieren massiv in Propaganda-Trollfabriken und KI, um geopolitische Ziele zu verfolgen – sei es, Gegner zu destabilisieren oder die eigene Bevölkerung zu manipulieren.
* **Politische Gruppen und Parteien:** Auch politische Gruppen und Parteien nutzen Desinformation, beispielsweise zur Wahlbeeinflussung oder um Gegner zu diskreditieren. Beispiele aus der Slowakei, den USA und der Türkei zeigen, wie KI-Deepfakes kurz vor Wahlen eingesetzt werden, um gezielt Zweifel zu säen oder Kandidatinnen und Kandidaten zu schaden.
* **Kommerzielle Anbieter und Content-Farmen:** Eine wachsende Rolle spielen sogenannte „Disinformation-for-hire“-Dienstleister: Firmen oder Online-Netzwerke, die gegen Bezahlung Fake-Trends, gefälschte Kommentare oder manipulierte Artikel liefern. Besonders im internationalen Kontext können Bot-Armeen und KI-Textgeneratoren kostengünstig eingesetzt werden.
* **Extremistische Gruppen und Einzelpersonen:** Auch extremistische Gruppen und Einzelpersonen nutzen KI-Desinformation, etwa um Feindbilder zu schüren oder bestimmte politische Ziele zu verfolgen. Die niedrige Eintrittsbarriere durch frei verfügbare KI-Tools ermöglicht es heute praktisch jeder Person, Desinformation zu produzieren und zu verbreiten.

Das Zusammenspiel aus neuen Technologien, vielfältigen Akteuren und gezielten Methoden macht KI-gestützte Desinformation zu einer echten Herausforderung für unsere Gesellschaft. Deshalb ist es wichtiger denn je, zu verstehen, wie solche Fakes entstehen und verbreitet werden – und wie wir uns als Gesellschaft dagegen wappnen können.

---

### KI-basierte Desinformation im Wahlkampf: Manipulationstechniken und praktische Prüfinstrumente

Moderne Desinformationskampagnen im Kontext politischer Wahlen zeigen, wie gezielt Akteure KI-Technologien zur Manipulation einsetzen und wie technische sowie medienkompetenzbasierte Gegenstrategien aussehen können:

* **KI-basierte Wahlkampfmanipulation:** Bei der Europawahl und deutschen Landtagswahlen – etwa durch Parteien wie die AfD – werden mittlerweile vollständig KI-generierte Wahlwerbevideos genutzt. Ziel ist es, mit realistisch wirkenden, aber künstlich erzeugten Bildern und Szenarien gezielt Emotionen, Unsicherheit oder Angst hervorzurufen und so Meinungen im Sinne der jeweiligen Kampagne zu beeinflussen.
* **Parallel wurde zur US-Präsidentschaftswahl 2024** ein Rekordniveau an Desinformationskampagnen registriert. Hier kamen insbesondere Social Bots und Deepfakes zum Einsatz, um großflächig gezielte Fehlinformationen zu verbreiten und politische Stimmungen zu manipulieren.
* **Faktenprüfung und technische Abwehrmaßnahmen:** Als Reaktion auf diese neuen Herausforderungen setzen Projekte wie „noFake“ auf eine Verbindung aus menschlicher Expertise und KI-gestützten Analyseverfahren, um Desinformation identifizieren und bewerten zu können.
* **Der CORRECTIV.Checkbot** prüft beispielsweise automatisiert, ob sich verbreitete Aussagen mit bekannten Fakten abgleichen lassen, und unterstützt insbesondere Journalist:innen bei der schnellen Verifizierung neuer Inhalte.
* **Ergänzend ermöglichen spezialisierte Geolokalisierungstools wie „SPOT“** das Überprüfen von Bild- und Videomaterial auf Ort und Authentizität – so kann beispielsweise selbst mit einfachen Mitteln (z.B. Abgleich in Google Street View) nachvollzogen werden, ob der angeblich gezeigte Schauplatz eines Medieninhalts plausibel ist oder manipuliert wurde.

Diese Werkzeuge helfen, gezielte Falschinformationen zu erkennen und zu entlarven. Kombiniert verdeutlichen diese Beispiele: KI-gestützte Desinformationskampagnen können heute große Wirkung entfalten – die Technik zur Erzeugung und zur Abwehr entwickelt sich jedoch parallel weiter. Erfolgreiche Gegenmaßnahmen setzen auf eine Verbindung aus technischem Prüfen, gezieltem Mitteleinsatz (z.B. durch Browser-Plugins, Geolokalisierungstools und automatisierte Faktenchecks) sowie auf die Vermittlung von Medien- und KI-Kompetenz in der breiten Bevölkerung.

---

### Video 3: Manipulationspotenziale, Wirkmechanismen und gesellschaftliche Folgen
*(Sprechertext)*

**Was macht KI-Desinformation so wirkungsvoll?**

Was macht KI-Desinformation eigentlich so gefährlich – und wie wirkt sie sich auf unser Zusammenleben aus? In diesem Abschnitt schauen wir auf die Potenziale, Wirkmechanismen und Folgen für unsere Gesellschaft.

Mit dem Begriff „Manipulationspotenzial“ wird die neue Stärke und Qualität der Beeinflussung beschrieben, die durch KI-gestützte Desinformation möglich wird. Während Propaganda, Gerüchte und Täuschung bereits früher Teil der Medienwelt waren, verleiht Künstliche Intelligenz der Desinformation eine neue Skalierbarkeit, Authentizität und Flexibilität. KI-generierte Falschinformationen können heute schneller, massenhaft und täuschend echt produziert und verbreitet werden – personalisiert und oft schwerer zu erkennen als klassische Manipulation. Dadurch steigt das Potenzial, Menschen zu beeinflussen, in bisher unbekanntem Ausmaß.

Im Unterschied zu früheren Manipulationsformen kann KI Inhalte in Echtzeit auf aktuelle Ereignisse zuschneiden, ganze Kampagnen automatisch steuern und wiederholt ausspielen, die Täuschung visuell und akustisch perfekt erscheinen lassen (z.B. Deepfakes) und gezielt auf individuelle Profile eingehen (Mikrotargeting). Die Eintrittsschwelle sinkt: Fast jede und jeder kann mit einfachen Tools überzeugende Fakes erzeugen. Die Verbreitung wird automatisiert und durch Social Bots beschleunigt. Damit entsteht eine neue Dimension der Manipulationsgefahr.

**Ziele und Wirkungsrichtungen**

Das Spektrum der möglichen Ziele ist breit: Politische Destabilisierung (z.B. Zweifel an Wahlen, Diskreditierung von Institutionen), Wahlbeeinflussung (z.B. Diffamierung von Kandidierenden, Mobilisierung oder Demobilisierung von Wählergruppen), Diskreditierung von Personen oder Institutionen (z.B. durch gefälschte Skandal-Videos), Fragmentierung und Polarisierung der Gesellschaft (z.B. durch die Verstärkung kontroverser Narrative) sowie Erosion von Vertrauen (insbesondere in Medien, Wissenschaft, Demokratie und zwischenmenschliche Beziehungen). Die Wirkungsrichtung ist dabei sowohl horizontal (Lager spalten, Gemeinschaften auseinanderbringen) als auch vertikal (Vertrauensverhältnis zwischen Bürgerinnen und Bürger und Staat/Eliten schwächen). In Einzelfällen können KI-basierte Desinformationen sogar reale Konflikte befeuern.

**Psychologische und soziale Wirkmechanismen**

Warum wirken KI-Fakes so stark? Studien und Übersichtsarbeiten nennen mehrere psychologische und soziale Mechanismen:

Ein zentraler Punkt sind **emotionale Trigger**: KI kann gezielt Inhalte erzeugen, die starke Gefühle wie Angst, Wut oder Empörung auslösen. Solche emotionalen Botschaften werden besonders schnell geglaubt und weiterverbreitet.

Ein weiterer Mechanismus ist der sogenannte **Truth Effect**, oder auch „illusorischer Wahrheitseffekt“. Damit ist gemeint: Je öfter wir eine Information hören oder sehen, desto glaubwürdiger erscheint sie uns – auch wenn sie eigentlich falsch ist. Social Bots und Fake-Profile können diese Wiederholung gezielt steuern und so Desinformation besonders wirksam machen.

Dann gibt es noch die **Liar’s Dividend**, auf Deutsch die „Lügnerdividende“: Das bedeutet, dass allein die Existenz von Deepfakes dazu führt, dass auch echte Beweise leicht als Fälschung abgetan werden können. Wer zum Beispiel mit belastendem Material konfrontiert wird, könnte einfach behaupten: „Das Video könnte ja KI-generiert sein.“

Ein weiteres Prinzip ist die **Hyperpersonalisierung** oder das sogenannte Mikrotargeting. Das heißt: KI kann Botschaften individuell auf einzelne Personen zuschneiden, je nach Interessen oder Ansichten. Dadurch entstehen sogenannte Filterblasen oder Echokammern, in denen die eigenen Überzeugungen immer wieder bestätigt werden und andere Sichtweisen kaum noch vorkommen.

Schließlich gibt es noch den **Vertrauensmissbrauch durch KI-Interaktion**: KI-basierte Chatbots oder Avatare können sich in Online-Diskussionen als echte Menschen ausgeben, bauen Vertrauen auf und können dann gezielt Desinformation platzieren.

All diese Mechanismen wirken zusammen und machen es immer schwieriger, Fakes und echte Informationen voneinander zu unterscheiden.

**Gesellschaftliche Folgen und Herausforderungen**

Die Folgen KI-gestützter Desinformation gehen weit über Einzelfälle hinaus und betreffen zentrale Grundlagen von Demokratie, Gesellschaft und Bildung: Der öffentliche Diskurs wird geschwächt, weil sachliche Debatten von Fake-Behauptungen überlagert werden. Es kommt zu einem Vertrauensverlust gegenüber Medien, Institutionen und Mitmenschen. Demokratische Prozesse werden gefährdet, wenn Wahlen oder Entscheidungsfindungen durch Fakes beeinflusst oder delegitimiert werden. Auch Medien- und KI-Kompetenz werden dadurch immer wichtiger, denn selbst Expertinnen und Experten, Lehrkräfte oder Journalistinnen und Journalisten können Echtheit nicht mehr sicher bewerten.

KI-Fakes können darüber hinaus Suchmaschinen, soziale Medien und sogar Warnsysteme mit Spam und Fehlinformationen überfluten. Daraus kann eine generelle Desensibilisierung gegenüber Wahrheit entstehen, was langfristig demokratische Strukturen, gesellschaftlichen Frieden und das Vertrauen in die Technik gefährden kann.

Das Besondere an KI-Desinformation ist die Verbindung von Quantität, Qualität und Undurchschaubarkeit. Während früher klassische Propaganda begrenzt und meist leichter erkennbar war, sind KI-basierte Fälschungen massiv skalierbar, automatisierbar, technisch und psychologisch überzeugend und kaum noch eindeutig als Fakes zu entlarven. Dadurch ist die Gesellschaft als Ganzes gefordert, neue Strategien zu entwickeln: Fakten zu prüfen, Quellen kritisch zu hinterfragen und einen bewussteren Umgang mit digitalen Inhalten zu lernen. Die Herausforderungen sind groß, aber auch Gegenmaßnahmen – von technischer Detektion bis zur Stärkung der Medien- und KI-Kompetenz in Schule und Gesellschaft – entwickeln sich weiter. Die OECD empfiehlt in ihrem „AI Literacy Framework for Primary and Secondary Education“ aus dem Jahr 2025, dass Medienkompetenz zur Grundvoraussetzung für gesellschaftliche Teilhabe im KI-Zeitalter wird.

---

### Umgang mit Manipulationsmechanismen

Praxistipps zum Umgang mit KI-gestützter Desinformation profitieren erheblich von psychologischen und kommunikativen Erkenntnissen, die in aktuellen Analysen und Forschungsarbeiten bestätigt werden:

**Emotionale Distanz und kritisches Hinterfragen**
KI-generierte Desinformation zielt oft auf emotionale Aktivierung ab, um Nutzer:innen zu impulsiven Weiterleitungen oder Reaktionen zu verleiten. Fachportale empfehlen daher, bei besonders emotionalen oder dramatischen Inhalten innezuhalten und den Wahrheitsgehalt zu prüfen, bevor eine Weiterleitung oder ein "Like" erfolgt. Reißerische Sprache, die Gefühle wie Angst oder Wut erzeugt, ist ein typisches Warnsignal. Es wird geraten, sich die Fragen zu stellen: „Ist das plausibel?“ oder „Wem nützt diese Darstellung?“. Quellen und Absender sollten regelmäßig geprüft, Nachrichten mit anderen Medien abgeglichen und offizielle Faktenchecks genutzt werden.

**Umgang mit dem „Truth Effect“ (Wahrheitseffekt)**
Wird eine Aussage wiederholt, steigt unabhängig vom Wahrheitsgehalt die gefühlte Glaubwürdigkeit – auch bekannt als Truth Effect oder Illusory Truth Effect. Deshalb werden im Kontext politischer und gesellschaftlicher Desinformation gezielt identische Falschnachrichten über verschiedene Kanäle und Formate gestreut. Besonders wirksam ist Wiederholung über mehrere voneinander unabhängige Quellen (Konvergenzvalidität).
Der beste Praxistipp: Informationen, die sehr häufig und mit ähnlichen Argumentationsmustern auftauchen, sollten gezielt mit vertrauenswürdigen Quellen abgeglichen und besonders kritisch reflektiert werden. Höheres Alter und große Lebenserfahrung können Schutz bieten, da damit ein breiteres Faktenwissen für den Plausibilitätsabgleich zur Verfügung steht.

**Kompetenz- und Sensibilisierungsmaßnahmen**
Neben individuellen Strategien empfehlen Wissenschaft und Behörden eine Stärkung der Medien- und KI-Kompetenz in Schulen und der Allgemeinbevölkerung. Bildung und Sensibilisierung sind entscheidend, um die psychologischen Angriffspunkte von Desinformationskampagnen zu kennen und abzuwehren. Institutionen wie die Bundeszentrale für politische Bildung oder das Bildungsnetzwerk BMBF bieten Leitlinien und Schulungsmaterialien an. Diese Punkte werden auch von Bundesregierung und Forschungseinrichtungen ausdrücklich unterstützt. Sie zielen darauf ab, die individuellen und gesellschaftlichen Resilienzen gegenüber KI-gestützter Desinformation zu stärken und eine sachlichere Kommunikation im digitalen Raum zu fördern.

---

## Vertiefung

**„Systematische Manipulation sozialer Medien im Zeitalter der KI" (Bundeszentrale für politische Bildung, 2025)**
Diese aktuelle Publikation beleuchtet explizit die Verschmelzung von KI-Technologien mit systematischen Manipulationsstrategien in sozialen Medien. Der Artikel analysiert, wie Plattform-Algorithmen und KI die gezielte Verbreitung emotionalisierender Beiträge zur kollektiven Manipulation ermöglichen. Besonders relevant: Die Publikation zeigt auf, wie verschiedene Akteure – von staatlichen Organisationen bis zu Aktivisten – „algorithmische Kompetenz" entwickeln, um Plattformdynamiken strategisch für Desinformationskampagnen zu nutzen.

**„Künstliche Intelligenz in politischen Kampagnen" (Otto-Brenner-Stiftung, 2024)**
Diese Studie untersucht den konkreten Einsatz generativer KI in politischen Kampagnen und Desinformationsstrategien. Sie beschreibt drei wesentliche Bedenken: die Überflutung öffentlicher Kommunikationsräume mit KI-generierten Inhalten, die Polarisierung durch personalisierte Botschaften und das Missbrauchspotenzial für täuschend echte kompromittierende Inhalte. Besonders wertvoll für die Analyse von Akteuren und Techniken: Die Studie dokumentiert aktuelle Fallbeispiele des KI-Einsatzes in Wahlkämpfen.

**„Fake Facts – Wie Verschwörungstheorien unser Denken bestimmen" (Katharina Nocun und Pia Lamberty, 2020)**
Dieses Standardwerk legt ein solides Fundament für das Verständnis von Manipulationsmechanismen. Die Autorinnen erklären psychologische Grundlagen wie den „Truth Effect" und analysieren, wie sich Menschen aus der Mitte der Gesellschaft durch Falschinformationen radikalisieren können. Auch wenn KI-gestützte Techniken noch nicht im Fokus stehen, sind die Grundprinzipien der Manipulation zeitlos und helfen dabei, aktuelle KI-gestützte Desinformationsstrategien besser zu verstehen.

**Podcast „KI verstehen" (Deutschlandfunk) – „Deepfakes und Demokratie“**
Die Folge widmet sich der ernsthaften Bedrohung, die Deepfakes und KI für demokratische Wahlen darstellen. Im Fokus steht die Sorge, dass künstlich generierte Inhalte Verwirrung stiften und das Vertrauen in die Realität untergraben können. Es wird beleuchtet, wie generative KI zur Manipulation von Bildern, Tönen und Videos genutzt wird und Beispiele aus verschiedenen Ländern angeführt.

**Online-Spiel “Fake It To Make It”**
Das Spiel der Niedersächsischen Landeszentrale für politische Bildung versetzt die Spielenden selbst in die Rolle eines Fake-News-Produzenten. Sie erleben, wie sich Falschmeldungen gezielt erfinden, verbreiten und emotionalisieren lassen. Dadurch wird verständlich, nach welchen Mechanismen Desinformation funktioniert und welche psychologischen Tricks dabei eingesetzt werden.

---

## Stimmen aus der Praxis

Um Ihnen einen authentischen Einblick in die praktische Anwendung von KI zu geben, haben wir Expert*innen aus verschiedenen Bereichen zu Wort kommen lassen.

*(Mögliche Fragen)*
* Welche Chancen und Risiken siehst du im Einsatz von KI bei der Verbreitung von Informationen?
* Hat sich dein eigenes Verhalten im Umgang mit digitalen Informationen durch die Entwicklung von KI verändert?

---

## Transferaufgaben

**Selbstreflexion**
* **Eigene Anfälligkeit für Mikrotargeting einschätzen:** Überlegen Sie, welche Themen Sie emotional besonders ansprechen (z.B. Umwelt, Politik, Familie, Beruf). Könnten Sie sich vorstellen, dass jemand gezielt Falschinformationen zu genau diesen Themen streut, um Sie zu beeinflussen? Wie würden Sie reagieren, wenn eine scheinbar seriöse Quelle etwas behauptet, das Ihre größten Sorgen oder Hoffnungen anspricht?
* **Gesellschaftliche Rolle und persönliche Handlungsmöglichkeiten:** Wenn Sie an Ihre Familie, Freunde oder Kollegen denken: Wie könnten Sie dazu beitragen, dass auch sie kritischer mit digitalen Inhalten umgehen? Welche konkreten Schritte könnten Sie in Ihrem Umfeld unternehmen – als Privatperson, in der Schule, im Beruf oder in der Gemeinde?
* **Technologiebewertung und Zukunftsperspektive:** Wenn Sie alle Chancen und Risiken von KI-Technologie abwägen – überwiegen für Sie persönlich die Vorteile (z.B. kreative Unterstützung, Effizienz) oder die Gefahren (z.B. Desinformation, Manipulation)?

**Transferaufgabe**
* **Deepfake-Erkennung üben:** Besuchen Sie Webseiten wie *ThisPersonDoesNotExist.com*, die KI-generierte Porträts zeigen. Vergleichen Sie eines dieser Bilder mit einem echten Foto. Suchen Sie gezielt nach Merkmalen, die auf eine künstliche Erstellung hindeuten (z. B. Unstimmigkeiten im Hintergrund, bei Haaren oder Accessoires). Ziel: Schärfen Sie den Blick für typische Merkmale von KI-Bildern.
* **Faktencheck selbst ausprobieren:** Wählen Sie einen aktuellen Online-Beitrag oder Social-Media-Post, bei dem Sie den Verdacht haben, es könnte sich um Desinformation handeln. Prüfen Sie mit Faktencheck-Plattformen wie Correctiv, Mimikama oder dem Faktenfinder der Tagesschau nach, ob der Inhalt verifiziert oder widerlegt wurde. Notieren Sie Indizien und Ergebnis.
* **KI-Desinformation kreativ nachempfinden:** Nutzen Sie eine frei verfügbare KI-Anwendung, um ein kurzes, fiktives, harmloses Nachrichtenbeispiel zu erzeugen. Analysieren Sie: Wie glaubwürdig wirkt der Text oder das Bild? Welche Elemente machen ihn überzeugend? Zeigen Sie Ihr „Fake“ anderen und fragen Sie nach deren Einschätzung. Ziel: Selbst erleben, wie einfach täuschend echte Inhalte generiert werden können.

---

## Zusammenfassung

Das Modul „Techniken, Akteure und Manipulationspotenzial KI-gestützter Desinformation“ gibt einen umfassenden Einblick in die neuen Herausforderungen, die mit generativer KI für Informationsgesellschaft und Demokratie entstehen. Im Mittelpunkt steht die Frage, wie Künstliche Intelligenz die Erzeugung und Verbreitung von Falschinformationen verändert – und warum gerade KI-basierte Desinformation heute eine neue Dimension von Tempo, Authentizität und Reichweite erreicht.

Sie haben gelernt, wie generative KI-Modelle Texte, Bilder, Audios und Videos erschaffen, wie Social Bots, Content-Farmen und Fake-Accounts automatisiert Desinformation streuen und warum Deepfakes das Vertrauen in digitale Inhalte erschüttern können. Anhand zahlreicher Beispiele wurde deutlich, wie vielfältig die Akteure und Motive hinter KI-Desinformation sind: von staatlichen Akteuren über politische Gruppen bis hin zu Einzelpersonen, die gezielt Einfluss auf Meinungsbildung und gesellschaftlichen Zusammenhalt nehmen.

Ein besonderes Augenmerk lag auf den psychologischen und sozialen Wirkmechanismen – etwa dem Truth Effect oder der Liar’s Dividend – und darauf, wie KI-basierte Manipulationen das gesellschaftliche Klima, Wahlprozesse und das Vertrauen in Medien und Institutionen untergraben. Sie konnten nachvollziehen, dass Filterblasen, Echokammern und Mikrotargeting die gesellschaftliche Polarisierung verstärken und selbst erfahrene Mediennutzende vor neue Herausforderungen stellen.

Zugleich wurden aktuelle Gegenmaßnahmen und Strategien vorgestellt: von technischer Detektion über Faktenchecks bis zur gezielten Förderung von Medien- und KI-Kompetenz. Dabei wurde klar, dass ein kritischer, reflektierter Umgang mit digitalen Inhalten, das Prüfen von Quellen sowie eine bewusste Mediennutzung zentrale Schlüsselkompetenzen sind – nicht nur für Lehrende, sondern für alle Bürgerinnen und Bürger in einer demokratischen Gesellschaft.

Mit Abschluss dieses Moduls sind Sie in der Lage, die Funktionsweise und die Risiken von KI-gestützter Desinformation einzuordnen, typische Akteure und Wirkmechanismen zu erkennen sowie Handlungsstrategien für den Umgang mit digitalen Fakes zu entwickeln. Sie wissen um die Bedeutung von Medien- und KI-Kompetenz und sind gut vorbereitet, sich selbst, Ihre Lernenden oder Ihr Umfeld für die Herausforderungen einer durch KI geprägten Informationswelt zu sensibilisieren.

---

## Anschlüsse

**Fake News & DeepFakes – Niedersächsische Landeszentrale für politische Bildung**
Die Website bietet eine praxisnahe Einführung in das Thema Fake News, mit besonderem Fokus auf DeepFakes. Unter der Rubrik „DeepFakes – Von kreierten Wahrheiten und geschaffenen Realitäten“ wird anschaulich erklärt, wie mit KI-Technik manipulierte und täuschend echte Videos entstehen und welche Risiken sie bergen. Die Seite verbindet Hintergrundwissen mit aktuellen Beispielen und gibt konkrete Tipps für Alltag und Unterricht.

**KI-Kompetenzzentrum Niedersachsen (KiKoN) – Kompaktüberblick**
Das KI-Kompetenzzentrum Niedersachsen (KiKoN) ist ein geplantes Projekt, das Know-how zu Künstlicher Intelligenz in der Verwaltung bündeln soll. Im Mittelpunkt stehen Praxisprojekte mit KI sowie die gezielte Schulung von Mitarbeitenden – auch im Hinblick auf Risiken wie Deepfakes und KI-gestützte Desinformation. Die Planung sieht ab 2025/2026 eigene Veranstaltungen und Anlaufstellen vor.

---

## Abspann

**KI-Transparenzhinweis**
Wir praktizieren, was wir lehren! Dieses Lernangebot wurde bewusst mit KI-Technologien entwickelt – als lebendiges Beispiel für die Möglichkeiten moderner künstlicher Intelligenz. Unsere KI-Assistenten waren unsere Co-Kreativen:
* Perplexity AI gestaltete Struktur und Inhalte
* Gemini und NotebookLM recherchierte unterstützende Quellen
* ChatGPT schrieb Textentwürfe
* DeepL verfeinerte die Sprache

So zeigen wir: KI ist mehr als eine Technologie – sie ist ein mächtiges Werkzeug für Kreativität und Wissensarbeit. Eines bleibt dabei unverrückbar: Die menschliche Expertise und Verantwortung bilden die Grundlage.

**Letzte Aktualisierung**
Dieses Lernangebot wurde im September 2025 fertiggestellt und ist danach nicht mehr aktualisiert worden. Es liegt in der Natur des Internets, dass Webangebote und Links sich verändern oder nicht mehr verfügbar sind. Insofern bitten wir um Nachsicht, falls ein genanntes und/oder verlinktes Angebot nicht mehr erreichbar ist oder sich verändert hat.

**Kontakt**
Wenn Sie eine Frage oder eine Rückmeldung zu diesem Lernangebot haben, freuen wir uns, wenn Sie uns über service@nlc.info, Tel. 05121/1695-400 kontaktieren.

**Team**
* Verantwortlich seitens des NLQ: Christian Haake und Jörg Steinemann
* Konzeption, Redaktion: Jöran Muuß-Merholz, Blanche Fabri, Nicole Hagen, Frank Homp, Tessa Moje der Agentur J&K – Jöran und Konsorten
* Gesamtleitung: Blanche Fabri, Agentur J&K – Jöran und Konsorten
* Mitarbeit: Jula Henke, Pascal Fieseler, Ben Paetzold der Agentur J&K – Jöran und Konsorten

**Lizenzhinweise**
Dieses Angebot ist frei lizenziert und im Sinne von Open Educational Resources (OER) offen zur weiteren Verwendung, Veränderung, Weitergabe etc. Als Gesamtwerk steht er unter der Lizenz CC BY 4.0. Als Namensnennung im Sinne der Lizenz ist vorgesehen: „Agentur J&K – Jöran und Konsorten im Auftrag des Niedersächsischen Landesinstituts für schulische Qualitätsentwicklung (NLQ Hildesheim)“.

Einzelne Elemente des Angebots, zum Beispiel Abbildungen, Videos, Texte, können eigenständig unter anderen Lizenzbedingungen freigegeben sein, auch durch Dritte. In diesen Fällen ist dies im oder am jeweiligen Element angegeben. Screenshots und Screencasts werden im Sinne von Bildzitaten und/oder in der Annahme genutzt, dass die abgebildeten Inhalte keinen urheberrechtlichen Schutz beanspruchen können. Die darin abgebildeten Inhalte / Programme stehen i.d.R. nicht unter freier Lizenz und können nur weiterverwendet werden, solange sie im Sinne von Bildzitaten genutzt werden. Abgebildete Logos, Marken etc. stehen nicht unter freier Lizenz und sind unter Umständen zudem markenrechtlich geschützt.