WEBVTT

1
00:00:06.560 --> 00:00:09.880
Manipulationspotenziale, Wirkmechanismen

2
00:00:09.880 --> 00:00:11.520
und gesellschaftliche Folgen

3
00:00:11.520 --> 00:00:14.080
von KI gestützter Desinformation.

4
00:00:17.200 --> 00:00:19.960
Was macht KI-Desinformation eigentlich

5
00:00:19.960 --> 00:00:22.280
so gefährlich – und wie wirkt sie

6
00:00:22.280 --> 00:00:24.400
sich auf unser Zusammenleben aus?

7
00:00:24.400 --> 00:00:26.610
In diesem Abschnitt schauen wir auf

8
00:00:26.610 --> 00:00:29.130
die Potenziale, Wirkmechanismen und

9
00:00:29.130 --> 00:00:30.730
Folgen für unsere Gesellschaft.

10
00:00:31.450 --> 00:00:34.650
Mit dem Begriff „Manipulationspotenzial“

11
00:00:34.650 --> 00:00:36.810
wird die neue Stärke und Qualität

12
00:00:36.810 --> 00:00:39.410
der Beeinflussung beschrieben, die durch

13
00:00:39.410 --> 00:00:41.770
KI-gestützte Desinformation möglich wird.

14
00:00:42.330 --> 00:00:45.330
Während Propaganda, Gerüchte und Täuschung

15
00:00:45.330 --> 00:00:47.010
bereits früher Teil der Medienwelt

16
00:00:47.010 --> 00:00:49.770
waren, verleiht künstliche Intelligenz der

17
00:00:49.770 --> 00:00:52.570
Desinformation eine neue Skalierbarkeit,

18
00:00:53.110 --> 00:00:55.510
Authentizität und Flexibilität.

19
00:00:56.390 --> 00:00:59.390
KI-generierte Falschinformationen können

20
00:00:59.390 --> 00:01:02.190
heute schneller, massenhaft und täuschend

21
00:01:02.190 --> 00:01:04.790
echt produziert und verbreitet werden –

22
00:01:04.790 --> 00:01:07.310
personalisiert und oft schwerer zu

23
00:01:07.310 --> 00:01:09.590
erkennen als klassische Manipulation.

24
00:01:10.230 --> 00:01:12.910
Dadurch steigt das Potenzial, Menschen zu

25
00:01:12.910 --> 00:01:16.070
beeinflussen, in bisher unbekanntem Ausmaß.

26
00:01:16.630 --> 00:01:18.350
Im Unterschied zu früheren

27
00:01:18.350 --> 00:01:21.730
Manipulationsformen kann KI Inhalte in

28
00:01:21.730 --> 00:01:24.210
Echtzeit auf aktuelle Ereignisse

29
00:01:24.210 --> 00:01:27.010
zuschneiden, ganze Kampagnen automatisch

30
00:01:27.010 --> 00:01:30.250
steuern und wiederholt ausspielen, Die

31
00:01:30.250 --> 00:01:32.770
Täuschung visuell und akustisch perfekt

32
00:01:32.770 --> 00:01:36.010
erscheinen lassen (zum Beispiel Deepfakes)

33
00:01:36.010 --> 00:01:38.370
und gezielt auf individuelle Profile

34
00:01:38.370 --> 00:01:42.330
eingehen, das nennt sich Mikrotargeting.

35
00:01:42.330 --> 00:01:44.010
Die Eintrittsschwelle sinkt:

36
00:01:44.650 --> 00:01:47.050
Fast jede und jeder kann mit einfachen

37
00:01:47.050 --> 00:01:49.130
Tools überzeugende Fakes erzeugen.

38
00:01:49.860 --> 00:01:51.780
Die Verbreitung wird automatisiert

39
00:01:51.780 --> 00:01:53.940
und durch Social Bots beschleunigt.

40
00:01:54.660 --> 00:01:56.740
Damit entsteht eine neue Dimension

41
00:01:56.740 --> 00:01:58.420
der Manipulationsgefahr.

42
00:02:01.460 --> 00:02:03.700
Das Spektrum der möglichen Ziele ist breit:

43
00:02:04.580 --> 00:02:07.580
Politische Destabilisierung, zum Beispiel

44
00:02:07.580 --> 00:02:10.419
Zweifel an Wahlen, Diskreditierung von

45
00:02:10.419 --> 00:02:13.940
Institutionen, Wahlbeeinflussung, zum

46
00:02:13.940 --> 00:02:16.340
Beispiel Diffamierung von Kandidierenden,

47
00:02:17.120 --> 00:02:19.640
Mobilisierung oder Demobilisierung von

48
00:02:19.640 --> 00:02:22.640
Wählergruppen, Diskreditierung von Personen

49
00:02:23.200 --> 00:02:25.840
oder Institutionen (zum Beispiel durch

50
00:02:25.840 --> 00:02:28.920
gefälschte Skandal-Videos), Fragmentierung

51
00:02:28.920 --> 00:02:31.720
und Polarisierung der Gesellschaft, zum

52
00:02:31.720 --> 00:02:34.080
Beispiel dach die Verstärkung kontroverser

53
00:02:34.080 --> 00:02:37.200
Narrative sowie Erosion von Vertrauen,

54
00:02:37.760 --> 00:02:40.400
insbesondere in Medien, Wissenschaft,

55
00:02:40.400 --> 00:02:42.760
Demokratie und zwischenmenschliche

56
00:02:42.760 --> 00:02:43.360
Beziehungen.

57
00:02:44.250 --> 00:02:46.170
Die Wirkungsrichtung ist dabei sowohl

58
00:02:46.170 --> 00:02:48.850
horizontal, sprich Lagerspalten,

59
00:02:48.850 --> 00:02:51.690
Gemeinschaften auseinanderbringen, als auch

60
00:02:51.690 --> 00:02:54.490
vertikal, indem das Vertrauensverhältnis

61
00:02:54.490 --> 00:02:56.010
zwischen Bürgerinnen bzw.

62
00:02:56.010 --> 00:02:57.770
Bürgern und Staat bzw.

63
00:02:57.770 --> 00:02:59.689
Eliten geschwächt wird.

64
00:02:59.689 --> 00:03:01.610
In Einzelfällen können

65
00:03:01.610 --> 00:03:03.770
KI-basierte Desinformationen sogar

66
00:03:03.770 --> 00:03:05.530
reale Konflikte befeuern.

67
00:03:08.890 --> 00:03:11.450
Warum wirken KI-Fakes so stark?

68
00:03:12.000 --> 00:03:13.800
Studien und Übersichtsarbeiten

69
00:03:13.800 --> 00:03:15.560
nennen mehrere psychologische

70
00:03:15.560 --> 00:03:17.520
und soziale Mechanismen:

71
00:03:17.520 --> 00:03:20.640
Ein zentraler Punkt sind emotionale Trigger:

72
00:03:20.640 --> 00:03:23.480
KI kann gezielt Inhalte erzeugen,

73
00:03:23.480 --> 00:03:25.600
die starke Gefühle wie Angst,

74
00:03:25.600 --> 00:03:28.720
Wut oder Empörung auslösen.

75
00:03:28.720 --> 00:03:30.600
Solche emotionalen Botschaften

76
00:03:30.600 --> 00:03:31.600
werden besonders schnell

77
00:03:31.600 --> 00:03:33.920
geglaubt und weiterverbreitet.

78
00:03:33.920 --> 00:03:35.480
Ein weiterer Mechanismus ist der

79
00:03:35.480 --> 00:03:38.500
sogenannte Truth Effekt, oder auch

80
00:03:38.500 --> 00:03:41.220
„illusorischer Wahrheitseffekt“.

81
00:03:41.220 --> 00:03:44.180
Damit ist gemeint: Je öfter wir eine Information

82
00:03:44.180 --> 00:03:46.060
hören oder sehen, desto

83
00:03:46.060 --> 00:03:48.340
glaubwürdiger erscheint sie uns –

84
00:03:48.340 --> 00:03:50.580
auch wenn sie eigentlich falsch ist.

85
00:03:50.580 --> 00:03:53.340
Social Bots und Fake-Profile können diese

86
00:03:53.340 --> 00:03:55.900
Wiederholung gezielt steuern und so

87
00:03:55.900 --> 00:03:58.980
Desinformation besonders wirksam machen.

88
00:03:58.980 --> 00:04:01.220
Dann gibt es noch die Liar’s Dividend,

89
00:04:01.220 --> 00:04:03.460
auf Deutsch die „Lügnerdividende“:

90
00:04:04.300 --> 00:04:05.940
Das bedeutet, dass allein die

91
00:04:05.940 --> 00:04:08.020
Existenz von Deepfakes dazu führt,

92
00:04:08.020 --> 00:04:10.140
dass auch echte Beweise leicht als

93
00:04:10.140 --> 00:04:11.900
Fälschung abgetan werden können.

94
00:04:12.620 --> 00:04:14.460
Wer zum Beispiel mit belastendem

95
00:04:14.460 --> 00:04:16.420
Material konfrontiert wird, könnte

96
00:04:16.420 --> 00:04:18.180
einfach behaupten: „das Video

97
00:04:18.180 --> 00:04:20.220
könnte ja KI-generiert sein.“

98
00:04:20.940 --> 00:04:22.420
Ein weiteres Prinzip ist die

99
00:04:22.420 --> 00:04:24.420
Hyperpersonalisierung oder das

100
00:04:24.420 --> 00:04:26.620
sogenannte Mikrotargeting.

101
00:04:26.620 --> 00:04:30.060
Das heißt, KI kann Botschaften individuell

102
00:04:30.060 --> 00:04:32.220
auf einzelne Personen zuschneiden,

103
00:04:32.220 --> 00:04:34.140
je nach Interessen oder Ansichten.

104
00:04:34.740 --> 00:04:37.300
Dadurch entstehen sogenannte Filterblasen

105
00:04:37.300 --> 00:04:39.860
oder Echokammern, in denen die eigenen

106
00:04:39.860 --> 00:04:42.420
Überzeugungen immer wieder bestätigt werden

107
00:04:42.420 --> 00:04:44.980
und andere Sichtweisen kaum noch vorkommen.

108
00:04:45.540 --> 00:04:46.780
Schließlich gibt es noch den

109
00:04:46.780 --> 00:04:49.460
Vertrauensmissbrauch durch KI-Interaktion.

110
00:04:50.179 --> 00:04:52.940
KI-basierte Chatbots oder Avatare

111
00:04:52.940 --> 00:04:54.780
können sich in Online Diskussionen

112
00:04:54.780 --> 00:04:57.140
als echte Menschen ausgeben, bauen

113
00:04:57.140 --> 00:04:59.100
Vertrauen auf und können dann

114
00:04:59.100 --> 00:05:01.220
gezielt Desinformation platzieren.

115
00:05:01.880 --> 00:05:04.080
All diese Mechanismen wirken zusammen

116
00:05:04.080 --> 00:05:05.640
und machen es immer schwieriger,

117
00:05:05.640 --> 00:05:07.480
Fakes und echte Informationen

118
00:05:07.480 --> 00:05:08.920
voneinander zu unterscheiden.

119
00:05:11.960 --> 00:05:15.000
Die Folgen KI gestützter Desinformation

120
00:05:15.000 --> 00:05:17.240
gehen weit über Einzelfälle hinaus

121
00:05:17.240 --> 00:05:19.480
und betreffen zentrale Grundlagen von

122
00:05:19.480 --> 00:05:21.880
Demokratie, Gesellschaft und Bildung:

123
00:05:22.520 --> 00:05:24.920
Der öffentliche Diskurs wird geschwächt,

124
00:05:24.920 --> 00:05:26.400
weil sachliche Debatten von

125
00:05:26.400 --> 00:05:28.360
Fake- Behauptungen überlagert werden.

126
00:05:29.160 --> 00:05:30.880
Es kommt zu einem Vertrauensverlust

127
00:05:30.880 --> 00:05:32.200
gegenüber Medien,

128
00:05:32.200 --> 00:05:34.280
Institutionen und Mitmenschen.

129
00:05:34.920 --> 00:05:36.640
Demokratische Prozesse werden

130
00:05:36.640 --> 00:05:38.520
gefährdet, wenn Wahlen oder

131
00:05:38.520 --> 00:05:40.440
Entscheidungsfindungen durch Fakes

132
00:05:40.440 --> 00:05:43.000
beeinflusst oder delegitimiert werden.

133
00:05:43.720 --> 00:05:46.280
Auch Medien- und KI-Kompetenz werden

134
00:05:46.280 --> 00:05:48.440
dadurch immer wichtiger, denn selbst

135
00:05:48.440 --> 00:05:51.480
Expertinnen und Experten, Lehrkräfte oder

136
00:05:51.480 --> 00:05:53.560
Journalistinnen und Journalisten

137
00:05:53.560 --> 00:05:55.960
können Echtheit nicht mehr sicher bewerten.

138
00:05:56.920 --> 00:05:59.080
KI-Fakes können darüber hinaus

139
00:05:59.080 --> 00:06:01.920
Suchmaschinen, soziale Medien und

140
00:06:01.920 --> 00:06:04.000
sogar Warnsysteme mit Spam und

141
00:06:04.000 --> 00:06:06.440
Fehlinformationen überfluten.

142
00:06:06.440 --> 00:06:08.280
Daraus kann eine generelle

143
00:06:08.280 --> 00:06:11.000
Desensibilisierung gegenüber Wahrheit

144
00:06:11.000 --> 00:06:13.960
entstehen, was langfristig demokratische

145
00:06:13.960 --> 00:06:16.080
Strukturen, gesellschaftlichen

146
00:06:16.080 --> 00:06:18.000
Frieden und das Vertrauen in

147
00:06:18.000 --> 00:06:19.960
die Technik gefährden kann.

148
00:06:19.960 --> 00:06:22.680
Das Besondere an KI-Desinformation

149
00:06:22.680 --> 00:06:24.440
ist die Verbindung von Quantität,

150
00:06:25.200 --> 00:06:28.000
Qualität und Undurchschaubarkeit.

151
00:06:28.000 --> 00:06:30.120
Während früher klassische Propaganda

152
00:06:30.120 --> 00:06:33.120
begrenzt und meist leichter erkennbar war,

153
00:06:33.120 --> 00:06:35.480
sind KI basierte Fälschungen massiv

154
00:06:35.480 --> 00:06:38.640
skalierbar, automatisierbar, technisch

155
00:06:38.640 --> 00:06:41.320
und psychologisch überzeugend und kaum

156
00:06:41.320 --> 00:06:43.840
noch eindeutig als Fakes zu entlarven.

157
00:06:44.400 --> 00:06:46.400
Dadurch ist die Gesellschaft als Ganzes

158
00:06:46.400 --> 00:06:49.520
gefordert, neue Strategien zu entwickeln:

159
00:06:49.520 --> 00:06:52.230
Fakten zu prüfen, Quellen kritisch

160
00:06:52.230 --> 00:06:54.830
zu hinterfragen und einen bewussteren

161
00:06:54.830 --> 00:06:57.230
Umgang mit digitalen Inhalten zu lernen.

162
00:06:57.870 --> 00:07:00.030
Die Herausforderungen sind groß,

163
00:07:00.030 --> 00:07:02.990
aber auch Gegenmaßnahmen – von technischer

164
00:07:02.990 --> 00:07:05.710
Detektion bis zur Stärkung der Medien-

165
00:07:05.710 --> 00:07:07.750
und KI-Kompetenz in Schule und

166
00:07:07.750 --> 00:07:09.630
Gesellschaft entwickeln sich weiter.

167
00:07:10.190 --> 00:07:12.990
Die OECD empfiehlt in ihrem

168
00:07:12.990 --> 00:07:15.070
„AI Literacy Framework for Primary

169
00:07:15.070 --> 00:07:19.470
and Secondary Education“ aus dem Jahr 2025,

170
00:07:19.470 --> 00:07:21.110
dass Medienkompetenz zur

171
00:07:21.110 --> 00:07:23.310
Grundvoraussetzung für gesellschaftliche

172
00:07:23.310 --> 00:07:26.110
Teilhabe im KI-Zeitalter wird.
