# M1.2-2 – Funktionsweise von KI

## Start: Worum geht es?

Dieses Lernangebot bietet eine fundierte Einführung in die Funktionsweise moderner KI-Systeme, insbesondere KI-Sprachmodelle, und behandelt zentrale Themen wie maschinelles Lernen, Transformer-Architekturen, Trainingsmethoden und ethische Herausforderungen. Es richtet sich an Lehrende und Personen in der Verwaltung und zielt darauf ab, ein reflektiertes Verständnis für KI zu fördern, um diese sinnvoll einzusetzen und kritisch zu hinterfragen.

Die Teilnehmenden sollen ein grundlegendes Verständnis für KI-Systeme entwickeln und deren Funktionsweise sowie Grenzen erkennen. Sie lernen, wie KI-Modelle trainiert und optimiert werden, und entwickeln Kompetenzen im kritischen Umgang mit KI-generierten Inhalten. Darüber hinaus wird die Fähigkeit gefördert, ethische Fragen zu reflektieren und KI-Anwendungen verantwortungsvoll in Bildungskontexten einzusetzen. Das Lernangebot umfasst unter anderem Grundlagen der KI, Trainingsparadigmen, Modelloptimierung sowie praktische Beispiele mit Soeka 2.0 und SoekaGPT. Ziel ist es, eine informierte Haltung gegenüber KI zu entwickeln, die technische Machbarkeit mit ethischer Verantwortung verbindet. Es konzentriert sich auf die Perspektive „Wie funktioniert KI?“ und richtet sich an Lehrkräfte, Personal in der Schulverwaltung oder Multiplikatoren und Multiplikatorinnen mit erstem Wissen über Künstliche Intelligenz und Large Language Modellen (LLM).

---

## Testen Sie Ihr Vorwissen

### Fragen

1.  Welche ethischen Herausforderungen werden im Zusammenhang mit KI genannt?
    * ✅ Diskriminierung durch Verzerrungen in Trainingsdaten
    * ✅ Transparenzprobleme durch „Black Box“-Systeme
    * ❌ Unmöglichkeit der Automatisierung von Entscheidungen
    * ❌ Mangel an Trainingsdaten für neuronale Netze

2.  Was bedeutet „Prompt Engineering“?
    * ✅ Die gezielte Gestaltung von Eingaben, um das Verhalten von KI-Modellen zu steuern
    * ❌ Das Training eines Modells mit neuen Daten
    * ❌ Die Entwicklung neuer KI-Architekturen
    * ✅ Eine Technik, die Lehrenden hilft, Prompts zu gestalten

3.  Welche Rolle spielt Reinforcement Learning from Human Feedback (RLHF)?
    * ✅ Es verbessert Modelle durch menschliches Feedback
    * ❌ Es ersetzt die Notwendigkeit eines Trainingsdatensatzes
    * ✅ Es hilft, Modelle besser an menschliche Werte anzupassen
    * ❌ Es automatisiert die Datenannotation vollständig

4.  Welche Aufgaben übernehmen Clickworker bei RLHF?
    * ✅ Bewertung von Antwortpaaren
    * ✅ Markierung problematischer Inhalte
    * ❌ Entwicklung neuer KI-Systeme
    * ❌ Erstellung von Trainingsdaten durch Programmierung

5.  Was sind Benchmarks in der KI?
    * ✅ Standardisierte Tests zur Bewertung von Sprachmodellen
    * ❌ Werkzeuge zur Entwicklung neuronaler Netze
    * ✅ Tests, die Fähigkeiten wie Sprachverständnis und logisches Denken prüfen
    * ❌ Programme zur automatischen Datenfilterung

6.  Was prüft der Massive Multitask Language Understanding (MMLU)-Test?
    * ✅ Allgemeines Wissen und Transferfähigkeit über verschiedene Fachgebiete hinweg
    * ❌ Nur mathematische Problemlösungen
    * ✅ Wissen aus MINT-Fächern, Geisteswissenschaften und Sozialwissenschaften
    * ❌ Nur logisches Schlussfolgern

7.  Welche Funktion hat das Masking bei Transformer-Modellen?
    * ✅ Ausblenden bestimmter Teile des Eingabetextes, um Vorhersagen zu verbessern
    * ❌ Erhöhung der Rechenleistung durch parallele Verarbeitung
    * ❌ Speicherung von Trainingsdaten für spätere Nutzung
    * ✅ Verhindern, dass das Modell Informationen „vorausnimmt“

8.  Was ist eine Herausforderung bei der Nutzung großer Sprachmodelle?
    * ✅ Hoher Energieverbrauch und Ressourcenbedarf beim Training und Einsatz
    * ❌ Unfähigkeit zur Verarbeitung natürlicher Sprache
    * ✅ Sensitivität gegenüber kleinen Änderungen im Prompt
    * ❌ Fehlende Unterstützung für multimodale Inhalte

9.  Was versteht man unter „Model Collapse“?
    * ✅ Qualitätsverlust durch Training mit KI-generierten Daten
    * ❌ Ein abruptes Ende des Trainingsprozesses
    * ❌ Fehlerhafte Datenannotation durch menschliche Nutzende
    * ✅ Abnahme der Kreativität und Präzision eines Modells

10. Wie können multimodale KIs im Bildungsbereich eingesetzt werden?
    * ✅ Übersetzung visueller Inhalte in gesprochene Sprache oder umgekehrt
    * ✅ Unterstützung kreativer Arbeit durch Kombination von Bild und Text
    * ❌ Ersetzen traditioneller Unterrichtsmethoden
    * ✅ Automatische Auswertung von Grafiken und Diagrammen

### Auswertung der Fragen

* **Einstieg (0-3 richtige Antworten):** Klasse, dass Sie sich an den Fragen versucht haben! Jetzt können Sie tiefer in die Materie eintauchen.
* **Fortgeschritten (4-7 richtige Antworten):):** Sie haben schon ein solides Grundwissen. Der Kurs wird Ihnen helfen, Themen weiter zu vertiefen.
* **Profi (8-10 richtige Antworten):** Beeindruckend! Ihr Wissen ist bereits fundiert. Der Kurs kann Ihnen eine Auffrischung und neue Impulse bieten.

---

## Grundlagen

Das Video bietet einen vertieften Einblick in die Funktionsweise moderner KI-Systeme – insbesondere der KI-Sprachmodelle – und erläutert zentrale Konzepte wie maschinelles Lernen, Transformer-Architekturen, Trainingsmethoden und ethische Herausforderungen. Im Fokus steht dabei, wie dieses Wissen Lehrkräften und Personen in der Bildungsverwaltung hilft, KI fundiert zu verstehen, sinnvoll einzusetzen und kritisch zu reflektieren – insbesondere anhand konkreter Beispiele wie Soeka und SoekaGPT. Dieses Video soll dazu beitragen, eine informierte und handlungsfähige Haltung gegenüber KI zu entwickeln – mit einem Fokus auf das, was technisch möglich, gesellschaftlich sinnvoll und bildungsrelevant ist. Für den sinnvollen Einsatz braucht es nicht nur Wissen über Technik, sondern auch ein Gespür für ethische und didaktische Herausforderungen. Dieses Skript soll helfen, beides miteinander zu verbinden.

### Warum ist das Thema wichtig?

Künstliche Intelligenz ist ein mächtiges Werkzeug – und ihre Bedeutung wächst kontinuierlich. Ein grundlegendes Verständnis ihrer Funktionsweise ist unerlässlich, um fundierte Entscheidungen treffen, Potenziale zu nutzen und Risiken einschätzen zu können. Dieses Wissen hilft dabei, KI nicht nur zu konsumieren, sondern aktiv, kritisch und reflektiert zu gestalten.

Gerade im schulischen und verwaltungstechnischen Kontext ist dieses Thema besonders relevant:

* **In der Schule** prägt KI zunehmend den Lernalltag – von der Erstellung von Unterrichtsmaterialien bis hin zu individualisiertem Feedback oder unterstützten Bewertungen. Mitarbeitende sollten in der Lage sein, die Funktionsweise, Möglichkeiten und Grenzen solcher Systeme zu verstehen, um Lernprozesse sinnvoll und verantwortungsvoll zu begleiten.
* **In der Bildungs- und Schulverwaltung** ist ein grundlegendes Verständnis von Künstlicher Intelligenz entscheidend, um zukünftige Entwicklungen aktiv mitgestalten zu können. KI wird zunehmend Einfluss auf Prozesse wie Datenanalyse, Entscheidungsunterstützung, automatisierte Kommunikation oder digitale Auskunftssysteme nehmen. Wer in Planung, Steuerung oder Beratung tätig ist, sollte daher einschätzen können, wie KI-Systeme funktionieren, welche Chancen sie bieten – und wo ihre Grenzen liegen, um eine informierte und handlungsfähige Haltung gegenüber KI einnehmen zu können.

### Die verschiedenen Aspekte im Detail

Das Video führt Sie durch acht Abschnitte mit thematisch aufeinander aufbauenden Themengebieten:

* Der erste Abschnitt vermittelt sowohl die **Grundprinzipien von Künstlicher Intelligenz** als auch ein grundlegendes Verständnis für KI – einschließlich der Abgrenzung zur klassischen Programmierung.
* Der Abschnitt **Von LLMs bis Transformer** erläutert Ihnen zentrale Funktionsprinzipien moderner Sprachmodelle und erklärt dabei Begriffe wie Embeddings, Positionskodierung und Maskierung.
* Im Abschnitt **Trainingsparadigmen und Modelloptimierung** werden Konzepte wie Pretraining, Finetuning, RAG sowie Gradient Descent und Loss-Funktion erläutert.
* **Feinabstimmung von KI-Modellen: Prompt Engineering, RLHF und die Rolle spezialisierter Berufe** setzt den Fokus auf Eingabegestaltung, System-Prompts, menschliches Feedback und die Berufsbilder hinter der Modelloptimierung.
* Der Abschnitt **Modellqualität und Benchmarks** zeigt, wie man die Leistung und Fairness von KI-Modellen anhand von Benchmarks und Rückmeldeschleifen bewerten kann.
* **Multimodale KI** gibt einen Einblick in Systeme, die nicht nur Text, sondern auch Bilder, Audio oder Video verarbeiten.
* Ein konkreter Praxisbezug folgt mit **Soeka 2.0 und SoekaGPT**. Diese Systeme erklären die Prinzipien Suchmaschine und Large Language Model didaktisch.
* Das Video schließt mit **Herausforderungen und offenen Fragen** von technischer Robustheit über ethische Aspekte und Ressourcenverbrauch bis hin zu rechtlichen Rahmenbedingungen.

---

## Ausarbeitung der verschiedenen Aspekte

### Grundprinzipien von Künstlicher Intelligenz

Künstliche Intelligenz ist ein Sammelbegriff für Verfahren, die das Ziel haben, Maschinen mit menschenähnlichen kognitiven Fähigkeiten auszustatten. Grundlage für KI sind **Algorithmen** – also eindeutige Handlungsvorschriften, die ein Problem schrittweise lösen.

In **klassischen Programmen** schreiben Entwickler und Entwicklerinnen alle Regeln explizit vor. Das System führt genau das aus, was ihm Schritt für Schritt vorgegeben wurde. So kennt zum Beispiel ein Taschenrechner eine feste Funktion zur Addition – er „weiß“ allerdings nicht, was Zahlen bedeuten, sondern befolgt definierte Rechenvorschriften.

In der **KI** – insbesondere beim maschinellen Lernen – werden Regeln nicht vollständig vorgegeben, sondern das System lernt aus Daten. Die Maschine erkennt Muster, Zusammenhänge und Regularitäten eigenständig. Dadurch können KI-Systeme beispielsweise Gesichter erkennen, Sprache verarbeiten oder Texte schreiben. Das sind alles Aufgaben, die sich schwer in explizite Regeln fassen lassen.

**Maschinelles Lernen**, im Fachjargon **Machine Learning (ML)** genannt, ist ein Teilgebiet der KI, bei dem Systeme Muster aus Daten erkennen und sich dadurch verbessern können, ohne explizit programmiert zu sein.

**Deep Learning (DL)** ist wiederum eine spezielle Methode des maschinellen Lernens, bei der künstliche neuronale Netze mit vielen Schichten, daher „deep“, genutzt werden. Diese Netze ermöglichen besonders leistungsstarke Systeme – etwa bei Bilderkennung, Sprachverarbeitung oder autonomen Systemen.

Beispielhafte Lernverfahren sind das **überwachte Lernen**, bei dem anhand von Beispielen mit bekannten Ausgaben gelernt wird. Beim **unüberwachten Lernen** geht es um die Entdeckung von Mustern in unmarkierten Daten. **Bestärkendes Lernen** hingegen bezeichnet das Lernen durch Belohnung oder Strafe in Interaktion mit einer Umgebung.

---

### Von LLMs bis Transformer – Technischer Einblick

Moderne KI-Modelle wie GPT, Claude oder Gemini basieren auf der sogenannten **Transformer-Architektur**. Diese Architektur ist ein spezieller Aufbau eines neuronalen Netzes, der entwickelt wurde, um besonders effizient mit Textdaten umzugehen. Im Gegensatz zu älteren Architekturen verzichtet der Transformer vollständig auf eine sequenzielle Verarbeitung und setzt stattdessen auf eine parallele Verarbeitung von Daten.

Transformer-Modelle können nicht nur die Reihenfolge von Wörtern berücksichtigen, sondern auch komplexe Abhängigkeiten in sehr langen Texten erkennen. Ihr Kernmechanismus ist die **Self-Attention** (Selbstaufmerksamkeit), mit der das Modell selbst entscheidet, welche Wörter in einem Satz besonders wichtig füreinander sind. Die Transformer-Architektur bildet die Grundlage für viele aktuelle KI-Modelle – nicht nur im Textbereich, sondern auch für Bild, Ton und multimodale Anwendungen.

Wichtige Teilkomponenten dieser Architektur sind sogenannte **Embeddings** (Einbettungen). Hierbei werden Wörter oder Tokens in Vektoren mit numerischen Werten umgewandelt. Diese Vektoren repräsentieren die Bedeutung der Wörter im Kontext. Ähnliche Wörter haben ähnliche Vektoren. Das Modell „versteht“ Sprache nicht im menschlichen Sinn, sondern über diese mathematische Darstellung semantischer Beziehungen.

Eine weitere Komponente ist das **Position Encoding** (Positionskodierung). Da das Transformer-Modell keine Reihenfolge der Tokens „kennt“, wird jedem Token eine Positionsinformation hinzugefügt. Diese Kodierung stellt sicher, dass das Modell weiß, welches Wort zuerst kam und welches danach, was für Grammatik und Bedeutung wichtig ist.

Beim **Masking** (Maskierung) der Textgenerierung werden hingegen bestimmte Teile des Eingabetextes maskiert – also vorübergehend ausgeblendet – damit das Modell nur vorherige Wörter sieht und das nächste sinnvoll vorhersagen kann. Dies verhindert, dass das Modell Informationen „vorausnimmt“.

---

### Trainingsparadigmen und Modelloptimierung

Trainingsparadigmen und Modelloptimierung bilden das Rückgrat moderner KI-Entwicklung. Sie bestimmen, wie Modelle aus Daten lernen, an spezifische Aufgaben angepasst werden und ihr Wissen gezielt ergänzen.

Beim sogenannten **Pre-Training** (Vortraining) werden Sprachmodelle auf riesigen Textmengen trainiert. Das sind beispielsweise Texte aus dem Internet, aus Büchern, Foren oder wissenschaftlichen Datenbanken. Die Daten werden automatisiert gesammelt und gefiltert, um möglichst viele sprachliche Muster zu erfassen. Ziel ist es, ein generelles Sprachverständnis zu entwickeln. Die Modelle lernen dabei zum Beispiel, das nächste Wort in einem Satz vorherzusagen.

Im anschließenden **Fine-Tuning** werden die Modelle für spezifische Aufgaben weitertrainiert. Dies geschieht mit einer kleineren, gezielt kuratierten Datenbasis. So kann ein Modell beispielsweise für juristische Texte, medizinische Anfragen oder schulische Verwaltungsvorgänge optimiert werden. Beim Fine-Tuning werden oft auch ethische Regeln, Sprachstil oder Fachsprache angepasst.

Die Technik der **Retrieval-Augmented Generation (RAG)** kombiniert ein LLM mit einer externen Wissensquelle – zum Beispiel mit einer Suchmaschine oder Datenbank. Das Modell greift während der Antwortgenerierung auf aktuelle oder fachspezifische Informationen zu.

Das Training der Modelle basiert auf einem Optimierungsverfahren namens **Gradient Descent** (Gradientenabstieg). Dabei wird das Modell schrittweise angepasst, um die Fehlerquote zu verringern. Grundlage ist die sogenannte **Loss-Funktion** (Verlustfunktion). Sie misst, wie weit die Modellvorhersage von der tatsächlichen Antwort abweicht. Je größer die Abweichung, desto höher der Fehlerwert, sprich der Loss. Der Algorithmus berechnet nun die Richtung, in der die Modellparameter verändert werden müssen, um den Fehler zu verringern. In kleinen Schritten wird das Modell so immer besser darin, korrekte Vorhersagen zu treffen. Dieser Prozess wiederholt sich millionenfach, bis das Modell ein stabiles Leistungsniveau erreicht hat.

---

### Feinabstimmung von KI-Modellen: Prompt Engineering, RLHF und die Rolle spezialisierter Berufe

Nach dem Training eines KI-Modells beginnt die entscheidende Phase der Feinabstimmung. Techniken wie **Prompt Engineering** und **Reinforcement Learning from Human Feedback (RLHF)** sowie die Arbeit spezialisierter Fachkräfte tragen dazu bei, die Qualität der Ausgaben zu optimieren und Modelle besser an menschliche Bedürfnisse anzupassen.

**Prompt Engineering** zeigt, wie gezielte Eingaben das Verhalten von KI-Modellen steuern können – eine wertvolle Technik für Mitarbeitende, die Prompts gestalten oder andere im Umgang mit KI anleiten möchten. Die Qualität der LLM-Antwort hängt stark von der Eingabe ab – also vom sogenannten **Prompt**. Ein Prompt ist die direkte Eingabe, die Nutzende formulieren, um das Modell zu einer Antwort zu bewegen.

**System-Prompts** hingegen sind unsichtbare Anweisungen im Hintergrund, die das generelle Verhalten des Modells steuern. Sie legen beispielsweise fest, ob ein Modell freundlich, sachlich oder vorsichtig antwortet. Auch Einschränkungen wie „Antworte nur auf Fragen zu Schulrecht in Niedersachsen“ können im System-Prompt definiert sein. Nutzende sehen diesen Teil des Prompts in der Regel nicht.

**Reinforcement Learning from Human Feedback (RLHF)** ist eine Methode, um Modelle mithilfe menschlichen Feedbacks zu verbessern. Dabei bewerten Menschen die Antworten eines Modells – zum Beispiel in Bezug auf Korrektheit, Verständlichkeit oder ethische Angemessenheit. Diese Bewertungen dienen als Grundlage für ein weiteres Training des Modells, bei dem es lernt, bevorzugte Antworten häufiger zu geben und problematische zu vermeiden.

RLHF erfordert die Zusammenarbeit verschiedener Fachkräfte:

* **AI-Trainierende** bewerten Modellantworten und geben Rückmeldungen dazu, welche Varianten besser oder schlechter sind.
* **Prompt Engineers** entwerfen Prompts, um Antworten für das menschliche Feedback im RLHF-Prozess zu generieren.
* **Machine Learning Engineers** setzen die technische Infrastruktur um, um menschliches Feedback in den Optimierungsprozess eines vortrainierten Modells zu integrieren.
* **Ethik-Experten und -Expertinnen** bewerten die Antworten auf ethische Implikationen und tragen zur Entwicklung angemessener Bewertungsrichtlinien bei.
* **Produktmanagende** koordinieren den gesamten Feedbackprozess und sorgen dafür, dass die Ergebnisse aus dem RLHF in Einklang mit den Produktzielen stehen.
* **Clickworker** übernehmen einfache, wiederholbare Aufgaben wie das Bewerten von Antwortpaaren oder das Markieren von problematischen Inhalten.

---

### Modellqualität und Benchmarks

Wie wird die Leistungsfähigkeit eines LLMs gemessen? Mit sogenannten **Benchmark-Tests**. **Benchmarks** sind standardisierte Tests, mit denen Sprachmodelle verglichen und bewertet werden können. Sie enthalten speziell konstruierte Aufgaben, die bestimmte Fähigkeiten prüfen, zum Beispiel Sprachverständnis, logisches Denken, Faktenwissen oder mathematisches Problemlösen.

Beispiele für Benchmarks sind:

* **MMLU** (Massive Multitask Language Understanding): Ein Fragetest mit über 50 Fachgebieten, der allgemeines Wissen und Transferfähigkeit prüft.
* **HellaSwag**: Testet logisches Schließen in Alltagssituationen, z. B. durch Auswählen der plausibelsten Fortsetzung eines Textes.
* **SuperGLUE**: Umfasst acht verschiedene Aufgaben, die unterschiedliche Aspekte des Verständnisses natürlicher Sprache testen, darunter Koreferenzauflösung und logisches Schlussfolgern.

**Human-in-the-Loop** spielt eine zentrale Rolle bei der Optimierung von KI-Systemen, indem echtes Nutzendenfeedback genutzt wird, um die Zuverlässigkeit und Qualität der Ausgaben zu verbessern. Dieses Feedback kann aus der Bewertung von Antworten mit „Daumen hoch“ oder „Daumen runter“ oder aus der Markierung von falschen oder unangemessenen Inhalten bestehen.

---

### Multimodale KI

Multimodale KI eröffnet neue didaktische Möglichkeiten, indem sie kreative und barrierearme Unterrichtsformen unterstützt und so den Zugang zu Bildung für alle erleichtert. Sie kann auch in der Verwaltung eingesetzt werden, um Prozesse effizienter zu gestalten.

Neue Modelle wie **GPT-4V** oder **Gemini** sind **multimodal** – sie verarbeiten und erzeugen Text, Bild, Audio oder Video gleichzeitig. Dadurch erweitern sich die Fähigkeiten der KI-Systeme weit über klassische Text-LLMs hinaus. Klassische LLMs wie GPT-3 sind auf Sprache spezialisiert und können keine Bilder interpretieren oder Töne erzeugen. Multimodale Modelle hingegen können zum Beispiel eine Bildbeschreibung erstellen, auf ein gesprochenes Audio antworten oder Text und Bild kombinieren.

Technisch basiert multimodale KI häufig auf der Kombination spezialisierter Modelle wie einem **Bild-Encoder** und **Sprachdecoder**. Ein Bild-Encoder ist ein Teilmodell, das ein Bild analysiert und in eine strukturierte Form bringt, die ein anderes Modell weiterverarbeiten kann. Ein Sprachdecoder ist ein Modul, das diese Informationen nutzt, um Sprache zu erzeugen. Im Grunde ist ein Sprachdecoder ein LLM oder ein vergleichbares Sprachmodell, das auf Basis der „verstandenen“ Inhalte Text generiert.

Anwendungsbeispiele multimodaler Systeme:

* **Inklusiven Bildung**: Visuelle Inhalte in gesprochene Sprache übersetzen oder umgekehrt.
* **Kunst- und Designbereich**: Unterstützung kreativer Arbeit durch das Kombinieren von Bild- und Textideen.
* **Wissenschaft**: Automatische Auswertung von Grafiken, Diagrammen und Tabellen.

---

### Praxisbeispiel: Soeka 2.0 und SoekaGPT

Nachdem bisher die technologischen Grundlagen von KI sowie deren Anwendungen und Herausforderungen betrachtet wurden, stellt sich die Frage: Wie kann KI konkret in Bildungskontexten eingesetzt werden?. Besonders im schulischen und administrativen Alltag gibt es Potenziale, KI-Systeme zur Wissensvermittlung und zur Entlastung einzusetzen. Dabei spielen didaktische Tools wie **Soeka 2.0** und **SoekaGPT** eine zentrale Rolle. Sie wurden speziell entwickelt, um Lehrenden und Lernenden ein besseres Verständnis für die Funktionsweise von KI zu vermitteln.

**Soeka 2.0** funktioniert wie eine spezialisierte Suchmaschine und nutzt semantische Technologien, um nicht nur Schlagwörter, sondern Bedeutungszusammenhänge zu erkennen. Dadurch liefert es gezieltere und kontextrelevantere Ergebnisse als eine klassische Volltextsuche. Besonders hilfreich ist, dass Soeka 2.0 mit eigenen Inhalten wie zum Beispiel Schulrecht, Verwaltungstexte oder Curricula ergänzt werden kann. Dadurch lässt sich das System an spezifische Informationsbedarfe anpassen.

**SoekaGPT** ist ein didaktisches Sprachmodell, das speziell für den Einsatz im Unterricht entwickelt wurde. Es dient dazu, Lernenden und Mitarbeitenden die Funktionsweise von KI-Sprachmodellen wie ChatGPT verständlich zu machen. Das System arbeitet mit einem kontrollierten Textkorpus, der gezielt angepasst werden kann, beispielsweise durch das Hinzufügen eigener Inhalte wie Märchen oder Fachtexte. Anders als große Sprachmodelle basiert SoekaGPT nicht auf neuronalen Netzen, sondern auf statistischen Methoden und ermöglicht so einen interaktiven Blick hinter die Kulissen der Textgenerierung.

Der didaktische Mehrwert von Soeka 2.0 und SoekaGPT liegt in der intuitiven Bedienung. Sie eignen sich besonders zur Förderung von KI-Kompetenz in der Aus- und Fortbildung. Dabei werden Kompetenzen gefördert wie: das Verständnis von Funktionsweise und Grenzen von KI, der kritische Umgang mit KI-generierten Inhalten, die Reflexion über Datenquellen, Vertrauen und Transparenz in KI-Systemen, sowie der Transfer auf den eigenen beruflichen Kontext.

---

### Herausforderungen und offene Fragen

Die Weiterentwicklung und der Einsatz von KI-Systemen bringen zahlreiche Herausforderungen mit sich – sowohl auf technischer, ethischer als auch rechtlicher Ebene. Um KI verantwortungsvoll zu nutzen und weiterzuentwickeln, ist ein kritischer Blick auf diese Aspekte unerlässlich.

#### Technische Herausforderungen

* **Ressourcenbedarf**: Das Training großer Modelle erfordert immense Rechenleistung, was mit hohem Strom- und Kühlbedarf einhergeht. Auch die Nutzung von KI-Modellen ist energieintensiv.
* **Robustheit**: Viele KI-Modelle reagieren empfindlich auf kleine Änderungen in der Eingabe – also auf minimale Variationen in den Prompts.
* **Model Collapse**: Wenn Modelle mit KI-generierten Inhalten weitertrainiert werden, kann es zu einem Qualitätsverlust kommen. Die „künstliche Sprache“ wird dann zur Trainingsbasis, was das Modell weniger nuanciert und kreativ macht.

#### Ethische Herausforderungen

* **Verantwortung**: Wer haftet für Entscheidungen, die auf KI-Empfehlungen beruhen?.
* **Diskriminierung und Bias**: KI-Modelle übernehmen Verzerrungen aus ihren Trainingsdaten, die zu Benachteiligung bestimmter Gruppen führen können.
* **Transparenz**: Viele Systeme gelten als „Black Boxes“, da die internen Entscheidungswege nicht nachvollziehbar sind.

#### Rechtliche Herausforderungen

* **Datenschutz**: Der Einsatz von KI darf personenbezogene Daten nicht verletzen, die strengen gesetzlichen Vorgaben, wie der DSGVO, unterliegen.
* **Urheberrecht**: Für das Training von KI werden häufig urheberrechtlich geschützte Werke verwendet. Es sind rechtliche Klärungen notwendig, wem KI-generierte Inhalte „gehören“.
* **EU AI Act**: Der geplante europäische Rechtsrahmen stuft bestimmte KI-Anwendungen als Hochrisiko-Systeme ein, wenn sie zur Bewertung von Schülerleistungen oder zur Auswahl von Bewerbenden eingesetzt werden.

---

### Fun Fact

Wenn du ein Sprachmodell bittest, ein Gedicht zu schreiben, wird es nicht in Reimen denken oder Erinnerungen treiben. Stattdessen wählt es Wort für Wort geschickt, was statistisch am besten in den Kontext passt und glückt. Es kennt Milliarden von Beispielen, die es studiert, doch echte Kreativität wird dabei nicht kreiert. Es ist keine Kunst, kein schöpferisches Licht, nur Statistik, die uns beeindruckende Texte verspricht.

---

## Vertiefung

### Vertiefendes Material

* **Wie Sprachmodelle denken: Ein Blick ins Innere von Claude 3.5**
    * Die Seite „On the Biology of a Large Language Model“ (englischsprachig) auf *transformer-circuits.pub* beschäftigt sich mit der Analyse der internen Mechanismen von großen Sprachmodellen, insbesondere Claude 3.5 Haiku. Ziel ist es, die oft als „Black Box“ wahrgenommenen Prozesse transparenter zu machen. Die Analyse nutzt sogenannte **Attribution Graphs**. Durch die Analyse konnten Forscher beispielsweise nachvollziehen, wie das Modell logische Schlussfolgerungen zieht oder Gedichte plant.

* **Model Collapse – Training mit KI-Inhalten**
    * Wenn Modelle mit synthetisch generierten Daten weitertrainiert werden, kann es zu einem Qualitätsverlust kommen. Konkrete Fälle des Model Collapse großer Modelle sind bisher selten veröffentlicht worden, aber in wissenschaftlichen Publikationen wird das Risiko als real und wachsend eingeschätzt. Studien zum Weiterlesen sind: *The Curse of Recursion: Training on Generated Data Makes Models Forget* oder *AI models collapse when trained on recursively generated data*.

* **Soeka 2.0 und SoekaGPT**
    * **Erklärvideo**: Das Video behandelt die didaktische Nutzung der Tools im Unterricht, um Lernenden den Umgang mit digitaler Technologie und KI näherzubringen.
    * **Soeka 2.0 Aufgaben**: Praxisnahe Übungen vermitteln die Funktionsweise von Suchmaschinen, von der Indexierung bis zur Rangierung der Ergebnisse.
    * **Handreichung für Lehrpersonen**: Bietet eine Einführung in die didaktische Suchmaschine und ihre Anwendung im Unterricht. Ziel ist es, Lehrkräften Werkzeuge zur Förderung digitaler Informationssuche an die Hand zu geben.
    * **SoekaGPT – Handreichung**: Ein didaktisches Dokument, das Lehrkräften eine Einführung in die Funktionsweise von Sprachmodellen und deren Einsatz im Unterricht bietet. Es stellt SoekaGPT als vereinfachtes, statistisches Sprachmodell vor.
    * **SoekaGPT – Vorstellung**: Der Artikel beschreibt, wie SoekaGPT entwickelt wurde, um die grundlegende Funktionsweise von statistischen Sprachmodellen zu vermitteln. Es nutzt bewusst vereinfachte Methoden, um einen Blick „unter die Motorhaube“ von Textgeneratoren zu ermöglichen.
    * **Erklärvideo für Lehrpersonal**: Das Video „Das Phänomen Textgeneratoren“ erklärt die Funktionsweise und den didaktischen Einsatz von SoekaGPT.

---

## Transferaufgaben

### Selbstreflexion

* **Explainable AI (XAI)**: Wie können KI-Systeme so gestaltet werden, dass ihre Entscheidungen nachvollziehbar und transparent sind?
* **Alignment & Constitutional AI**: Wie können Modelle sicherstellen, dass sie sich an gesellschaftliche, ethische oder rechtliche Werte halten?
* **Guardrails**: Welche technischen oder prozeduralen Sicherungsmechanismen sind notwendig, um problematische Inhalte zu verhindern?
* Wie verändert sich eine Antwort durch kleine Änderungen im Prompt?
* Wie verändert sich der Unterricht mit multimodaler KI?

### Transferaufgabe

* **Vergleich von SoekaGPT mit ChatGPT**:
    * Beschreiben Sie die grundlegenden Unterschiede zwischen SoekaGPT und ChatGPT in Bezug auf Funktionsweise, Datenbasis und Einsatzmöglichkeiten.
    * Diskutieren Sie, welche Vorteile und Nachteile die beiden Modelle jeweils für den Unterricht bieten.
* **Analyse von Schwächen**:
    * Identifizieren Sie Schwächen von SoekaGPT, wie Wissenslücken oder Kontextverlust, und erklären Sie, wie diese Schwächen die Qualität der generierten Texte beeinflussen.
* **Reflexion: Was macht eine KI vertrauenswürdig?**
    * Diskutieren Sie, welche Eigenschaften eine KI haben muss, um als vertrauenswürdig zu gelten (zum Beispiel Transparenz, Konsistenz, ethische Ausrichtung).
    * Überlegen Sie, wie technische Mechanismen wie Bias-Korrektur oder Guardrails dazu beitragen können, das Vertrauen in KI-Systeme zu stärken.

### Interaktive Aufgaben

1.  **Prompt-Tuning-Workshop**:
    * **Aufgabe**: Entwickeln und optimieren Sie gezielt Prompts, um die Antworten eines KI-Sprachmodells (zum Beispiel SoekiaGPT oder ChatGPT) zu verbessern.
    * **Schritte**:
        * Generieren Sie mit einem Basis-Prompt eine Antwort.
        * Modifizieren Sie den Prompt schrittweise und vergleichen Sie die Ergebnisse.
        * Dokumentieren Sie, wie sich kleine Änderungen im Prompt auf die Qualität der Antwort auswirken.
2.  **Analyseübungen zu Bias und Diskriminierung**:
    * **Aufgabe**: Analysieren Sie KI-Antworten auf potenzielle Verzerrungen (Bias) oder diskriminierende Aussagen.
    * **Schritte**:
        * Stellen Sie einem Sprachmodell Fragen zu sensiblen Themen.
        * Identifizieren Sie problematische Aussagen und diskutieren Sie, welche Trainingsdaten diese verursacht haben könnten.
        * Entwickeln Sie Strategien, um solche Verzerrungen zu reduzieren.
3.  **Rollenspiel: Verantwortung für KI-Entscheidungen**:
    * **Aufgabe**: Simulieren Sie eine Debatte zur Frage „Wer haftet für KI-gesteuerte Entscheidungen?“.
    * **Rollen**: Entwickler oder Entwicklerin des KI-Modells, Nutzende, Jurist oder Juristin, Ethik-Experte oder -Expertin.
    * **Ziel**: Erarbeiten Sie gemeinsam Lösungsvorschläge für Haftungsfragen und ethische Richtlinien.
4.  **Szenarienentwicklung: KI in der eigenen Institution**:
    * **Aufgabe**: Entwerfen Sie ein Konzept für den verantwortungsvollen Einsatz von KI in Ihrer Schule/Organisation.
    * **Aspekte**: Welche Aufgaben könnten sinnvoll durch KI unterstützt werden? Welche Sicherheitsmechanismen (Guardrails) sind notwendig? Wie wird Transparenz (XAI) gewährleistet?.
5.  **Alignment & Constitutional AI**:
    * **Aufgabe**: Erstellen Sie ein „Wertepapier“ für ein fiktives KI-Modell, das ethische Richtlinien festlegt.
6.  **Guardrails-Experiment**:
    * **Aufgabe**: Implementieren Sie einfache „Leitplanken“ für ein KI-System.
7.  **Interaktive Bias-Erkennung**:
    * **Aufgabe**: Untersuchen Sie KI-generierte Texte auf geschlechterstereotype Formulierungen.
    * **Methode**: Analysieren Sie, ob bestimmte Berufe stereotyp mit Geschlechtern verknüpft werden.

---

## Zusammenfassung & Glossar

### Zusammenfassung

Das Lernangebot **„Funktionsweise von KI“** bietet eine umfassende Einführung in die Funktionsweise moderner KI-Systeme. Es beleuchtet technische Grundlagen, Trainingsmethoden sowie ethische und didaktische Herausforderungen. Ziel ist es, Lehrenden und Personen in der Verwaltung ein fundiertes Verständnis zu vermitteln. Das Lernangebot beginnt mit den Grundlagen der KI, darunter maschinelles Lernen und die Transformer-Architektur. Es erklärt, wie KI-Systeme durch Daten lernen und welche Mechanismen wie Embeddings, Positionskodierung und Masking dabei eine Rolle spielen. Es werden Trainingsparadigmen wie Pretraining, Finetuning und Retrieval-Augmented Generation (RAG) vorgestellt. Ein zentraler Abschnitt widmet sich der Feinabstimmung von Modellen, einschließlich Prompt Engineering und Reinforcement Learning from Human Feedback (RLHF). Ergänzend wird erläutert, wie Benchmarks wie MMLU oder HellaSwag genutzt werden, um die Qualität von Modellen zu bewerten.

Das Lernangebot geht auch auf multimodale KI-Systeme wie GPT-4V oder Gemini ein, die Text-, Bild-, Audio- und Videodaten gleichzeitig verarbeiten können. Als konkrete didaktische Werkzeuge werden Soeka 2.0 (eine spezialisierte Suchmaschine) und SoekaGPT (ein vereinfachtes Sprachmodell) vorgestellt. Ethik, Bias, Transparenz und rechtliche Aspekte wie Datenschutz, Urheberrecht und der EU AI Act werden ebenfalls thematisiert.

### Glossar

* **Glossar KI**

---

## Anschlüsse

### Rechtliche und ethische Dimension

In den Lernangeboten **M1.1 Datenschutz** und **M1.1 Urheberrecht** können Sie sich vertieft mit den Aspekten Datenschutz, DSGVO, EU AI Act und Urheberrecht auseinandersetzen. Zudem bieten die Angebote **M3.1 KI und Ethik: Chancen und Risiken der KI-Nutzung** und **M3.1 Ethik und Verantwortung: Zum Wechselverhältnis von Technologie und Gesellschaft** einen vertieften Einblick in die ethischen Aspekte im Zusammenhang mit KI.

---

## Abspann

### KI-Transparenzhinweis

Dieses Lernangebot wurde bewusst mit KI-Technologien entwickelt – als lebendiges Beispiel für die Möglichkeiten moderner künstlicher Intelligenz. Unsere KI-Assistenten waren unsere Co-Kreativen:

* **Perplexity AI** gestaltete Struktur und Inhalte
* **Gemini** und **NotebookLM** recherchierten unterstützende Quellen
* **ChatGPT** schrieb Textentwürfe
* **DeepL** verfeinerte die Sprache

So zeigen wir: KI ist mehr als eine Technologie – sie ist ein mächtiges Werkzeug für Kreativität und Wissensarbeit. Eines bleibt dabei unverrückbar: Die menschliche Expertise und Verantwortung bilden die Grundlage.

### Letzte Aktualisierung

Dieses Lernangebot wurde im März 2025 fertiggestellt und ist danach nicht mehr aktualisiert worden. Es liegt in der Natur des Internets, dass Webangebote und Links sich verändern oder nicht mehr verfügbar sind. Insofern bitten wir um Nachsicht, falls ein genanntes und/oder verlinktes Angebot nicht mehr erreichbar ist oder sich verändert hat.

### Kontakt

Wenn Sie eine Frage oder eine Rückmeldung zu diesem Lernangebot haben, freuen wir uns, wenn Sie uns im Forum oder Christian Haake über christian.haake@nlq.niedersachsen.de, Tel. +49 5121 1695151‬ kontaktieren.

### Team

* **Verantwortlich seitens des NLQ**: Christian Haake und Jörg Steinemann
* **Fachliche Beratung**: Ekkehard Brüggemann
* **Konzeption, Redaktion**: Jöran Muuß-Merholz, Blanche Fabri, Nicole Hagen, Frank Homp, Tessa Moje der Agentur J&K – Jöran und Konsorten
* **Gesamtleitung**: Blanche Fabri, Agentur J&K – Jöran und Konsorten
* **Mitarbeit**: Jula Henke, Pascal Fieseler, Ben Paetzold, Owais Alsayed Ahmad der Agentur J&K – Jöran und Konsorten

### Downloads

* Video Funktionsweise von KI [LINK ZUM VIDEO] von der Agentur J&K – Jöran und Konsorten im Auftrag des Niedersächsischen Landesinstituts für schulische Qualitätsentwicklung (NLQ Hildesheim) | Lizenz CC BY 4.0.
* Video Funktionsweise von KI – Stimmen aus der Praxis von NAMEN mit der Agentur J&K – Jöran und Konsorten im Auftrag des Niedersächsischen Landesinstituts für schulische Qualitätsentwicklung (NLQ Hildesheim) | Lizenz CC BY 4.0.

### Lizenzhinweise

Dieses Angebot ist frei lizenziert und im Sinne von Open Educational Resources (OER) offen zur weiteren Verwendung, Veränderung, Weitergabe etc.. Als Gesamtwerk steht es unter der Lizenz **CC BY 4.0**. Details zu dieser Lizenz finden Sie hier in Kurzform und hier ausführlich. Als Namensnennung im Sinne der Lizenz ist vorgesehen: „Agentur J&K – Jöran und Konsorten im Auftrag des Niedersächsischen Landesinstituts für schulische Qualitätsentwicklung (NLQ Hildesheim)“.

Einzelne Elemente des Angebots, zum Beispiel Abbildungen, Videos, Texte, können eigenständig unter anderen Lizenzbedingungen freigegeben sein, auch durch Dritte. In diesen Fällen ist dies im oder am jeweiligen Element angegeben.
