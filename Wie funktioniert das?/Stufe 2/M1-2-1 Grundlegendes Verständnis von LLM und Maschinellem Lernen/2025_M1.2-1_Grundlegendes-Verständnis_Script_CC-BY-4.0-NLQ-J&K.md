Das ist die bereinigte Markdown-Version des Skripts, die für die Veröffentlichung auf GitHub geeignet ist. Alle redaktionellen und produktionsbezogenen Anweisungen wurden entfernt, während die wesentlichen Inhalte und Hyperlinks beibehalten wurden.

# M1.2-1 Grundlegendes Verständnis von LLM und Maschinellem Lernen

## Start: Worum geht es?

Anhand eines einfachen Beispiels für Maschinelles Lernen (NIM-Spiel) verstehen Sie die Grundprinzipien, die hinter einem Sprachmodell wie ChatGPT stecken. Diese Grundprinzipien werden auf ein stark vereinfachtes Sprachmodell übertragen, um Ihnen zu zeigen, welche Promptingstrategien zum Erfolg führen und welche nicht. Zudem wird auf die Unterschiede zwischen traditioneller Programmierung und KI-Systemen eingegangen.

Nach Abschluss dieses Lernangebots werden Sie eine grundsätzliche Vorstellung davon haben, wie ein Sprachmodell wie zum Beispiel ChatGPT funktioniert und die Grundlage für eine bessere Promptingstrategie besitzen. Sie werden zudem Sprachmodellen Texte entlocken können, die bei unreflektierten Prompts gefiltert beziehungsweise stark verändert worden wären.

Dieses Angebot richtet sich sowohl an Menschen, die an Schulen aller Schultypen arbeiten, als auch an Mitarbeitende der Verwaltung, die ein Grundverständnis für die Funktion und die Nutzung von Large Language Modellen (LLMs) erhalten möchten. Gemäß des Frankfurt-Dreiecks konzentriert sich das Angebot im Kern auf die Perspektive: Wie funktioniert KI?

### Testen Sie Ihr Vorwissen

* Welche der folgenden Technologien sind Beispiele für Anwendungen von KI im Bildungsbereich?
  * A) Generative KI für Texterstellung
  * B) Maschinelles Lernen zur Automatisierung administrativer Prozesse
  * C) Bildgenerierende KI für visuelle Lernmaterialien
  * **Richtig:** A, B, C
* Welche Strategien können verwendet werden, um die Qualität von LLM-Ausgaben zu verbessern?
  * A) Mehrmalige Verwendung des gleichen Prompts
  * B) Auswahl des besten Ergebnisses aus mehreren Ausgaben
  * C) Verwendung von präzisen Eingaben
  * **Richtig:** A, B, C
* Was ist das Hauptziel beim Bau einer mechanischen KI für das Nim-Spiel?
  * A) Die KI soll durch Zufall Entscheidungen treffen
  * B) Die KI soll durch Training unschlagbar werden
  * C) Die KI soll menschliche Intelligenz simulieren
  * **Richtig:** B) Die KI soll durch Training unschlagbar werden
* Welche Hierarchie besteht in der Künstlichen Intelligenz?
  * A) Algorithmen → KI → Maschinelles Lernen → Deep Learning → Generative KI
  * B) Generative KI → Deep Learning → Maschinelles Lernen → KI → Algorithmen
  * C) Algorithmen → Deep Learning → KI → Maschinelles Lernen → Generative KI
  * **Richtig:** A) Algorithmen → KI → Maschinelles Lernen → Deep Learning → Generative KI
* Was ist die Hauptfunktion von Tokenisierung in KI?
  * A) Die semantische Bedeutung von Wörtern zu verstehen.
  * B) Texte in maschinell verarbeitbare Einheiten zu zerlegen.
  * C) Die Grammatik von Sätzen zu korrigieren.
  * **Richtig:** B) Texte in maschinell verarbeitbare Einheiten zu zerlegen.
* Warum sind KI-Systeme wie GPT nicht in der Lage, Sprache im menschlichen Sinne zu verstehen?
  * A) Weil sie keine Algorithmen verwenden.
  * B) Weil sie nur statistische Muster erkennen.
  * C) Weil sie keine Daten haben.
  * **Richtig:** B) Weil sie nur statistische Muster erkennen.
* Was ist die Rolle von Clickworkern bei der KI-Entwicklung?
  * A) Sie entwickeln Algorithmen.
  * B) Sie annotieren Daten.
  * C) Sie bauen Hardware.
  * **Richtig:** B) Sie annotieren Daten.
* Wodurch unterscheidet sich klassische Programmierung von KI?
  * A) Klassische Programmierung ist flexibler als KI
  * B) KI ist datengetrieben und lernfähig, während klassische Programmierung auf festen Regeln basiert
  * C) Klassische Programmierung kann komplexere Probleme lösen als KI
  * **Richtig:** B) KI ist datengetrieben und lernfähig, während klassische Programmierung auf festen Regeln basiert
* Was ist Anthropomorphisierung im Kontext von KI?
  * A) Die Fähigkeit von KI, menschliche Emotionen zu verstehen
  * B) Das Zuschreiben menschlicher Eigenschaften an nicht-menschliche Systeme wie KI
  * C) Die Entwicklung von KI-Systemen, die menschenähnlich aussehen
  * **Richtig:** B) Das Zuschreiben menschlicher Eigenschaften an nicht-menschliche Systeme wie KI
* Was ist ein "Human-in-the-Loop"-Ansatz?
  * A) Ein Ansatz, bei dem Menschen vollständig durch KI ersetzt werden
  * B) Ein Ansatz, bei dem Menschen eng mit KI-Systemen zusammenarbeiten, um deren Entscheidungen zu überwachen
  * C) Ein Ansatz, bei dem KI-Systeme menschliches Verhalten imitieren
  * **Richtig:** B) Ein Ansatz, bei dem Menschen eng mit KI-Systemen zusammenarbeiten, um deren Entscheidungen zu überwachen
* Welches Problem entsteht, wenn Schüler LLMs für ihre Aufgaben nutzen?
  * A) Die Texte werden zu kurz
  * B) Wichtige Lernprozesse werden übersprungen, da nur das Endprodukt zählt
  * C) Die Texte enthalten zu viele Fachbegriffe
  * **Richtig:** B) Wichtige Lernprozesse werden übersprungen, da nur das Endprodukt zählt
* Warum ist die Entfernung einzelner Inhalte aus einem LLM schwierig?
  * A) Weil die Inhalte urheberrechtlich geschützt sind
  * B) Weil ein komplettes Neutraining des Modells erforderlich wäre
  * C) Weil die Entwickler den Zugriff auf die Inhalte verweigern
  * **Richtig:** B) Weil ein komplettes Neutraining des Modells erforderlich wäre
* Warum ist die Qualität der Eingabe bei LLMs wichtig?
  * A) Sie beeinflusst die Geschwindigkeit der Verarbeitung
  * B) Sie bestimmt maßgeblich die Qualität der Ausgabe
  * C) Sie hat keinen Einfluss auf die Ergebnisse
  * **Richtig:** B) Sie bestimmt maßgeblich die Qualität der Ausgabe
* Welche Vorteile bietet die Verwendung von KI im Bildungsbereich?
  * A) Automatisierung administrativer Aufgaben
  * B) Erstellung individualisierter Lernmaterialien
  * C) Unterstützung bei der Unterrichtsplanung
  * **Richtig:** A, B, C
* Welche Herausforderungen bestehen bei der Verwendung von LLMs im Bildungsbereich?
  * A) Instabilität der Ausgaben
  * B) Mangelnde Transparenz bei der Bewertung
  * C) Schwierigkeit, wichtige Lernprozesse zu überspringen
  * **Richtig:** A, B, C
* Wie können LLMs im Fremdsprachenunterricht eingesetzt werden?
  * A) Ausschließlich zur Bewertung von Schülerleistungen
  * B) Zur Erstellung differenzierter Übungsmaterialien wie Hörverstehensübungen
  * C) Als Ersatz für Lehrkräfte
  * **Richtig:** B) Zur Erstellung differenzierter Übungsmaterialien wie Hörverstehensübungen

---

### Auswertung der Fragen

* **Einstieg** (0-3 richtige Antworten): Klasse, dass Sie sich an den Fragen versucht haben! Jetzt können Sie tiefer in die Materie eintauchen.
* **Fortgeschritten** (4-7 richtige Antworten): Sie haben schon ein solides Grundwissen. Der Kurs wird Ihnen helfen, Themen weiter zu vertiefen.
* **Profi** (8-10 richtige Antworten): Beeindruckend! Ihr Wissen ist bereits fundiert. Der Kurs kann Ihnen eine Auffrischung und neue Impulse bieten.

---

## Grundlagen

In diesem Video erfahren Sie, wie die Technik hinter Sprachmodellen funktioniert, indem Ihnen die Funktionsweise von KI und Maschinellem Lernen mit anschaulichen Beispielen erläutert wird. Mit diesem Wissen entwickeln Sie Strategien für einen kompetenten Umgang mit diesen Werkzeugen. Dadurch nutzen Sie KI-Anwendungen noch effizienter für Ihren eigenen Workflow. Gleichzeitig lernen Sie etwas über die Grenzen von Large Language Modellen, kurz LLMs genannt. So erfahren Sie, wofür sich Sprachmodelle eignen und wofür nicht. Zum Abschluss wird Ihnen eine praktische Anwendungsmöglichkeit für den Unterricht erläutert.

### Warum ist das Thema wichtig?

Das Thema ist wichtig, da ein grundlegendes Wissen über KI und ihre Funktionsweise hilfreich ist, um zu verstehen, wie ein geeigneter Prompt aussieht, um eine möglichst passende Antwort zu erhalten. Das Thema ist ebenso wichtig, um sich über die immensen zeitlichen und energetischen Ressourcen klar zu werden, die in die Trainingsphase eines Modells gesteckt werden. Dies erklärt gleichzeitig auch, warum ein erneutes Training wirtschaftlich meist nicht lukrativ ist. Wie aufwändig solch ein Prozess des Trainings tatsächlich ist, wird innerhalb dieses Videos anhand des NIM-Spiels in Ansätzen gezeigt werden.

Weiterhin wird deutlich, dass aufgrund des sehr hohen Vernetzungsgrades innerhalb eines bestehenden Modells einzelne inhaltliche Aspekte nicht einfach „gelöscht“ werden können, sondern das Modell jedes Mal komplett neu trainiert oder mit Ein- und Ausgabefiltern versehen werden muss. Durch geschicktes Prompting ist zumindest in Transformermodellen wie KI-Chatbots und Co. eine Abweichung vom statistisch wahrscheinlichsten Weg erreichbar.

Es ist zudem wichtig zu wissen, dass das Regelwerk, welches der Konzern beim Training vorgibt, maßgeblich die erwartbaren Ausgaben mitbestimmt. Die Ausgaben von Sprachmodellen werden daher immer auch durch kulturelle, politische und wirtschaftliche Rahmenbedingungen geprägt, die sich im Laufe der Zeit verändern können.

### Was also ist eigentlich Künstliche Intelligenz?

Künstliche Intelligenz bezeichnet die Fähigkeit von Computersystemen, auf sie zugeschnittene Aufgaben selbsttätig zu lösen, die aufgrund ihrer Komplexität bislang menschliche Fähigkeiten erforderten. Das Zitat beschreibt demnach die Fähigkeit von KI, menschliche Intelligenz in bestimmten Bereichen zu imitieren oder sogar zu übertreffen, indem sie komplexe Aufgaben automatisch löst.

Sie kennen KI sicherlich durch Anwendungen wie ChatGPT oder bildgenerierende Systeme wie DALL-E oder Stable Diffusion. Doch das Thema Künstliche Intelligenz umfasst weit mehr und lässt sich in verschiedene Ebenen unterteilen, die aufeinander aufbauen und unterschiedliche Funktionen erfüllen.

**Algorithmen** bilden die Grundlage jeder KI. Sie sind schrittweise Anleitungen, die es ermöglichen, Daten zu analysieren, Muster zu erkennen und Aufgaben zu lösen. Ohne Algorithmen könnten weder einfache Programme noch komplexe KI-Systeme existieren.

Darauf aufbauend steht die **Künstliche Intelligenz** als Oberbegriff für Systeme, die Aufgaben lösen können, die früher menschliche Intelligenz erforderten.

Das **Maschinelle Lernen** ist ein spezialisierter Bereich innerhalb der KI. Hierbei lernen Systeme aus Daten, um ihre Leistung bei bestimmten Aufgaben kontinuierlich zu verbessern.

Das **Deep Learning** ist eine fortgeschrittene Form des Maschinellen Lernens. Deep Learning nutzt künstliche neuronale Netze, um große Datenmengen zu verarbeiten und komplexe Muster zu erkennen. Es ist besonders leistungsfähig bei Aufgaben wie Sprachverarbeitung oder Bilderkennung.

Innerhalb des Deep Learnings hat sich die **Generative KI** entwickelt, eine spezifische Anwendung von KI-Technologien. Generative KI-Systeme wie ChatGPT oder bildgenerierende Tools wie DALL-E erstellen neue Inhalte – sei es Text, Ton oder Bilder – basierend auf den Mustern und Informationen, die sie zuvor gelernt haben. Sie können multimodale Inhalte produzieren, also verschiedene Medien wie Text und Bild kombinieren.

Bei der **klassischen Programmierung** hingegen schreibt eine entwickelnde Person explizite Anweisungen, die genau definieren, wie der Computer eine Aufgabe ausführen soll. Programme basieren auf festen Regeln und Logiken, die deterministisch sind. Das heißt, bei gleicher Eingabe wird immer die gleiche Ausgabe erzeugt.

Während die klassische Programmierung also auf festen Regeln basiert, ist KI datengetrieben und lernfähig. Klassische Programme sind statisch und vorhersehbar, KI-Modelle hingegen dynamisch und flexibel. Beide Ansätze haben ihre Stärken: Die klassische Programmierung eignet sich für klar definierte Aufgaben mit festen Regeln, während KI komplexe, datenbasierte Probleme lösen kann, bei denen die Regeln nicht vollständig bekannt sind oder sich ständig ändern.

---

### Das Nim-Spiel und Maschinelles Lernen

Um eine Einführung in das Maschinelle Lernen zu geben und dessen Funktionsweise genauer zu verstehen, wird oft das sogenannte **Nim-Spiel** und die Gewinn-Strategie, die dahinter steht, herangezogen.

Das Nim-Spiel ist ein mathematisches Strategiespiel, das seit Jahrhunderten existiert und sich durch seine Einfachheit und Tiefe auszeichnet. Es wird von zwei Personen gespielt, die abwechselnd Objekte, in dem gezeigten Beispiel Streichhölzer, aus mehreren Stapeln oder Reihen entfernen. Jede Person muss mindestens ein Streichholz aus einer Reihe nehmen, kann aber auch mehrere, im gezeigten Beispiel bis zu drei, Hölzer aus derselben Reihe entfernen.

Die Spielziele variieren je nach Version: In der normalen Variante gewinnt die Person, die das letzte Streichholz nimmt, während in der Misère-Variante die Person verliert, die das letzte Streichholz nimmt.

Die Geschichte des Nim-Spiels reicht bis in die chinesische Antike zurück. Die ersten europäischen Erwähnungen stammen aus dem 16. Jahrhundert. Der Name „Nim“ wurde von Charles L. Bouton von der Harvard University geprägt, der 1901 die vollständige Theorie des Spiels entwickelte.

„Nim“ wird oft auf das deutsche Verb „nimm“ zurückgeführt, das „nehme“ bedeutet. Dies ist passend, da das Spiel darin besteht, Objekte aus Haufen zu entfernen. Es gibt auch eine Verbindung zu einem veralteten englischen Wort „nim“, das ebenfalls „nehmen“ bedeutet. Die genaue Herkunft des Namens ist jedoch nicht vollständig geklärt, und es gibt Spekulationen über mögliche Verbindungen zu anderen Spielen oder Wörtern. Trotzdem hat sich der Name „Nim“ etabliert und wird weltweit verwendet, um dieses mathematische Strategiespiel zu beschreiben.

---

### Was hat das Nim-Spiel mit KI zu tun?

Das Nim-Spiel ist besonders gut geeignet, um lernende KIs zu erklären, da es ein unparteiisches Spiel ist, bei dem beide Personen die gleichen Züge haben. Es ist vollständig gelöst, was bedeutet, dass die optimale Strategie für jede Startkonfiguration bekannt ist.

Diese Eigenschaften machen es zu einem idealen Modell für Reinforcement Learning, also verstärkendes Lernen und Maschinelles Lernen. KI-Systeme können durch das Spielen des Nim-Spiels lernen, Strategien zu entwickeln und zu optimieren.

Der Lernprozess wird im Folgenden auf ganz anschauliche und vereinfachte Weise erklärt. Dafür stellen Sie sich vor, Sie spielen das Nim-Spiel mit einem Computer, der durch Erfahrungswerte lernt. Der Computer hat keine Ahnung von der optimalen Strategie, sondern muss durch Versuch und Irrtum lernen.

Der Mensch beginnt und zieht zwischen einem und drei Spielsteinen. Der Computer zählt daraufhin die übrigen Spielsteine und muss entscheiden, wie viele er ziehen soll.

Für den Lernprozess hat der Computer eine Art Notizbuch, in dem er all seine Erfahrungen aufschreibt. Jedes Mal, wenn er eine Entscheidung trifft, schreibt er auf, was passiert ist.

Wenn der Computer nun den letzten Spielstein zieht und somit verliert, schreibt er in sein Notizbuch: „Diese Entscheidung war schlecht, vermeide sie in Zukunft!“

Wenn der Computer jedoch nicht den letzten Spielstein zieht und somit gewinnt, schreibt er: „Diese Entscheidung war gut, wiederhole sie!“

Mit jedem weiteren Spiel liest der Computer sein Notizbuch durch und denkt: „Ah, ich erinnere mich, dass ich in dieser Situation letztes Mal verloren habe. Dieses Mal werde ich etwas anderes probieren.“

Wenn er eine Entscheidung trifft, die zu einem Gewinn führt, denkt er: „Super, das hat funktioniert! Ich werde das nächste Mal wieder so handeln.“

Durch die Wiederholung des Spiels wird der Computer immer besser darin, die richtigen Entscheidungen zu treffen, um zu gewinnen.

Dieser Ansatz zeigt, wie der Computer durch Erfahrungswerte und Anpassung lernt, die optimale Strategie für das Nim-Spiel zu entwickeln. Der Computer wird mit der Zeit immer besser darin, die günstigen Entscheidungen zu treffen, indem er aus seinen Fehlern lernt und seine Erfolge wiederholt.

Für das hier konkret gezeigte Beispiel zum Ende des Spiels heißt das, dass sich der Computer denkt: „Ah, ich erinnere mich, dass ich in dieser Situation letztes Mal verloren habe. Als ich ein oder drei Hölzchen genommen habe. Dieses Mal werde ich etwas anderes probieren.“ Das heißt beim nächsten Mal wird der Computer zwei Hölzchen nehmen, denn mehr Möglichkeiten bleiben nicht mehr. Mit dieser Strategie wird er gewinnen und sich in sein Notizbuch notieren: „Super, zwei Hölzchen zu nehmen hat funktioniert! Ich werde das nächste Mal wieder so handeln.“

Durch die Wiederholung des Spiels und sämtlicher Kombinationen wird der Computer immer besser darin, die richtigen Entscheidungen zu treffen, um zu gewinnen.

---

### In welcher Relation steht maschinelles Lernen zum biologischen Lernen?

Trotz des gerade sehr anschaulich und vermenschlicht dargestellten Beispiels zu Maschinellem Lernen unterscheidet sich dieses vom biologischen Lernen dennoch massiv. Denn beide Arten des Lernens unterscheiden sich grundlegend in ihrer Art und Weise, wie sie Informationen verarbeiten und lernen. Beim maschinellen Lernen wird das Lernen durch den Einsatz von Algorithmen erreicht, die systematisch durch eine Menge möglicher Lösungen wiederholt durchlaufen und optimiert werden, um die besten Ergebnisse zu finden. Dieser Prozess kann als das schlichte Abarbeiten eines Algorithmus beschrieben werden, bei dem ungeeignete Lösungen eliminiert werden, bis die optimale gefunden ist.

Ein interessantes Beispiel dafür ist das eben erklärte Nim-Spiel. Obwohl das maschinelle Lernen im Nim-Spiel lediglich eine Lösungsmenge ermittelt, kann das Ergebnis für einen ungeschulten Beobachtenden als „intelligent“ erscheinen. Dies liegt daran, dass die KI in der Lage ist, durch systematische Berechnungen die beste Strategie zu finden, ohne dass ein tiefes Verständnis oder eine intuitive Einsicht erforderlich ist.

Ein wichtiger Unterschied zwischen maschinellem und biologischem Lernen ist zudem die Komplexität des Lernprozesses. Beim maschinellen Lernen ist das Training oft sehr aufwändig und erfordert große Mengen an Daten und Rechenleistung. Im Gegensatz dazu scheint biologisches Lernen oft intuitiver und weniger aufwändig zu sein, obwohl es tatsächlich auf komplexen neurobiologischen Prozessen basiert.

Trotz dieser Unterschiede können beide Formen des Lernens beeindruckende Ergebnisse erzielen. Während biologisches Lernen auf der Fähigkeit basiert, Erfahrungen zu verarbeiten und zu generalisieren, nutzt maschinelles Lernen die systematische Anwendung von Algorithmen, um komplexe Probleme zu lösen. Beide Ansätze haben ihre Stärken und Schwächen und können in unterschiedlichen Kontexten eingesetzt werden.

---

## Einführung in Large Language Models (LLMs)

Im Folgenden wird eine Darstellung der Grundprinzipien eines stark vereinfachten Ansatzes genutzt, der in modernen Large Language Modellen, kurz LLM, nicht mehr verwendet wird, aber genau wie das NIM-Spiel einen Einblick in grundlegende Funktionsweisen ermöglicht.

### Ein Modell für Märchenanfänge – Märchenbaum

Stellen Sie sich vor, eine Maschine analysiert verschiedene Märchenanfänge mithilfe von Algorithmen. Das Ergebnis können Sie sich wie einen großen Baum vorstellen. Anstatt Äste und Blätter hat dieser Baum Wortgruppen, die immer wieder in einer bestimmten Reihenfolge zusammenkommen.

Wenn Sie nun von oben nach unten durch den Baum gehen, erhalten Sie Märchenanfänge, die in ihrer Qualität variieren können.

Manche sind gut strukturiert und klingen wie echte Märchen, während andere weniger überzeugend sind oder so gar nicht zusammenpassen. Dies liegt daran, dass der Baum alle möglichen Kombinationen der analysierten Wortgruppen enthält, auch diejenigen, die nicht unbedingt gut funktionieren.

Der Baum zeigt Ihnen also, wie die Maschine die Struktur von Märchenanfängen versteht und wie sie diese Struktur nutzt, um neue Anfänge zu generieren. Je tiefer Sie in den Baum gehen würden, desto mehr Variationen und möglicherweise auch weniger gelungene Kombinationen würden Sie finden.

---

### Tokenisierung durch Generative Pretrained Transformer (GPT)

In der Realität ist die Generierung mit Systemen wie ChatGPT natürlich viel abstrakter. Wenn ein Generative Pretrained Transformer wie KI-Chatbots einen Text verarbeitet, beginnt es nicht mit der Analyse von Wörtern im herkömmlichen Sinne. Stattdessen transformiert es die Eingabe in **Tokens**, die als bedeutungslose Zeichenfolgen betrachtet werden. Tokens können Wörter, Teile von Wörtern oder sogar einzelne Zeichen sein, die während des Tokenisierungsprozesses erstellt werden.

Diese Tokenisierung ist ein entscheidender Schritt im Verarbeitungsprozess von GPT-Modellen. Anstatt Wörter wörtlich zu interpretieren, werden sie in Token-IDs umgewandelt, die lediglich eine Kennziffer haben. Diese IDs repräsentieren häufig auftretende Zeichenreihenfolgen, die während des Trainingsprozesses gelernt wurden.

Alle weiteren Verarbeitungsschritte basieren auf diesen Token-IDs und nicht etwa auf der semantischen Bedeutung der Wörter. Das heißt, dass GPT die Sprache nicht im menschlichen Sinne versteht, sondern lediglich statistische Muster in den Tokenfolgen erkennt und nutzt, um wahrscheinliche Ausgaben zu generieren.

Wenn Sie selbst einmal sehen wollen, wie der Satzanfang „Es war einmal ein Müller, der in die Welt zog …“ durch ein GPT in Tokens zergliedert und individuellen IDs zugeordnet wird, nutzen Sie spezielle Websites, die das Prinzip veranschaulichen. Einen Link dazu finden Sie auch im Kurs unter „Vertiefung“.

---

### Ein Modell für Märchenanfänge: Statistische Pfade und Ergebnisse

Stellen Sie sich nun vor, Sie haben ein einfaches Modell, das Märchenanfänge generiert. Wenn Sie dieses Modell viele Male laufen und die Ergebnisse von Menschen bewerten lassen, können Sie sehen, wie wahrscheinlich bestimmte Pfade sind.

Die Verbindungslinien zwischen den Elementen zeigen Ihnen, wie oft ein bestimmter Weg gewählt wird. Wenn zwei Pfade gleich wahrscheinlich sind, entscheidet der Zufall, welcher genommen wird. Deshalb kann es passieren, dass bei gleicher Eingabe in ein großes Sprachmodell unterschiedliche Ergebnisse entstehen.

Je vager die Anfrage ist, desto eher wird der Modellpfad gewählt, der das statistische Optimum darstellt. Das bedeutet, dass das Modell auf die am häufigsten vorkommenden Muster zurückgreift. Wenn man jedoch spezifische Elemente wie Fantasiewesen in das Märchen einbauen möchte, muss dies explizit in der Prompteingabe angegeben werden. Auf diese Weise kann man die „Grundprogrammierung“ des Modells sozusagen „überschreiben“ und sicherstellen, dass die gewünschten Elemente im Märchen vorkommen.

Dieses Verfahren zeigt, wie wichtig es ist, klare Anweisungen zu geben, um die gewünschten Ergebnisse zu erzielen, und wie der Zufall eine Rolle spielt, wenn mehrere Pfade gleich wahrscheinlich sind.

---

### Der menschliche Faktor in der KI: Von Datenannotation bis Ethik

Wenn Sie sich wieder den Märchenbaum vorstellen, der durch algorithmische Analyse von Märchenanfängen entsteht, sehen Sie, dass die Ergebnisse stark von menschlichen Eingriffen abhängen. Der Baum selbst ist ein Produkt von Algorithmen, die Wortgruppen und ihre Reihenfolge analysieren, um typische Märchenanfänge zu generieren.

Doch bevor diese Algorithmen überhaupt arbeiten können, sind Menschen notwendig, um die Daten zu annotieren und zu etikettieren, die Daten also mit zusätzlichen Informationen zu versehen. Diese Arbeit wird oft von **Clickworkern** und anderen Mikrojob-Plattformen durchgeführt, die in Schwellen- oder Entwicklungsländern tätig sind. Diese Menschen spielen eine entscheidende Rolle, indem sie sicherstellen, dass die Daten korrekt und konsistent sind, was wiederum die Qualität der KI-Ergebnisse beeinflusst.

Neben der Datenannotation sind auch Fachkräfte wie **Datenwissenschaftler** und **Ingenieure** unverzichtbar. Sie entwickeln und optimieren die Algorithmen, die den Märchenbaum generieren. Diese Experten sind verantwortlich für die Architektur der Modelle und passen sie an spezifische Anforderungen an. Sie entscheiden, wie der Baum strukturiert wird und welche Pfade am wahrscheinlichsten genommen werden.

Ein weiterer wichtiger Aspekt ist die **Governance und Ethik**. AI-Ethiker und -Experten, politische Entscheidungsträger und Regulierungsbehörden, Unternehmensleitende und Compliance-Teams, Datenschutzbeauftragte, interne Ethikkomitees und viele andere tragen Verantwortung dafür, dass KI-Systeme ethisch und rechtlich einwandfrei betrieben werden. Dies umfasst unter anderem die Überwachung von Bias in den Daten und die Einhaltung von Datenschutzbestimmungen. Im Kontext des Märchenbaums bedeutet dies, dass die Ergebnisse frei von unerwünschten Stereotypen oder Vorurteilen sein sollten. Allerdings ist es wichtig zu betonen, dass eine vollständige Sicherstellung der ethischen und rechtlichen Unbedenklichkeit von LLMs nicht garantiert werden kann. Bias in den Modellen ist oft tief in den Trainingsdaten verankert und kann sogar gezielt eingesetzt werden, um bestimmte Ergebnisse zu fördern.

Schließlich spielt der **Human-in-the-Loop-Ansatz** eine wichtige Rolle. Hier arbeiten Menschen eng mit den KI-Systemen zusammen, um deren Entscheidungen zu überwachen und zu korrigieren. Dies verbessert die Genauigkeit und Zuverlässigkeit der Modelle.

Im Märchenbaum bedeutet dies, dass Menschen die generierten Märchenanfänge überprüfen und gegebenenfalls anpassen, um sicherzustellen, dass sie den Erwartungen entsprechen.

---

### Anthropomorphisierung als problematische Komponente

Die Ausgaben von Large Language Modellen wirken oft so, als ob sie von einem intelligenten System stammen. Doch in Wirklichkeit basieren sie auf statistischen Berechnungen, die komplexe Muster aus großen Datenmengen erkennen und darauf aufbauend Ergebnisse generieren.

Diese Ergebnisse sind für Menschen oft beeindruckend, ähnlich wie für eine Person, die das Nim-Spiel nicht gewinnen kann und glaubt, der Gegner, also die KI, sei besonders clever.

Diese Annahme entsteht durch die **Anthropomorphisierung**. Dies bezeichnet im Allgemeinen das Zuschreiben menschlicher Eigenschaften gegenüber Tieren, Göttern, Naturgewalten und Ähnlichem.

Anthropomorphisierung im Zusammenhang mit KI bedeutet, dass typisch menschliche Eigenschaften wie Emotionen, Intentionen oder Verhaltensweisen nicht-menschlichen Systemen, wie Künstlichen Intelligenzen oder Robotern, zugeschrieben werden.

Dies kann dazu führen, dass Nutzende KI-Systeme als intelligent oder sogar emotional empfinden, obwohl sie lediglich komplexe Algorithmen ausführen. Diese Tendenz kann sowohl positive als auch negative Auswirkungen haben, wie etwa die Überbewertung der Fähigkeiten von KI oder die Verzerrung moralischer Urteile über deren Verantwortung.

Die Begriffe „Künstliche Intelligenz“ und „Lernen“ sind in der Informatik seit Jahrzehnten fest etabliert. Sie dienen dazu, komplexe Konzepte zu beschreiben, wie etwa die Fähigkeit von Computern aus Daten Muster zu erkennen und Aufgaben zu lösen.

Diese Fachbegriffe sind tief in der akademischen und industriellen Praxis verwurzelt und schwer zu ersetzen. Gleichzeitig tragen sie jedoch auch dazu bei, dass KI-Systeme oft als selbstständig denkende Entitäten wahrgenommen werden – eine Vorstellung, die durch die Anthropomorphisierung verstärkt wird.

Folgen der Anthropomorphisierung im Zusammenhang mit KI können demnach sein, dass die Betreiber von KI-Systemen möglicherweise von dieser Wahrnehmung profitieren. Wenn KI-Systeme als „intelligent“ gelten und ihre Ergebnisse als autonom angesehen werden, kann dies dazu führen, dass die Verantwortung für Fehler oder Falschaussagen auf die Systeme selbst verschoben wird, anstatt auf die Entwickler und Entwicklerinnen oder Betreiber und Betreiberinnen. Auch die Nutzenden selbst sind immer in der Verpflichtung, die Ausgaben eines LLMs zu überprüfen. Die Öffentlichkeit könnte dadurch glauben, dass die Systeme unabhängig handeln und nicht von Menschen kontrolliert werden. Dies birgt das Risiko einer mangelnden Transparenz und Verantwortlichkeit. In Wirklichkeit sind jedoch die Entwickler und Entwicklerinnen und Betreiber und Betreiberinnen für die Qualität und Sicherheit der KI-Systeme verantwortlich.

Insgesamt zeigt sich also, dass die Art und Weise, wie wir über KI sprechen – insbesondere durch Begriffe wie „Intelligenz“ und „Lernen“ – unsere Wahrnehmung beeinflussen.

Es ist wichtig, zwischen der tatsächlichen Funktionsweise von KI-Systemen und der durch Anthropomorphisierung geprägten Vorstellung zu unterscheiden. Nur so kann sichergestellt werden, dass Verantwortung für Fehler und Entscheidungen klar den Menschen zugewiesen wird, die diese Systeme entwickeln, betreiben und nutzen.

---

## Herausforderungen bei der Verwendung von LLMs

Die Verwendung von LLMs bietet viele Möglichkeiten, um komplexe Texte zu generieren und zu bearbeiten. Doch trotz ihrer beeindruckenden Fähigkeiten gibt es einige Herausforderungen, die beachtet werden müssen.

### Abhängigkeit von der Eingabequalität

Eine der größten Herausforderungen ist die Abhängigkeit von der Eingabequalität. Die Qualität der Ausgaben hängt stark von der Qualität und Detailliertheit der Eingaben ab. Zudem sind die Ausgaben von LLMs nicht immer konsistent, was bedeutet, dass dieselbe Eingabe unterschiedliche Ergebnisse liefern kann.

Um diese Herausforderungen zu meistern, ist es wichtig, die Eingaben sorgfältig zu gestalten und die Ergebnisse kritisch zu bewerten. Im Folgenden wird sich mit diesen Herausforderungen auseinandergesetzt und Strategien erörtert, wie man die Qualität und Konsistenz der Ausgaben verbessern kann.

Wenn Sie beispielsweise eine Rede in Ihrem persönlichen Stil erstellen lassen möchten, ist es ratsam, dem LLM drei bis vier Ihrer eigenen Texte zur Verfügung zu stellen. Auf dieser Grundlage kann das Modell Ihren Stil besser verstehen und eine neue Rede erstellen, die Ihren Erwartungen entspricht.

Da die Ausgaben von LLMs nicht immer konsistent sind, empfiehlt es sich, den gleichen Eingabeprompt mehrmals, gegebenenfalls auch in unterschiedlichen Sprachmodellen, zu verwenden und aus den verschiedenen Ergebnissen das beste auszuwählen. Dieser Ansatz hilft, die beste mögliche Ausgabe zu erzielen und die Konsistenz der Ergebnisse zu verbessern. Perplexity bietet zum Beispiel an, mithilfe des gleichen Prompts Ausgaben mit unterschiedlichen Sprachmodellen zu erstellen. Auch hierdurch können sehr unterschiedliche Texte entstehen.

### LLMs bei der Bewertung und Feedbackgenerierung

Die Verwendung von Large Language Modellen zur Generierung von Feedback und Bewertungen für Schülerinnen und Schüler ist ein komplexes Thema, das sowohl durch Automatisierung von Prozessen Vorteile und Arbeitserleichterungen, als auch Herausforderungen und Einschränkungen mit sich bringt, die berücksichtigt werden müssen.

Die Verwendung von Large Language Modellen zur Generierung von Feedback und Bewertungen für Schülerinnen und Schüler ist problematisch, da ihre Ausgaben instabil sind. Sowohl das Feedback als auch die Bewertungen variieren stark, was zu inkonsistenten Ergebnissen führt. Ein häufiges Argument ist, dass auch menschliche Bewertungen variieren können. Wenn man diesem Argument zustimmt, bieten LLMs in diesem Bereich keinen wesentlichen Vorteil, außer möglicherweise eine Arbeitserleichterung durch die Automatisierung.

Ein entscheidender Nachteil von LLMs ist jedoch, dass sie im Zweifelsfall nicht erklären können, wie eine bestimmte Ausgabe zustande gekommen ist. Wenn eine Rechtfertigung oder Begründung erforderlich ist, kann dies sogar mehr Arbeit erfordern als eine eigenständige Bewertung durch einen Menschen. Dies liegt daran, dass LLMs nicht in der Lage sind, den Entscheidungsprozess transparent zu machen oder die zugrunde liegenden Gründe für ihre Bewertungen zu erläutern. Daher können sie in Situationen, in denen Transparenz und Nachvollziehbarkeit wichtig sind, nicht vollständig als Ersatz für menschliche Bewertungen dienen. Letztendlich bleibt die Verantwortung für die Nutzung und die Ergebnisse solcher Systeme immer beim Menschen.

### LLMs als Hilfsmittel für Schülerinnen und Schüler

Die Verwendung von Large Language Modellen im Bildungsbereich bietet viele Möglichkeiten, um den Unterricht zu bereichern und die Lernergebnisse zu verbessern. Doch auch hier existieren Herausforderungen, die beachtet werden müssen.

Die Ausgaben von Large Language Modellen basieren auf riesigen Datenmengen und sind sehr umfassend. Sie klingen oft so, als ob sie genau das sagen, was Schüler und Schülerinnen glauben, dass eine Lehrkraft hören möchte. Die Qualität dieser Ausgaben übertrifft zudem häufig das, was Schüler und Schülerinnen selbst erreichen können.

Dies kann jedoch problematisch sein, da die reine Ausgabe eines Produkts wichtige Prozessschritte beim Lernen überspringt. Entscheidend beim Lernen ist nicht nur das Endprodukt, sondern vielmehr der Prozess, der zu diesem Produkt führt, da dieser Prozess die Fähigkeiten und das Verständnis der Schüler und Schülerinnen entwickelt. Wenn LLMs die Schüler und Schülerinnen bei der Erstellung von Texten unterstützen, könnte dies die tiefere Auseinandersetzung mit dem Lernstoff behindern.

---

## Anwendungen von KI im Bildungs- und Verwaltungsbereich – Vorteile und Stärken

Trotz aller Herausforderungen, die mit der Verwendung von KI-Technologien verbunden sind, gibt es auch erhebliche Vorteile, die sie dem Bildungsbereich bieten.

### Kurze Anwendungsbeispiele im Bildungs- und Verwaltungsbereich

Die Stärken von KI-Tools zeigen sich vor allem in Bereichen, in denen die Ausgaben klar strukturiert und statistisch konsistent sind, wie beispielsweise bei formalisierten oder standardisierten Aufgabenstellungen.

So können LLMs unstrukturierte Texte in Tabellen oder Spreadsheets umwandeln, standardisierte Formulare oder Fragebögen generieren, die bestimmten Vorlagen entsprechen oder lange Dokumente in präzise und organisierte Zusammenfassungen umwandeln, die wichtige Punkte hervorheben.

### LLMs zur Erstellung von differenziertem Übungsmaterial im Fremdsprachenunterricht

Im folgenden Abschnitt wird eine praktische Anwendung von KI im Bildungsbereich vorgestellt. Weitere Verweise auf konkrete Praxisbeispiele finden Sie in den „Anschlüssen“ zu diesem Kurs.

Die Erstellung von differenziertem Übungsmaterial im Fremdsprachenunterricht kann zum Beispiel durch den Einsatz von KI-Technologien erheblich erleichtert und erweitert werden. Eine Möglichkeit hierfür sind Hörverstehensübungen, die in Kombination mit verschiedenen generativen Systemen erstellt werden.

Mithilfe von gezielten Prompts werden Texte zum Beispiel zum Thema „Reisen durch Frankreich“ für verschiedene Anforderungsniveaus mit KI-Chatbots generiert. Diese Texte dienen dann als Grundlage für Hörverstehensübungen.

Um die Übungen noch interaktiver zu gestalten, nutzen Sie generative Audio-KI-Systeme, um die Texte in Hörtexte umzuwandeln. Auch diese KI-Systeme stehen auf vielen Plattformen zur Verfügung. Solche angepassten Hörtexte ermöglichen es den Schülerinnen und Schülern, ihre Fähigkeiten im Hörverstehen zu üben. Alternativ sprechen Sie die Texte ein.

Wollen Sie die Übungen und Texte dazu weiter vereinfachen oder zum Beispiel auf ein A1-Niveau anpassen? Hier kann zusätzlich ein Textvereinfacher-Tool oder ein einfacher Prompt helfen. Die Inhalte der Texte werden durch die Umwandlung kondensierter und strukturierter, um sie für die Schüler besser zugänglich zu machen. Einen Link dazu zum Ausprobieren finden Sie im Kurs unter „Vertiefung“.

Entwickeln Sie zusätzliche Hörverstehensübungen, die auf die generierten Hörtexte abgestimmt sind. Beispiele könnten Multiple-Choice-Fragen, Lückenfüllübungen oder Diskussionsfragen sein.

Durch diese Kombination von Technologien können Lehrkräfte ein breites Spektrum an Übungsmaterialien erstellen, das auf die unterschiedlichen Bedürfnisse ihrer Schüler und Schülerinnen abgestimmt ist.

---

## Zusammenfassung & Glossar

### Zusammenfassung

Das Lernangebot bietet einen umfassenden Überblick über die Grundlagen der **Künstlichen Intelligenz (KI)** und des **Maschinellen Lernens (ML)**. Grundlegende Konzepte der KI werden erläutert. Dass KI sich auf die Fähigkeit von Computersystemen bezieht, komplexe Aufgaben selbsttätig zu lösen, die früher menschliche Intelligenz erforderten. Algorithmen bilden die Basis jeder KI und ermöglichen es, Daten zu analysieren und Muster zu erkennen.

Ein großer Teil des Lernangebots beschäftigt sich mit **Large Language Modellen (LLMs)** und der **Anthropomorphisierung**, die oft zu Missverständnissen über die Fähigkeiten von KI führt. LLMs sind, basierend auf riesigen Datenmengen, in der Lage, Texte zu generieren und zu verstehen, die sie während eines langwierigen Trainingsprozesses gelernt haben. Allerdings verstehen sie Sprache nicht im menschlichen Sinne, sondern verarbeiten lediglich statistische Muster.

Das **Nim-Spiel** wird als Beispiel genutzt, um die Funktionsweise des maschinellen Lernens zu erklären, denn es zeigt, wie KI-Systeme durch Trial und Error lernen können, um optimale Strategien zu entwickeln. Ein anschauliches Beispiel für die Anwendung dieser Technologie ist der **Märchenbaum**, der durch die Analyse von Märchenanfängen entsteht und zeigt, wie KI-Systeme Strukturen erkennen und neue Texte generieren können, indem sie häufige Wortkombinationen kombinieren.

Des Weiteren werden praktische Anwendungen von KI im Bildungsbereich vorgestellt, wie zum Beispiel die Unterstützung bei der Unterrichtsplanung. Wichtig ist ein grundlegendes Verständnis von KI und Maschinellem Lernen, um diese Technologien effizient zu nutzen und ihre Grenzen zu verstehen.

---

## Vertiefung

Um das theoretische Wissen zu verankern und Ihnen einen Blick über den Tellerrand zu ermöglichen, haben wir für Sie Stimmen aus der Praxis, weiterführende Materialien und Ressourcen zusammengestellt, die Ihnen helfen werden, die Thematik der Künstlichen Intelligenz noch tiefer zu durchdringen und die vielfältigen Anwendungsmöglichkeiten zu erkunden.

### Vertiefende Informationen zum Thema

* **Nim-Spiel Erläuterungen**
  * Die Handreichung für Lehrerinnen und Lehrer für das Nim-Spiel erläutert viele Hintergründe und Erklärungen auf eine anschauliche und gut verständliche Weise.
  * Die Seite „inf-schule“ des Pädagogischen Landesinstitut Rheinland-Pfalz bietet dafür die Möglichkeit zum digitalen Spielen des Nim-Spiels. Dort ist es möglich, gegen sich selbst oder gegen eine KI zu spielen.
  * Auch können KIs dabei beobachtet werden, wie sie gegeneinander spielen, und die Strategien gerade selbst erst lernen.
* **Nim-Spiel und lernende KI – Video**
  * Das Video „Bastel deine eigene KI“ beschreibt, wie man eine einfache KI für das Spiel Nim ohne Computer bauen kann.
  * Hierbei werden Pappbecher und Zettel verwendet, um eine mechanische KI zu erstellen, die durch Wiederholung und Feedback trainiert wird.
  * Diese KI kann nach einigen Runden perfekt spielen und immer gewinnen, wenn sie den ersten Zug hat.
  * Die Seite erklärt auch die grundlegenden Prinzipien des Maschinellen Lernens und zeigt, wie ähnliche Methoden in der KI-Entwicklung verwendet werden.
  * Sie betont den Unterschied zwischen dem Bau einer KI und ihrem Training sowie die Grenzen von einfachen KI-Systemen bei komplexen Spielen wie Schach oder Go.
* **Märchenbaum ganz anders**
  * Im Video zur Märchengenerierung von SoekaGPT, einer webbasierten Lernumgebung zur Simulation eines Sprachmodells, wird anschaulich und ausführlich erklärt, wie ein Sprachmodell durch die Analyse von hinterlegten Märchen ein neues Märchen generiert.
* **Einfache Sprache Tool**
  * Die Textvereinfacher-App hilft Texte in einfache Sprache zu konvertieren.
* **Stimmen aus der Praxis**
  * Video

---

## Transferaufgaben

### Selbstreflexion

Bitte denken Sie über die folgenden Fragen einmal für sich selbst nach.

* **Anthropomorphisierung und ihre Folgen**
  * Welche Risiken entstehen durch die Vermenschlichung von KI-Systemen?
  * Wie könnte die Wahrnehmung von KI verändert werden, wenn wir auf anthropomorphisierende Begriffe verzichten?
  * Haben Sie schon einmal ein technisches System wie einen Sprachassistenten oder Chatbot vermenschlicht?
  * Was hat dazu geführt und wie hat das Ihre Wahrnehmung beeinflusst?
* **Medien und öffentliche Wahrnehmung**
  * Welche Rolle spielen Medien und Marketing bei der Verbreitung des Bildes von „intelligenten“ Maschinen?
  * Wie könnte man die Öffentlichkeit besser über die tatsächlichen Fähigkeiten und Grenzen von KI informieren?

### Transferaufgabe

Die Transferaufgabe ist in der verlinkten Datei enthalten.

---

## Anschlüsse

Wenn Sie weiter in dieses Thema einsteigen möchten, schauen Sie sich gerne das Lernangebot M2.2-6 – Differenzierung im Unterricht mit KI an, welches viele praktische Übungen und Beispiele dazu bietet.

### Testen Sie Ihr Vorwissen

Zum Abschluss des Moduls möchten wir Sie einladen, Ihr neu erworbenes Wissen zu reflektieren und zu überprüfen. Kehren wir zu den Fragen und Herausforderungen zurück, mit denen Sie hier gestartet sind – sehen Sie, wie sich Ihre Perspektive und Ihr Verständnis durch die Bearbeitung des Moduls verändert haben.

---

## Abspann

### KI-Transparenzhinweis

Wir praktizieren, was wir lehren! Dieses Lernangebot wurde bewusst mit KI-Technologien entwickelt – als lebendiges Beispiel für die Möglichkeiten moderner künstlicher Intelligenz.

Unsere KI-Assistenten waren unsere Co-Kreativen:

* Perplexity AI gestaltete Struktur und Inhalte
* Gemini und NotebookLM recherchierte unterstützende Quellen
* ChatGPT schrieb Textentwürfe
* DeepL verfeinerte die Sprache

So zeigen wir: KI ist mehr als eine Technologie – sie ist ein mächtiges Werkzeug für Kreativität und Wissensarbeit. Eines bleibt dabei unverrückbar: Die menschliche Expertise und Verantwortung bilden die Grundlage.

### Letzte Aktualisierung

Dieses Lernangebot wurde im März 2025 fertiggestellt und ist danach nicht mehr aktualisiert worden.

Es liegt in der Natur des Internets, dass Webangebote und Links sich verändern oder nicht mehr verfügbar sind. Insofern bitten wir um Nachsicht, falls ein genanntes und/oder verlinktes Angebot nicht mehr erreichbar ist oder sich verändert hat.

### Kontakt

Wenn Sie eine Frage oder eine Rückmeldung zu diesem Lernangebot haben, freuen wir uns, wenn Sie uns im Forum oder Christian Haake über christian.haake@nlq.niedersachsen.de, Tel. +49 5121 1695151‬ kontaktieren.

### Team

* **Verantwortlich seitens des NLQ:** Christian Haake und Jörg Steinemann
* **Fachliche Beratung:** Maik Riecken, Ekkehard Brüggemann, Barbara Ehlerding
* **Konzeption, Redaktion:** Jöran Muuß-Merholz, Blanche Fabri, Nicole Hagen, Frank Homp, Tessa Moje der Agentur J&K – Jöran und Konsorten
* **Gesamtleitung:** Blanche Fabri, Agentur J&K – Jöran und Konsorten
* **Mitarbeit:** Jula Henke, Pascal Fieseler, Ben Paetzold, Owais Alsayed Ahmad der Agentur J&K – Jöran und Konsorten

### Downloads

* Video Grundlegendes Verständnis von LLM und Maschinellem Lernen
* Video Grundlegendes Verständnis von LLM und Maschinellem Lernen – Stimmen aus der Praxis

### Lizenzhinweise

Dieses Angebot ist frei lizenziert und im Sinne von Open Educational Resources (OER) offen zur weiteren Verwendung, Veränderung, Weitergabe etc. Als Gesamtwerk steht es unter der Lizenz CC BY 4.0.

Als Namensnennung im Sinne der Lizenz ist vorgesehen: „Agentur J&K – Jöran und Konsorten im Auftrag des Niedersächsischen Landesinstituts für schulische Qualitätsentwicklung (NLQ Hildesheim)“.

Einzelne Elemente des Angebots, zum Beispiel Abbildungen, Videos, Texte, können eigenständig unter anderen Lizenzbedingungen freigegeben sein, auch durch Dritte. In diesen Fällen ist dies im oder am jeweiligen Element angegeben.

---

## Fun Fact

Einige aufmerksame Beobachter haben festgestellt, dass das Wort „NIM“ – wenn man es auf den Kopf stellt und rückwärts liest – zum englischen Wort „WIN“ – zu deutsch: „gewinnen“ – wird. Diese interessante sprachliche Symmetrie passt perfekt zur Natur des Nim-Spiels, bei dem es letztendlich darum geht, durch strategisches Denken und geschickte Züge den Sieg zu erringen. Diese visuelle Wortspielerei unterstreicht die elegante Verbindung zwischen dem Namen des Spiels und seinem ultimativen Ziel.