WEBVTT

1
00:00:06.320 --> 00:00:08.000
Herausforderungen und Risiken

2
00:00:08.000 --> 00:00:10.000
von generativer Bild-KI.

3
00:00:12.800 --> 00:00:15.160
Generative Bild-KI bringt eine Reihe

4
00:00:15.160 --> 00:00:17.080
von Herausforderungen und Risiken

5
00:00:17.080 --> 00:00:19.040
mit sich, die Lehrkräfte kennen

6
00:00:19.040 --> 00:00:20.880
und kritisch einordnen sollten.

7
00:00:21.440 --> 00:00:22.920
Ein zentrales Problem sind

8
00:00:22.920 --> 00:00:25.840
sogenannte Bias, also Verzerrungen.

9
00:00:26.630 --> 00:00:28.350
KI-Modelle lernen aus großen

10
00:00:28.350 --> 00:00:30.550
Datensätzen, in denen Vorurteile

11
00:00:30.550 --> 00:00:32.590
stecken können - kulturelle,

12
00:00:32.590 --> 00:00:35.270
geschlechtsspezifische oder rassische.

13
00:00:35.830 --> 00:00:37.790
Dadurch besteht die Gefahr, dass

14
00:00:37.790 --> 00:00:39.870
bestimmte Gruppen unterrepräsentiert

15
00:00:39.870 --> 00:00:41.910
sind oder in stereotypischer

16
00:00:41.910 --> 00:00:43.590
Weise dargestellt werden.

17
00:00:43.590 --> 00:00:45.830
Nutzende und Lehrkräfte müssen sich

18
00:00:45.830 --> 00:00:48.310
bewusst sein: Die Ergebnisse wirken

19
00:00:48.310 --> 00:00:50.230
auf den ersten Blick neutral,

20
00:00:50.230 --> 00:00:52.230
spiegeln aber in Wirklichkeit

21
00:00:52.230 --> 00:00:54.310
gesellschaftliche Schieflagen wider.

22
00:00:57.640 --> 00:00:59.120
Ein weiteres Risiko betrifft

23
00:00:59.120 --> 00:01:00.400
die Unsicherheit über die

24
00:01:00.400 --> 00:01:02.120
Herkunft der Trainingsdaten.

25
00:01:02.680 --> 00:01:04.640
Wurden urheberrechtlich geschützte

26
00:01:04.640 --> 00:01:06.160
Inhalte verwendet, können

27
00:01:06.160 --> 00:01:08.200
generierte Bilder denen geschützter

28
00:01:08.200 --> 00:01:09.720
Werke sehr ähnlich sein.

29
00:01:10.519 --> 00:01:12.760
Erste juristische Auseinandersetzungen

30
00:01:12.760 --> 00:01:14.680
zeigen, dass dieses Problem noch

31
00:01:14.680 --> 00:01:16.680
nicht abschließend geklärt ist.

32
00:01:16.680 --> 00:01:18.640
Besonders kritisch wird es, wenn

33
00:01:18.640 --> 00:01:20.120
Personen dargestellt werden.

34
00:01:21.050 --> 00:01:23.330
Hier geht es Persönlichkeitsrechte,

35
00:01:23.330 --> 00:01:25.730
Diskriminierung oder sogar um den

36
00:01:25.730 --> 00:01:28.570
Missbrauch durch sogenannte Deepfakes,

37
00:01:28.570 --> 00:01:30.290
also täuschend echt wirkende

38
00:01:30.290 --> 00:01:32.730
Darstellungen realer Menschen, die ohne

39
00:01:32.730 --> 00:01:34.570
deren Einwilligung erstellt werden.

40
00:01:37.690 --> 00:01:39.570
Besonders deutlich zeigen sich die

41
00:01:39.570 --> 00:01:41.170
Gefahren im Zusammenspiel mit

42
00:01:41.170 --> 00:01:43.930
sozialen Medien wie X, Facebook,

43
00:01:43.930 --> 00:01:46.250
Instagram und anderen Plattformen.

44
00:01:46.870 --> 00:01:49.110
Diese Dienste sind darauf ausgelegt, ihre

45
00:01:49.110 --> 00:01:51.590
Nutzerinnen und Nutzer möglichst lange

46
00:01:51.590 --> 00:01:54.150
zu binden, sie zum Teilen von Inhalten

47
00:01:54.150 --> 00:01:56.950
zu animieren und Klicks zu generieren.

48
00:01:57.510 --> 00:01:59.150
Bilder sind hier ein besonders

49
00:01:59.150 --> 00:02:01.630
wirksames Mittel, weil sie Botschaften

50
00:02:01.630 --> 00:02:03.470
niedrigschwellig transportieren

51
00:02:03.470 --> 00:02:05.430
und Emotionen hervorrufen.

52
00:02:06.070 --> 00:02:08.270
Dank moderner Bearbeitungstools oder

53
00:02:08.270 --> 00:02:10.910
generativer KI lassen sich solche

54
00:02:10.910 --> 00:02:12.670
Bilder heute in kürzester Zeit

55
00:02:12.670 --> 00:02:15.860
erstellen, verändern und verbreiten.

56
00:02:15.860 --> 00:02:17.620
Die Hemmschwelle für die Produktion

57
00:02:17.620 --> 00:02:20.660
von Inhalten sinkt dadurch erheblich,

58
00:02:20.660 --> 00:02:23.380
während gleichzeitig das Risiko steigt,

59
00:02:23.380 --> 00:02:25.500
dass manipulative Botschaften

60
00:02:25.500 --> 00:02:27.820
oder Fake News ein breites Publikum

61
00:02:27.820 --> 00:02:28.900
erreichen.

62
00:02:28.900 --> 00:02:31.380
Besonders gefährlich ist die Möglichkeit,

63
00:02:31.380 --> 00:02:32.820
falsche Geschichtsbilder

64
00:02:32.820 --> 00:02:34.980
oder populistische Narrative

65
00:02:34.980 --> 00:02:37.700
scheinbar authentisch zu visualisieren

66
00:02:37.700 --> 00:02:39.780
und so den öffentlichen Diskurs

67
00:02:39.780 --> 00:02:41.300
nachhaltig zu beeinflussen.

68
00:02:45.160 --> 00:02:47.280
Neben diesen inhaltlichen Fragen gibt

69
00:02:47.280 --> 00:02:49.720
es auch organisatorische Hürden.

70
00:02:49.720 --> 00:02:51.680
Neben der nicht immer vorhandenen

71
00:02:51.680 --> 00:02:53.200
benötigten Hardware an den

72
00:02:53.200 --> 00:02:55.200
Schulen betrifft dies besonders

73
00:02:55.200 --> 00:02:57.320
die Kompetenz der Nutzenden.

74
00:02:57.320 --> 00:02:59.320
Sie müssen lernen, mit neuen

75
00:02:59.320 --> 00:03:01.760
Technologien umzugehen und Ergebnisse

76
00:03:01.760 --> 00:03:02.960
im Rahmen der technischen

77
00:03:02.960 --> 00:03:05.160
Weiterentwicklung kritisch zu bewerten.

78
00:03:05.800 --> 00:03:07.800
Hinzu kommt der zeitliche Aufwand,

79
00:03:08.470 --> 00:03:10.710
Prompts müssen sorgfältig formuliert,

80
00:03:10.710 --> 00:03:12.350
Ergebnisse geprüft und

81
00:03:12.350 --> 00:03:14.630
gegebenenfalls nachbearbeitet werden.

82
00:03:15.270 --> 00:03:18.630
Mit dem EU AI Act gibt es seit August

83
00:03:18.630 --> 00:03:21.710
2024 die weltweit erste

84
00:03:21.710 --> 00:03:24.390
umfassende Regulierung, um einen sicheren

85
00:03:24.390 --> 00:03:26.270
und ethischen Rahmen für den

86
00:03:26.270 --> 00:03:28.270
Umgang mit künstlicher Intelligenz

87
00:03:28.270 --> 00:03:29.750
in der EU zu schaffen.

88
00:03:30.630 --> 00:03:32.870
Konkret auf den deutschen Schulkontext

89
00:03:32.870 --> 00:03:34.960
übertragen, fehlt es bislang

90
00:03:34.960 --> 00:03:36.920
jedoch noch an einheitlichen,

91
00:03:36.920 --> 00:03:39.880
bundesländerübergreifenden Regelungen.

92
00:03:39.880 --> 00:03:42.600
Eine Umfrage des Branchenverbands Bitkom

93
00:03:42.600 --> 00:03:44.760
zeigt, dass laut den teilnehmenden

94
00:03:44.760 --> 00:03:46.880
Schülerinnen und Schülern nur etwa

95
00:03:46.880 --> 00:03:49.000
ein Viertel der Schulen klare

96
00:03:49.000 --> 00:03:52.040
Vorgaben für den Umgang mit KI habe.

97
00:03:52.040 --> 00:03:53.720
In Niedersachsen gibt es zwar

98
00:03:53.720 --> 00:03:54.840
Förderprogramme und

99
00:03:54.840 --> 00:03:57.560
Fortbildungsangebote, doch verbindliche

100
00:03:57.560 --> 00:03:59.080
gesetzliche Leitlinien,

101
00:03:59.080 --> 00:04:00.700
konkret für die Schulen sind

102
00:04:00.700 --> 00:04:02.380
sind bislang kaum etabliert.

103
00:04:06.860 --> 00:04:09.300
Wie kann man KI generierte Bilder

104
00:04:09.300 --> 00:04:10.620
erkennen und sich vor

105
00:04:10.620 --> 00:04:13.180
Manipulationsversuchen schützen?

106
00:04:13.180 --> 00:04:15.740
Häufig enthalten KI generierte Bilder

107
00:04:15.740 --> 00:04:18.140
typische Fehler wie zum Beispiel

108
00:04:18.140 --> 00:04:20.459
fehlerhafte Hände, unnatürliche

109
00:04:20.459 --> 00:04:23.820
Proportionen oder Bildartefakte.

110
00:04:23.820 --> 00:04:26.340
Texte im Bild, Lichtverhältnisse

111
00:04:26.340 --> 00:04:28.550
oder Details geraten ebenfalls

112
00:04:28.550 --> 00:04:30.070
schnell aus dem Gleichgewicht.

113
00:04:30.710 --> 00:04:33.110
Auch eine Recherche über den Urheber

114
00:04:33.110 --> 00:04:35.590
oder das Impressum einer Webseite

115
00:04:35.590 --> 00:04:37.390
unterstützen dabei, die

116
00:04:37.390 --> 00:04:40.470
Seriösität der Quelle einzuschätzen.

117
00:04:40.470 --> 00:04:42.590
Zusätzlich können Rückwärtssuchen von

118
00:04:42.590 --> 00:04:44.950
Bildern oder spezialisierte KI

119
00:04:44.950 --> 00:04:47.350
Detektoren helfen, den Ursprung eines

120
00:04:47.350 --> 00:04:50.070
Bildes nachzuvollziehen, auch wenn diese

121
00:04:50.070 --> 00:04:52.790
Werkzeuge nicht immer zuverlässig sind.

122
00:04:52.790 --> 00:04:54.910
Schließlich ist es entscheidend, den

123
00:04:54.910 --> 00:04:56.870
Sinn eines Bildes zu hinterfragen.

124
00:04:57.660 --> 00:04:59.460
Welche Botschaft wird vermittelt?

125
00:04:59.460 --> 00:05:02.060
Ist sie sachlich oder politisch gefärbt

126
00:05:02.060 --> 00:05:04.540
und soll sie direkt oder eher subtil

127
00:05:04.540 --> 00:05:07.180
die Meinung der Betrachter beeinflussen?

128
00:05:07.180 --> 00:05:10.380
Ein Hinweis: In diesem Modul wird die Nutzung

129
00:05:10.380 --> 00:05:13.940
von generativer Bild-KI durch Lehrkräfte

130
00:05:13.940 --> 00:05:16.060
und in der Verwaltung fokussiert.

131
00:05:16.060 --> 00:05:17.180
Natürlich muss auch die

132
00:05:17.180 --> 00:05:19.060
Medienkompetenz der Schülerinnen

133
00:05:19.060 --> 00:05:20.620
und Schüler geschult werden.

134
00:05:20.620 --> 00:05:22.420
Auch sie müssen die in diesem

135
00:05:22.420 --> 00:05:24.140
Modul aufgeführten Inhalte

136
00:05:24.140 --> 00:05:26.280
erlernen und trainieren.

137
00:05:26.280 --> 00:05:28.240
Nur so können sie die Gefahren der

138
00:05:28.240 --> 00:05:30.320
manipulativen Bildverwendung in

139
00:05:30.320 --> 00:05:32.560
sozialen Medien erkennen und sich vor

140
00:05:32.560 --> 00:05:34.640
einer unkritischen Übernahme von Fake

141
00:05:34.640 --> 00:05:36.680
News oder Stereotypen schützen.
